{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47eTBHYNP4g1"
      },
      "source": [
        "# Introduction to LCEL and LangGraph: LangChain Powered RAG\n",
        "\n",
        "In the following notebook we're going to focus on learning how to navigate and build useful applications using LangChain, specifically LCEL, and how to integrate different APIs together into a coherent RAG application!\n",
        "\n",
        "In the notebook, you'll complete the following Tasks:\n",
        "\n",
        "- ðŸ¤ Breakout Room #1:\n",
        "  1. Install LangGraph\n",
        "  2. Understanding States and Nodes\n",
        "  3. Building a Basic Graph\n",
        "  4. Implementing a Simple RAG Graph\n",
        "  5. Extending the Graph with Complex Flows\n",
        "\n",
        "Let's get started!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ayVXHXHRE_t"
      },
      "source": [
        "# ðŸ¤ Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHd6POM0JFN"
      },
      "source": [
        "## Installing Required Libraries\n",
        "\n",
        "We'll start by grabbing all of our LangChain related packages!\n",
        "\n",
        "> NOTE: DO NOT RUN THIS CELL IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCC2AR-Q0m0x",
        "outputId": "cbd49ab6-f2fb-420c-e64c-e656ad21524e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU \"langgraph>=0.5.0\", \"langsmith>=0.4.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6wTp9C5qbY"
      },
      "source": [
        "## Set Environment Variables\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs - so we'll set our `OPENAI_API_KEY` `env` variable here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pKAfycq73wE",
        "outputId": "0b5702c2-028b-4bf4-ae8a-fffe243574a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsujAkpRWpJ"
      },
      "source": [
        "### A Note On Runnables\n",
        "\n",
        "# Understanding LangChain Runnables and LCEL\n",
        "\n",
        "In LangChain, a Runnable is like a LEGO brick in your AI application - it's a standardized component that can be easily connected with other components. The real power of Runnables comes from their ability to be combined in flexible ways using LCEL (LangChain Expression Language).\n",
        "\n",
        "## Key Features of Runnables\n",
        "\n",
        "### 1. Universal Interface\n",
        "Every Runnable in LangChain follows the same pattern:\n",
        "- Takes an input\n",
        "- Performs some operation\n",
        "- Returns an output\n",
        "\n",
        "This consistency means you can treat different components (like models, retrievers, or parsers) in the same way.\n",
        "\n",
        "### 2. Built-in Parallelization\n",
        "Runnables come with methods for handling multiple inputs efficiently:\n",
        "```python\n",
        "# Process inputs in parallel, maintain order\n",
        "results = chain.batch([input1, input2, input3])\n",
        "\n",
        "# Process inputs as they complete\n",
        "for result in chain.batch_as_completed([input1, input2, input3]):\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "### 3. Streaming Support\n",
        "Perfect for responsive applications:\n",
        "```python\n",
        "# Stream outputs as they're generated\n",
        "for chunk in chain.stream({\"query\": \"Tell me a story\"}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "```\n",
        "\n",
        "### 4. Easy Composition\n",
        "The `|` operator makes building pipelines intuitive:\n",
        "```python\n",
        "# Create a basic RAG chain\n",
        "rag_chain = retriever | prompt | model | output_parser\n",
        "```\n",
        "\n",
        "## Common Types of Runnables\n",
        "\n",
        "- **Language Models**: Like our `ChatOpenAI` instance\n",
        "- **Prompt Templates**: Format inputs consistently\n",
        "- **Retrievers**: Get relevant context from a vector store\n",
        "- **Output Parsers**: Structure model outputs\n",
        "- **LangGraph Nodes**: Individual components in our graph\n",
        "\n",
        "Think of Runnables as the building blocks of your LLM application. Just like how you can combine LEGO bricks in countless ways, you can mix and match Runnables to create increasingly sophisticated applications!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaVlJiilDzwM"
      },
      "source": [
        "## LangGraph Based RAG\n",
        "\n",
        "Now that we have a reasonable grasp of LCEL and the idea of Runnables - let's see how we can use LangGraph to build the same system!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77-NKo1EowG"
      },
      "source": [
        "### Primer: What is LangGraph?\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "#### Why Cycles?\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "#### Why LangGraph?\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!\n",
        "\n",
        "> NOTE: We're going to focus on building a simple DAG for today's assignment as an introduction to LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfLCnMXNE_Qc"
      },
      "source": [
        "### Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "> coordinated multi-actor and stateful applications\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "However, in our example here, we're focusing on a simpler `State` object:\n",
        "\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: list[Document]\n",
        "    response: str\n",
        "```\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. **We initialize our state object**:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "2. **Our user submits a query to our application.**  \n",
        "   We store the user's question in `state[\"question\"]`. Now we have:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **We pass our state object to an Agent node** which is able to read the current state. It will use the value of `state[\"question\"]` as input and might retrieve some context documents related to the question. It then generates a response which it stores in `state[\"response\"]`. For example:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [Document(page_content=\"...some data...\")],\n",
        "       \"response\": \"The Eiffel Tower is about 324 meters tall...\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "That's it! The important part is that we have a consistent object (`State`) that's passed around, holding the crucial information as we go from one node to the next. This ensures our application has a single source of truth about what has happened so far and what is happening now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kxczzsfVFNWT"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: list[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6xFY0_HoXG"
      },
      "source": [
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL Runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keL9O1drInw1"
      },
      "source": [
        "### Building Nodes\n",
        "\n",
        "We're going to need two nodes:\n",
        "\n",
        "A node for retrieval, and a node for generation.\n",
        "\n",
        "Let's start with our `retrieve` node!\n",
        "\n",
        "Notice how we do not need to update the state object in the node, but can instead return a modification directly to our state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Building a Retriever with LangChain\n",
        "\n",
        "In order to build our `retrieve` node, we'll first need to build a retriever!\n",
        "\n",
        "This will involve the following steps: \n",
        "\n",
        "1. Ingesting Data\n",
        "2. Chunking the Data\n",
        "3. Vectorizing the Data and Storing it in a Vector Database\n",
        "4. Converting it to a Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Retreiver Step 1: Ingesting Data\n",
        "\n",
        "In today's lesson, we're going to be building a RAG system to answer questions about loan complaints - and we will pull information into our index (vectorized chunks stored in our vector store) through LangChain's [`CSVLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> NOTE: We'll be using an async loader during our document ingesting - but our Jupyter Kernel is already running in an asyc loop! This means we'll want the ability to *nest* async loops. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we're good to load our documents through the [`PyMuPDFLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "\n",
        "loan_knowledge_resources = directory_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Volume 3\\nAcademic Calendars, Cost of Attendance, and\\nPackaging\\nIntroduction\\nThis volume of the Federal Student Aid (FSA) Handbook discusses the academic calendar, payment period, and\\ndisbursement requirements for awarding aid under the Title IV student financial aid programs, determining a student9s\\ncost of attendance, and packaging Title IV aid.\\nThroughout this volume of the Handbook, the words \"we,\" \"our,\" and \"us\" refer to the United States Department of\\nEducation (the Department). The word \"you\" refers to the primary audience of the Handbook, school financial aid\\nadministrators. In other volumes of the Handbook we use \"institution,\" \"school,\" and \"college\" interchangeably, unless a\\nmore specific meaning is provided. In this volume we consistently use the term \"school.\" <HEA= refers to the Higher\\nEducation Act of 1965, as amended. Title IV refers to the student financial aid programs authorized under Title IV of the\\nHEA.\\nWe appreciate any comments that you have on this volume as wel'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_knowledge_resources[0].page_content[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TextSplitting aka Chunking\n",
        "\n",
        "We'll use the `RecursiveCharacterTextSplitter` to create our toy example.\n",
        "\n",
        "It will split based on the following rules:\n",
        "\n",
        "- Each chunk has a maximum size of 1000 tokens\n",
        "- It will try and split first on the `\\n\\n` character, then on the `\\n`, then on the `<SPACE>` character, and finally it will split on individual tokens.\n",
        "\n",
        "Let's implement it and see the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "loan_knowledge_chunks = text_splitter.split_documents(loan_knowledge_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ðŸ—ï¸ Activity #1:\n",
        "\n",
        "While there's nothing specifically wrong with the chunking method used above - it is a naive approach that is not sensitive to specific data formats.\n",
        "\n",
        "Brainstorm some ideas that would split large single documents into smaller documents.\n",
        "\n",
        "#### âœ… Answer:\n",
        "\n",
        "## Sophisticated Document Chunking Strategies\n",
        "See [ACTIVITIES_QUESTIONS](./ACTIVITIES_QUESTIONS.md) for detailed code snippet examples\n",
        "\n",
        "### 1. **Semantic Boundary Chunking**\n",
        "\n",
        "This approach uses natural language processing to identify logical content boundaries, ensuring chunks maintain semantic coherence. Instead of splitting at arbitrary character counts, it identifies topic transitions, paragraph breaks, and section headers.\n",
        "\n",
        "**Process:**\n",
        "- Parse document structure (headers, paragraphs, sections)\n",
        "- Use sentence tokenization to identify natural breakpoints\n",
        "- Apply sliding window with overlap to maintain context\n",
        "- Validate chunk size constraints while preserving meaning\n",
        "\n",
        "### 2. **Hierarchical Structure-Aware Chunking**\n",
        "\n",
        "This method leverages document structure (tables, lists, code blocks, headers) to create chunks that respect the document's logical organization. It's particularly effective for technical documentation and structured content.\n",
        "\n",
        "**Process:**\n",
        "- Parse markdown/HTML structure to identify elements\n",
        "- Group related elements (tables with captions, code with explanations)\n",
        "- Maintain parent-child relationships in metadata\n",
        "- Create variable-sized chunks based on content type\n",
        "\n",
        "\n",
        "### 3. **Token-Optimized Sliding Window Chunking**\n",
        "\n",
        "This strategy optimizes for LLM token limits while maintaining context continuity. It uses actual tokenization to ensure precise token counts and implements intelligent overlap strategies.\n",
        "\n",
        "**Process:**\n",
        "- Use model-specific tokenizer for accurate token counting\n",
        "- Implement sliding window with contextual overlap\n",
        "- Preserve sentence boundaries within token constraints\n",
        "- Add metadata for chunk relationships and context\n",
        "\n",
        "\n",
        "### 4. **Embedding-Based Semantic Clustering Chunking**\n",
        "\n",
        "This advanced strategy uses vector embeddings to group semantically related content, even when it's not physically adjacent. It creates more coherent chunks by understanding content similarity at a deeper level than simple text analysis.\n",
        "\n",
        "**Process:**\n",
        "- Generate embeddings for sentences/paragraphs using sentence transformers\n",
        "- Apply clustering algorithms (K-means, DBSCAN) to group similar content\n",
        "- Create chunks from clusters while respecting size constraints\n",
        "- Maintain topic coherence across non-contiguous text sections\n",
        "\n",
        "\n",
        "### 5. **Multi-Modal Content-Type Aware Chunking**\n",
        "\n",
        "This sophisticated approach recognizes different content types (code blocks, tables, lists, prose) and applies specialized chunking strategies for each, maintaining the integrity of structured content while optimizing for downstream processing.\n",
        "\n",
        "**Process:**\n",
        "- Parse and classify content blocks by type (markdown, code, tables, etc.)\n",
        "- Apply type-specific chunking rules and size constraints\n",
        "- Maintain content relationships and dependencies\n",
        "- Create unified metadata schema across content types\n",
        "\n",
        "### 6. **Dependency-Aware Graph-Based Chunking**\n",
        "\n",
        "This cutting-edge approach models document content as a knowledge graph, identifying relationships and dependencies between concepts to create chunks that maintain logical coherence and reference integrity.\n",
        "\n",
        "**Process:**\n",
        "- Extract entities and relationships using NLP (spaCy, Stanford NER)\n",
        "- Build directed graph of content dependencies and references\n",
        "- Apply graph clustering algorithms to identify cohesive subgraphs\n",
        "- Generate chunks that preserve critical relationships and minimize broken references\n",
        "\n",
        "\n",
        "These sophisticated strategies leverage machine learning, graph theory, and advanced NLP to create more intelligent chunking that preserves semantic meaning, content structure, and logical relationships across document boundaries. Each strategy addresses different use cases: semantic chunking for general text processing, structure-aware for technical docs, and token-optimized for LLM applications. The choice depends on your document types and downstream processing requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Embeddings and Dense Vector Search\n",
        "\n",
        "Now that we have our individual chunks, we need a system to correctly select the relevant pieces of information to answer our query.\n",
        "\n",
        "This sounds like a perfect job for embeddings!\n",
        "\n",
        "We'll be using OpenAI's `text-embedding-3` model as our embedding model today!\n",
        "\n",
        "Let's load it up through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### â“ Question #1:\n",
        "\n",
        "What is the embedding dimension, given that we're using `text-embedding-3-small`?\n",
        "\n",
        "You will need to fill the next cell out correctly with your embedding dimension for the rest of the notebook to run.\n",
        "\n",
        "> HINT: Check out the docs to help you answer this question.\n",
        "\n",
        "#### âœ… Answer:\n",
        "\n",
        "Based on the OpenAI documentation and search results, **`text-embedding-3-small` has a default embedding dimension of 1536**.\n",
        "\n",
        "Key details about the dimensions:\n",
        "\n",
        "- **Default dimensions**: 1536 (same as the previous `text-embedding-ada-002` model)\n",
        "- **Configurable dimensions**: Can be shortened to as few as 512 dimensions using the `dimensions` parameter\n",
        "- **Flexible sizing**: You can specify any dimension size between 512 and 1536 without losing the concept-representing properties\n",
        "\n",
        "The model creates embeddings with 1536 dimensions by default, but OpenAI implemented Matryoshka Representation Learning (MRL) which allows you to truncate the embeddings to smaller sizes while maintaining most of the semantic quality.\n",
        "\n",
        "This is particularly useful for:\n",
        "\n",
        "- **Cost optimization**: Smaller dimensions = lower storage costs in vector databases\n",
        "- **Performance tuning**: Balance between accuracy and computational efficiency  \n",
        "- **Infrastructure constraints**: Some vector stores have dimension limits\n",
        "\n",
        "For example, in your chunking pipeline, you could use:\n",
        "\n",
        "```python\n",
        "# Full dimensions (1536)\n",
        "response = openai.embeddings.create(\n",
        "    input=chunks,\n",
        "    model=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "# Reduced dimensions (512) for cost savings\n",
        "response = openai.embeddings.create(\n",
        "    input=chunks,\n",
        "    model=\"text-embedding-3-small\",\n",
        "    dimensions=512\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim =  1536"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Using A Vector Database - Intoduction to Qdrant\n",
        "\n",
        "Up to this point, we've been using a dictionary to hold our embeddings - typically, we'll want to use a more robust strategy.\n",
        "\n",
        "In this bootcamp - we'll be focusing on leveraging [Qdrant's vector database](https://qdrant.tech/qdrant-vector-database/).\n",
        "\n",
        "Let's take a look at how we set-up Qdrant!\n",
        "\n",
        "> NOTE: We'll be spending a lot of time learning about Qdrant throughout the remainder of our time together - but for an initial primer, please check out [this resource](https://qdrant.tech/articles/what-is-a-vector-database/)\n",
        "\n",
        "We are going to be using an \"in-memory\" Qdrant client, which means that our vectors will be held in our system's memory (RAM) - this is useful for prototyping and developement at smaller scales - but would need to be modified when moving to production. Luckily for us, this modification is trivial!\n",
        "\n",
        "> NOTE: While LangChain uses the terminology \"VectorStore\" (also known as a Vector Library), Qdrant is a \"Vector Database\" - more info. on that [here.](https://weaviate.io/blog/vector-library-vs-vector-database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to create a collection - a collection is a specific...collection of vectors within the Qdrant client.\n",
        "\n",
        "These are useful as they allow us to create multiple different \"warehouses\" in a single client, which can be leveraged for personalization and more!\n",
        "\n",
        "Also notice that we define what our vector shapes are (embedding dim) as well as our desired distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can assemble our vector database! Notice that we provide our client, our created collection, and our embedding model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    embedding=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our vector database set-up, we can add our documents into it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=loan_knowledge_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "Now that we have an idea of how we're getting our most relevant information - let's see how we could create a pipeline that would automatically extract the closest chunk to our query and use it as context for our prompt!\n",
        "\n",
        "This will involve a popular LangChain interace known as `as_retriever`!\n",
        "\n",
        "> NOTE: We can still specify how many documents we wish to retrieve per vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 25, '_id': '568d223d01d247f88f21456227ef5a41', '_collection_name': 'loan_knowledge_index'}, page_content='hour, or non-SE9W nonstandard term program is offered in modules, the minimum loan period is still the lesser of the\\nacademic year or the program length (or remaining portion of the program).\\nFor Title IV aid purposes, students are allowed to skip one or more modules. However, if a loan period includes modules\\nthat the student does not attend, the COA for the loan period may not include costs associated with those modules.\\nMinimum Loan Period: Standard Term Combined With an Intersession\\nAs we explain under <Intersessions= in Volume 3, Chapter 1, in limited cases for academic programs offered in standard\\nterms, a short nonstandard term (often called an <intersession=) may be combined with a preceding or following standard\\nterm and considered to be a single standard term. In such cases, the minimum loan period for a Direct Loan is different\\ndepending on whether a student attends the intersession. If a student who attends the intersession requests a loan for the\\ncombined term, the loan period includes the standard term plus the intersession. However, if the student attends only the\\nstandard term and is not enrolled in the intersession that is attached to that term, the loan period includes only the\\nstandard term.\\nMaximum Loan Periods\\nThe maximum period for which you may originate a Direct Loan is generally an academic year. However, if your school\\napplies the annual loan limit for Direct Subsidized Loans and Direct Unsubsidized Loans to a period of time greater than\\nan academic year, you may originate a Direct Loan for that longer period of time. For example, a school might offer an\\n1100 clock-hour program and define the academic year as 900 clock hours but could choose to allow students to receive\\njust one annual loan limit for the entire 1100-hour program. In that case, the loan period would correspond to the length\\nof the program, a period of time that is longer than the academic year.\\nDirect Loan Disbursement Requirements\\nFor general guidance on the timing of disbursements made under the Title IV programs, see Volume 3, Chapter 1. For\\nguidance on reporting Title IV program disbursements through the COD System and the rules for making early\\ndisbursements, late disbursements, and retroactive payments, see Volume 4, Chapter 2. In this section we discuss certain\\nother disbursement requirements that are specific to the Direct Loan Program.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal Direct Loan disbursement\\nrequirements that apply when periods of clinical work are included in a standard term.\\nRequirement for Substantially Equal Disbursements\\nDirect Loans must be disbursed in substantially equal installments, regardless of any difference in costs for different\\npayment periods that are within the same loan period, and no Direct Loan disbursement may exceed one-half of the loan\\nMaximum Loan Period\\n34 CFR 685.301(a)(10)(iv)\\nDetermining Direct Loan Disbursement Dates and Amounts\\n34 CFR 685.303(d)'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 23, '_id': '2a89c17a69544637a2621147d4ec574c', '_collection_name': 'loan_knowledge_index'}, page_content='period are separated by one or more terms in which the student is ineligible. For example, if a student is expected to be\\nenrolled on at least a half-time basis in the fall and spring quarters of an academic year consisting of the fall, winter, and\\nspring quarters, but the student indicates that they do not plan to attend the winter quarter (or that they plan to be\\nenrolled on a less than half-time basis during that quarter), the school may still originate a loan for a loan period covering\\nthe fall, winter, and spring quarters. Of course, no costs associated with winter quarter may be included in the student9s\\nCOA when determining the loan amount the student is eligible to receive for the fall and spring quarters. Similarly, if a\\nschool initially originates a loan for a fall-winter-spring loan period based on a student9s anticipated enrollment status of\\nat least half time during all three quarters, but the student subsequently does not attend the winter quarter or temporarily\\ndrops below half-time status for that term, and then resumes at least half-time enrollment in the spring, the school is not\\nrequired to make any changes to the original fall-winter-spring loan period. However, it may be necessary for the school\\nto adjust the originally approved loan amount if that amount is no longer supported by the reduced costs for the fall and\\nspring quarters only.\\nIn the first scenario described above the school could also choose to originate two separate loans for fall-only and spring-\\nonly loan periods. In the second scenario the school would also have the option of adjusting the original fall-winter-spring\\nloan period to fall-only, and then originating a new spring-only loan. Note, however, that in both cases the school would\\nthen be required to separately subtract the student9s full SAI from the fall-only and spring-only costs when determining\\nthe student9s Direct Subsidized Loan eligibility for those terms (see <No Alternate SAI When Originating Loans for Periods\\nOther Than Nine Months= earlier in this chapter). In some cases this could significantly reduce or even eliminate a\\nstudent9s need for Direct Subsidized Loans. In contrast, using a fall-winter-spring loan period (excluding all costs\\nassociated with the winter quarter) would allow the school to subtract the full SAI from the higher combined costs for the\\nfall and spring terms, partially mitigating the effect of not having alternate SAIs for periods of enrollment other than nine\\nmonths.\\nThe limited exception described above applies only if a student is eligible to receive a Direct Loan during the first and last\\nterms within the loan period. The term in which the student is ineligible cannot be the first or last term in the loan period.\\nFor instance, a school may not originate a loan for a fall-winter-spring loan period if the student does not attend the fall\\nterm or the spring term.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal loan period rules that apply when\\nperiods of clinical work are included in a standard term.\\nMinimum Loan Periods\\nThe minimum period for which a school may originate a Direct Loan varies depending on the school9s academic calendar.\\nAs explained below and in Chapter 7, different rules apply for purposes of determining the minimum loan period for a\\nDirect Loan and the type of academic year that a school may use to monitor Direct Loan annual loan limits depending on\\nwhether a program is term-based (including subscription-based programs; see Volume 3, Chapter 1) with either standard'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 22, '_id': '90faa3c9e3d346eb81e2607eaff0f2a0', '_collection_name': 'loan_knowledge_index'}, page_content=\"or to prevent the total aid package from exceeding the student9s need.\\nAlthough a school isn9t required to return Direct Loan funds that were disbursed to the borrower (either directly or by\\napplying them to the student's account) before the overaward situation occurred, the law doesn9t prevent your school\\nfrom returning funds that were applied to the student account if you choose to do so. A borrower who receives a direct\\npayment of loan funds is not required to repay an overawarded amount, unless the overaward was caused by the\\nborrower9s misreporting or withholding of information.\\nLoan Periods\\nThe loan period (also referred to as the <period of enrollment=) is the period for which a Direct Loan is intended. It must\\ncoincide with an academic period established by the school for which institutional charges are generally assessed (e.g.,\\nsemester, trimester, quarter, length of the student9s program, or academic year). It9s important to define the loan period\\nat the beginning of the loan awarding process, because the timing and amount of Direct Loan disbursements are tied to\\nthe loan period.\\nGenerally, the loan period may not include terms in which a student is ineligible (for example, if the student is not enrolled\\nduring a particular term or is enrolled less than half time during a term). There is a limited exception to this rule if the loan\\nperiod begins and ends with a term in which the student is eligible for Direct Loans, but the first and last terms of the loan\"),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 24, '_id': '97ae96e1d6324d03a60e9d29842d0314', '_collection_name': 'loan_knowledge_index'}, page_content='2. \\nNonstandard terms that are substantially equal, but one or more of the terms in the academic year\\ncontains fewer than nine weeks.\\nNon-\\nSE9W\\n3. \\nNonstandard terms that are not substantially equal in length (one or more of the terms in the academic\\nyear differs in length from another term by more than two weeks).\\nNon-\\nSE9W\\nWe refer to the first type of nonstandard term as <SE9W= nonstandard terms. We group the second and third types\\ntogether and refer to them as <non-SE9W= nonstandard terms.\\nPrograms with SE9W nonstandard terms are treated the same as standard-term programs for purposes of determining\\nminimum loan period length and monitoring annual loan limits. However, programs with non-SE9W nonstandard terms are\\ntreated the same as non-term programs for these purposes.\\nNote that substantially equal nonstandard terms (the first two types of nonstandard terms described above) are treated\\ndifferently for purposes of determining Direct Loan payment periods than for determining minimum loan period length\\nand monitoring annual loan limits. As explained in Volume 1, Chapter 1, if a program is offered in standard terms or in\\nnonstandard terms that are substantially equal in length (regardless of the length of the nonstandard term), the payment\\nperiod is the term.\\nHowever, for purposes of determining the minimum loan period for a Direct Loan and monitoring Direct Loan annual loan\\nlimits, substantially equal nonstandard terms that contain fewer than nine weeks are treated the same as nonstandard\\nterms that are not substantially equal. This means that if a program has substantially equal nonstandard terms that are\\nless than nine weeks in length, you must make a Direct Loan disbursement each term (the same as would be the case if\\nthe program were offered in standard terms), but the minimum loan period and the type of academic year used to\\nmonitor Direct Loan annual loan limits must be determined in accordance with the rules that apply to non-term programs.\\nFor detailed information on standard term, nonstandard term, and non-term programs, see Volume 1, Chapter 1.\\nMinimum Loan Period: Standard Term and SE9W Nonstandard Term Programs\\nFor credit-hour programs with standard terms (semesters, quarters, or trimesters), or with SE9W\\nnonstandard terms, the minimum loan period is a single academic term. For example, if a student will be enrolled in the\\nfall semester only and will skip the spring semester, you may originate a loan with a loan period that covers only the fall\\nterm.\\nMinimum Loan Period: Clock-Hour, Non-Term, and Non-SE9W Nonstandard Term Programs\\nFor all other programs (i.e., clock-hour, non-term, and non-SE9W nonstandard term programs), the minimum\\nloan period is generally the lesser of the program length (or remainder of the program, if there is less than full academic\\nyear remaining) or the academic year. There are exceptions to this minimum loan period rule when originating loans for\\ntransfer students, or for students who complete or otherwise cease enrollment in one program and then begin a different\\nprogram at the same school. We discuss these exceptions in detail in Chapter 7 of this volume.\\nMinimum Loan Period: Programs Offered in Modules\\nIf a program is offered in modules, this does not change the minimum loan period rules for Direct Loans. For example, if a\\nstandard or SE9W nonstandard term is divided into two or more modules, the minimum loan period for a Direct Loan is'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 70, '_id': '809a98bca8cf4ab39414feb73020eeab', '_collection_name': 'loan_knowledge_index'}, page_content='credit-hour program.) The loan period will be for the first full academic year of the new program (the period\\nduring which the student will be expected to complete 24 semester hours and 30 weeks of instructional time).')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"What is the loan repayment period?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Node\n",
        "\n",
        "We're finally ready to create our node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "05qhncktIwK_"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Node\n",
        "\n",
        "Next, let's create our `generate` node - which will leverage LangChain and something called an \"LCEL Chain\" which you can read more about [here](https://python.langchain.com/docs/concepts/lcel/)!\n",
        "\n",
        "We'll want to create a chain that does the following: \n",
        "\n",
        "1. Formats our inputs into a chat template suitable for RAG\n",
        "2. Takes that chat template and sends it to an LLM\n",
        "3. Parses that output into `str` format\n",
        "\n",
        "Let's get chaining!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: RAG Chat Template\n",
        "\n",
        "We'll create a chat template that takes in some query and formats it as a RAG prompt using LangChain's prompt template!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#CONTEXT:\\nOUR CONTEXT HERE\\n\\nQUERY:\\nOUR QUERY HERE\\n\\nUse the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it\\'s not contained in the provided context response with \"I don\\'t know\"\\n'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt.invoke({\"context\" : \"OUR CONTEXT HERE\", \"query\" : \"OUR QUERY HERE\"}).messages[0].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Chain Components: Generator\n",
        "\n",
        "We'll next set-up the generator - which will be OpenAI's `gpt-4o-nano` for today!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now call our model with a formatted prompt.\n",
        "\n",
        "Notice that we have some nested calls here - we'll see that this is made easier by LCEL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 72, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BqQekKy0sRhBCVaH7QX12Riq4PmQ1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1af9e502-3ca0-4589-ab88-74a5520470d5-0', usage_metadata={'input_tokens': 72, 'output_tokens': 7, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_chat_model.invoke(chat_prompt.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: `str` Parser\n",
        "\n",
        "Finally, let's set-up our `StrOutputParser()` which will transform our model's output into a simple `str` to be provided to the user.\n",
        "\n",
        "> NOTE: You can see us leveraging LCEL in the example below to avoid needing to do nested calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The capital of France is Paris.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "\n",
        "generator_chain.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `generate` Node: \n",
        "\n",
        "Now we can create our `generate` Node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XiL2isC8JS0l"
      },
      "outputs": [],
      "source": [
        "def generate(state: State) -> State:\n",
        "  generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtriMEcJxeR"
      },
      "source": [
        "Now we can start defining our graph!\n",
        "\n",
        "Think of the graph's state as a blank canvas that we can add nodes and edges to.\n",
        "\n",
        "Every graph starts with two special nodes - START and END - the act as the entry and exit point to the other nodes in the graphs.  \n",
        "\n",
        "All valid graphs must start at the START node and end at the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ia9IWM9AJ4bx"
      },
      "outputs": [],
      "source": [
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kro8bQEL2Yj"
      },
      "source": [
        "Now we can add a sequence to our \"canvas\" (graph) - this can be done by providing a list of nodes, the will automatically have edges that connect the i-th element to the i+1-th element in the list. The final element will be added to the END node unless otherwise specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OSfDMlXUL2kh"
      },
      "outputs": [],
      "source": [
        "graph_builder = graph_builder.add_sequence([retrieve, generate])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g79NZf5VL4en"
      },
      "source": [
        "Next, let's connect our START node to our `retrieve` node by adding an edge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "w1kTJKGNL4qA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11cf50590>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"retrieve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiVyt8-L6_5"
      },
      "source": [
        "Finally we can compile our graph! This will do basic verification to ensure that the Runnables have the correct inputs/outputs and can be matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TM4My6geL7FW"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvoQcfCP3xI"
      },
      "source": [
        "Finally, we can visualize our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x11a555ee0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRCjvvyP8DA"
      },
      "source": [
        "Let's take it for a spin!\n",
        "\n",
        "We invoke our graph like we do any other Runnable in LCEL!\n",
        "\n",
        "> NOTE: That's right, even a compiled graph is a Runnable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mSbsRLurKOKd",
        "outputId": "114185f3-4b98-4c66-96cd-65f4e4e3ef1d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Applying for and securing a student loan in 2025 is not necessarily a terrible idea based on the provided context. The documents outline the process for applying for loans, including deadlines for application submissions, procedures for determining student eligibility, and the importance of counseling and understanding loan limits. They emphasize that students can receive loans if they meet certain criteria, and there are structured steps to ensure proper management of aid and repayment planning. Therefore, whether it is a good or bad idea depends on individual circumstances, but from the information given, it is a viable option if the student meets the eligibility requirements and understands the responsibilities involved."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "response = graph.invoke({\"question\" : \"Is applying for and securing a student loan in 2025 a terrible idea?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_jEmE_rKwED",
        "outputId": "c5fac807-2a24-4cf9-8cca-105def13e3d8"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, the maximum loan amounts you can receive from the government depend on your enrollment status, program length, and other factors. For example:\n",
              "\n",
              "- For a dependent student in a 900 clock-hour program, the prorated combined loan limit is $4,583, with up to $2,917 of that being subsidized.\n",
              "- The annual loan limit for a dependent first-year undergraduate is $5,500, with no more than $3,500 subsidized, but this can be prorated if the program is shorter than an academic year.\n",
              "- For programs shorter than an academic year, the loan limits are prorated based on the fraction of the academic year completed, and the total loan amount is capped accordingly.\n",
              "\n",
              "Additionally, there are aggregate loan limits: dependent undergraduates can borrow up to $31,000 total (with a maximum of $23,000 subsidized), and independent undergraduates can borrow up to $57,500 total (with a maximum of $23,000 subsidized). Graduate and professional students have higher limits.\n",
              "\n",
              "In summary, yes, there is a cap on the amount of loan money you can receive from the government, and it varies depending on your specific circumstances."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"How much loan money can I actually get from the government to go to school these days? Is there a cap?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The provided context mentions several types of grants and scholarships, but it does not specify which are available for free. However, generally, Pell Grants, FSEOG (Federal Supplemental Educational Opportunity Grant), and certain state grants are typically considered free financial aid because they do not require repayment. \n",
              "\n",
              "From the context:\n",
              "- Pell Grants are a form of federal grant aid.\n",
              "- FSEOG is another grant program mentioned.\n",
              "- State grants are also listed among the grants and scholarships that do not require repayment.\n",
              "\n",
              "Therefore, the grants and scholarships available for free include Pell Grants, FSEOG, and state grants."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"What grants and scholarships are available for free?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I don't know"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"Who is Batman?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LRYXvvRjOp"
      },
      "source": [
        "#### â“ Question #2:\n",
        "LangGraph's graph-based approach lets us visualize and manage complex flows naturally. How could we extend our current implementation to handle edge cases? For example:\n",
        "- What if the retriever finds no relevant context?  \n",
        "- What if the response needs fact-checking?\n",
        "Consider how you would modify the graph to handle these scenarios.\n",
        "\n",
        "##### Solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### âœ… Answer:\n",
        "\n",
        "## Enhanced LangGraph RAG with Edge Case Handling\n",
        "\n",
        "To handle edge cases in our RAG system, we'll extend the graph with additional nodes and conditional routing. Here's how we can address the scenarios you mentioned:\n",
        "\n",
        "### 1. Enhanced State Definition\n",
        "\n",
        "First, let's extend our state to track additional information needed for edge case handling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Optional, Literal\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Enhanced State with edge case handling\n",
        "class EnhancedState(TypedDict):\n",
        "    question: str\n",
        "    context: list[Document]\n",
        "    response: str\n",
        "    context_quality: Optional[float]  # Score for context relevance\n",
        "    needs_fact_check: Optional[bool]  # Flag for fact-checking requirement\n",
        "    fact_check_result: Optional[str]  # Result of fact-checking\n",
        "    fallback_response: Optional[str]  # Response when no context found\n",
        "    confidence_score: Optional[float]  # Overall confidence in the response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 2. Enhanced Retrieval Node\n",
        "\n",
        "We'll modify the retrieval node to assess context quality and handle cases where no relevant context is found:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_retrieve(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Enhanced retrieval with context quality assessment using the same Qdrant vector store\"\"\"\n",
        "    \n",
        "    # Use the same retriever from the previous implementation\n",
        "    # This ensures we're using the same Qdrant vector database and embedding model\n",
        "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "    \n",
        "    # Assess context quality using similarity scores and content analysis\n",
        "    context_quality = 0.0\n",
        "    \n",
        "    if retrieved_docs:\n",
        "        # Enhanced quality assessment using the same similarity scoring approach\n",
        "        # Get similarity scores by performing a similarity search with scores\n",
        "        scored_docs = vector_store.similarity_search_with_score(\n",
        "            state[\"question\"], \n",
        "            k=5\n",
        "        )\n",
        "        \n",
        "        # Calculate context quality based on similarity scores\n",
        "        if scored_docs:\n",
        "            # Use the highest similarity score as base quality\n",
        "            # Note: Qdrant with cosine distance returns distance, not similarity\n",
        "            # So we convert distance to similarity (1 - distance)\n",
        "            max_similarity = 1 - min(score for _, score in scored_docs)\n",
        "            context_quality = max(0.0, max_similarity)\n",
        "            \n",
        "            # Boost quality if we have multiple good matches\n",
        "            good_matches = sum(1 for _, score in scored_docs if (1 - score) > 0.7)\n",
        "            if good_matches >= 2:\n",
        "                context_quality = min(1.0, context_quality + 0.2)\n",
        "        \n",
        "        # Additional quality check based on content relevance\n",
        "        question_terms = set(state[\"question\"].lower().split())\n",
        "        for doc in retrieved_docs:\n",
        "            doc_terms = set(doc.page_content.lower().split())\n",
        "            overlap = len(question_terms.intersection(doc_terms))\n",
        "            if overlap > 2:  # If more than 2 terms overlap, boost quality\n",
        "                context_quality = min(1.0, context_quality + 0.1)\n",
        "                break\n",
        "    \n",
        "    return {\n",
        "        \"context\": retrieved_docs,\n",
        "        \"context_quality\": context_quality\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3. Context Quality Router\n",
        "\n",
        "This node decides whether to proceed with generation or provide a fallback response.\n",
        "\n",
        "**Note on Routing Design Pattern:**\n",
        "The router functions return logical names (like \"generate\", \"fallback\") rather than actual node names. This provides flexibility - you can change node names without modifying router logic. The mapping in `add_conditional_edges` translates logical names to actual node names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_based_on_context_quality(state: EnhancedState):\n",
        "    \"\"\"Route based on context quality assessment\"\"\"\n",
        "    \n",
        "    context_quality = state.get(\"context_quality\", 0.0)\n",
        "    context = state.get(\"context\", [])\n",
        "    \n",
        "    # If no context found or quality is too low, use fallback\n",
        "    if not context or context_quality < 0.3:\n",
        "        return \"fallback\"  # Logical name for fallback path\n",
        "    else:\n",
        "        return \"generate\"  # Logical name for generation path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4. Fallback Response Node\n",
        "\n",
        "This node handles cases where no relevant context is found:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fallback_response(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Provide fallback response when no relevant context is found\"\"\"\n",
        "    \n",
        "    fallback_msg = (\"I apologize, but I couldn't find relevant information in my knowledge base \"\n",
        "                   \"to answer your question about student loans and financial aid. \"\n",
        "                   \"For the most accurate and up-to-date information, I recommend contacting \"\n",
        "                   \"your school's financial aid office or visiting studentaid.gov.\")\n",
        "    \n",
        "    return {\n",
        "        \"response\": fallback_msg,\n",
        "        \"fallback_response\": fallback_msg,\n",
        "        \"confidence_score\": 0.1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 5. Enhanced Generation Node\n",
        "\n",
        "This node generates responses and determines if fact-checking is needed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_generate(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Enhanced generation with fact-checking assessment using the same chat prompt and model\"\"\"\n",
        "    \n",
        "    # Use the same generator chain from the previous implementation\n",
        "    # This ensures we're using the same chat_prompt and openai_chat_model\n",
        "    generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "    response = generator_chain.invoke({\n",
        "        \"query\": state[\"question\"], \n",
        "        \"context\": state[\"context\"]\n",
        "    })\n",
        "    \n",
        "    # Determine if fact-checking is needed based on content analysis\n",
        "    needs_fact_check = False\n",
        "    confidence_score = 0.8\n",
        "    \n",
        "    # Base confidence on context quality from retrieval\n",
        "    context_quality = state.get(\"context_quality\", 0.5)\n",
        "    confidence_score = max(0.3, min(0.9, context_quality))\n",
        "    \n",
        "    # Check for numerical values that might need verification\n",
        "    import re\n",
        "    if re.search(r'\\$[\\d,]+|\\d+%|\\d{4}', response):\n",
        "        needs_fact_check = True\n",
        "        confidence_score = max(0.4, confidence_score - 0.2)\n",
        "    \n",
        "    # Check for specific financial terms that need verification\n",
        "    financial_terms = ['loan limit', 'maximum', 'aggregate', 'annual', 'interest rate', 'cap']\n",
        "    if any(term in response.lower() for term in financial_terms):\n",
        "        needs_fact_check = True\n",
        "        confidence_score = max(0.5, confidence_score - 0.1)\n",
        "    \n",
        "    return {\n",
        "        \"response\": response,\n",
        "        \"needs_fact_check\": needs_fact_check,\n",
        "        \"confidence_score\": confidence_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 6. Fact-Checking Router\n",
        "\n",
        "This node determines whether to proceed with fact-checking or return the response:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_fact_check(state: EnhancedState):\n",
        "    \"\"\"Route to fact-checking if needed\"\"\"\n",
        "    \n",
        "    needs_fact_check = state.get(\"needs_fact_check\", False)\n",
        "    \n",
        "    if needs_fact_check:\n",
        "        return \"fact_check\"  # Logical name for fact-checking path\n",
        "    else:\n",
        "        return \"finalize\"  # Logical name for finalization path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7. Fact-Checking Node\n",
        "\n",
        "This node performs fact-checking on the generated response:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fact_check(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Perform fact-checking on the generated response using the same OpenAI model\"\"\"\n",
        "    \n",
        "    # Create a fact-checking prompt\n",
        "    fact_check_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"human\", \"\"\"\n",
        "        Please fact-check the following response about student loans and financial aid:\n",
        "        \n",
        "        ORIGINAL QUESTION: {question}\n",
        "        \n",
        "        RESPONSE TO CHECK: {response}\n",
        "        \n",
        "        CONTEXT USED: {context}\n",
        "        \n",
        "        Please verify if the information in the response is accurate based on the context.\n",
        "        If you find any inaccuracies, please provide corrections.\n",
        "        Respond with either:\n",
        "        - \"ACCURATE: The response is factually correct.\"\n",
        "        - \"INACCURATE: [specific corrections needed]\"\n",
        "        \"\"\")\n",
        "    ])\n",
        "    \n",
        "    # Create fact-checking chain using the same openai_chat_model from previous implementation\n",
        "    fact_check_chain = fact_check_prompt | openai_chat_model | StrOutputParser()\n",
        "    \n",
        "    # Perform fact-checking\n",
        "    fact_check_result = fact_check_chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"response\": state[\"response\"],\n",
        "        \"context\": \"\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
        "    })\n",
        "    \n",
        "    # Update confidence based on fact-check result and context quality\n",
        "    confidence_score = state.get(\"confidence_score\", 0.6)\n",
        "    context_quality = state.get(\"context_quality\", 0.5)\n",
        "    \n",
        "    if fact_check_result.startswith(\"ACCURATE\"):\n",
        "        # Boost confidence if fact-check passes and context quality is good\n",
        "        confidence_boost = 0.2 if context_quality > 0.7 else 0.1\n",
        "        confidence_score = min(1.0, confidence_score + confidence_boost)\n",
        "    else:\n",
        "        # Reduce confidence if fact-check fails, but consider context quality\n",
        "        confidence_reduction = 0.3 if context_quality < 0.5 else 0.2\n",
        "        confidence_score = max(0.2, confidence_score - confidence_reduction)\n",
        "    \n",
        "    return {\n",
        "        \"fact_check_result\": fact_check_result,\n",
        "        \"confidence_score\": confidence_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 8. Response Finalization Node\n",
        "\n",
        "This node finalizes the response with confidence information:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def finalize_response(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Finalize the response with confidence and fact-check information\"\"\"\n",
        "    \n",
        "    response = state[\"response\"]\n",
        "    confidence_score = state.get(\"confidence_score\", 0.8)\n",
        "    fact_check_result = state.get(\"fact_check_result\", \"\")\n",
        "    \n",
        "    # Add confidence indicator to response if confidence is low\n",
        "    if confidence_score < 0.5:\n",
        "        response += \"\\n\\n*Note: Please verify this information with official sources as my confidence in this response is limited.*\"\n",
        "    \n",
        "    # Add fact-check information if available\n",
        "    if fact_check_result and fact_check_result.startswith(\"INACCURATE\"):\n",
        "        response += f\"\\n\\n*Fact-check note: {fact_check_result}*\"\n",
        "    \n",
        "    return {\n",
        "        \"response\": response\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 9. Building the Enhanced Graph\n",
        "\n",
        "Now let's build the enhanced graph with conditional routing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import END from langgraph\n",
        "from langgraph.graph import END\n",
        "\n",
        "# Build the enhanced graph using the same components from the previous implementation:\n",
        "# - Same Qdrant vector_store and retriever for document retrieval\n",
        "# - Same embedding_model (OpenAI text-embedding-3-small) for vector similarity\n",
        "# - Same chat_prompt and openai_chat_model (gpt-4.1-nano) for generation\n",
        "# - Same StrOutputParser for response formatting\n",
        "enhanced_graph_builder = StateGraph(EnhancedState)\n",
        "\n",
        "# Add all nodes\n",
        "enhanced_graph_builder.add_node(\"enhanced_retrieve\", enhanced_retrieve)\n",
        "enhanced_graph_builder.add_node(\"fallback_response\", fallback_response)\n",
        "enhanced_graph_builder.add_node(\"enhanced_generate\", enhanced_generate)\n",
        "enhanced_graph_builder.add_node(\"fact_check\", fact_check)\n",
        "enhanced_graph_builder.add_node(\"finalize_response\", finalize_response)\n",
        "\n",
        "# Add edges with conditional routing\n",
        "enhanced_graph_builder.add_edge(START, \"enhanced_retrieve\")\n",
        "\n",
        "# Route based on context quality\n",
        "enhanced_graph_builder.add_conditional_edges(\n",
        "    \"enhanced_retrieve\",\n",
        "    route_based_on_context_quality,\n",
        "    {\n",
        "        \"generate\": \"enhanced_generate\",  # Logical \"generate\" â†’ actual \"enhanced_generate\" node\n",
        "        \"fallback\": \"fallback_response\"  # Logical \"fallback\" â†’ actual \"fallback_response\" node\n",
        "    }\n",
        ")\n",
        "\n",
        "# Route based on fact-checking needs\n",
        "enhanced_graph_builder.add_conditional_edges(\n",
        "    \"enhanced_generate\",\n",
        "    route_fact_check,\n",
        "    {\n",
        "        \"fact_check\": \"fact_check\",  # Logical \"fact_check\" â†’ actual \"fact_check\" node\n",
        "        \"finalize\": \"finalize_response\"  # Logical \"finalize\" â†’ actual \"finalize_response\" node\n",
        "    }\n",
        ")\n",
        "\n",
        "# Connect fact-check to finalize\n",
        "enhanced_graph_builder.add_edge(\"fact_check\", \"finalize_response\")\n",
        "\n",
        "# Both fallback and finalize go to END\n",
        "enhanced_graph_builder.add_edge(\"fallback_response\", END)\n",
        "enhanced_graph_builder.add_edge(\"finalize_response\", END)\n",
        "\n",
        "# Compile the enhanced graph\n",
        "enhanced_graph = enhanced_graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 10. Visualizing the Enhanced Graph\n",
        "\n",
        "Let's visualize our enhanced graph to see the conditional routing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x11cf6f410>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualize the enhanced graph\n",
        "enhanced_graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 11. Testing the Enhanced Graph\n",
        "\n",
        "Let's test our enhanced graph with different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 1: Normal Query ===\n",
            "Response: The maximum loan amount for undergraduate students is $31,000 in total, with no more than $23,000 of this amount being subsidized loans.\n",
            "\n",
            "*Note: Please verify this information with official sources as my confidence in this response is limited.*\n",
            "\n",
            "*Fact-check note: INACCURATE: The response contains incorrect information about the maximum loan amounts for undergraduate students. Specifically, it states that \"The maximum loan amount for undergraduate students is $31,000 in total, with no more than $23,000 of this amount being subsidized loans.\" \n",
            "\n",
            "Based on the provided context, the correct figures are:\n",
            "- For dependent undergraduate students, the **aggregate limit** is **$31,000** total (subsidized and unsubsidized combined), with **no more than $23,000** being subsidized.  \n",
            "- For annual loan limits, the **combined annual limit** for dependent undergraduates is **$5,500 to $7,500** (depending on the year in school), with **up to $3,500** of that in subsidized loans for the first year.  \n",
            "- For independent undergraduates, the annual limits are higher â€” **$9,500 to $12,500** annually, with a maximum of **$5,500 to $7,500** in subsidized loans (depending on the year).  \n",
            "\n",
            "The total aggregate limit for undergraduate students (dependent or independent) is **$31,000**, with **no more than $23,000** subsidized. The total amount, including unsubsidized loans, can reach up to **$57,500** for independent undergraduates over their lifetime, but this is separate from the undergraduate aggregate limit.\n",
            "\n",
            "Therefore, the original response incorrectly states the maximum loan amount as \"$31,000 in total\" with \"$23,000 of this being subsidized,\" which oversimplifies the actual limits and misunderstanding the annual limits and context.*\n",
            "Confidence: 0.2\n",
            "Context Quality: 0.4927267299921374\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Normal query with good context\n",
        "print(\"=== Test 1: Normal Query ===\")\n",
        "response1 = enhanced_graph.invoke({\n",
        "    \"question\": \"What is the maximum loan amount for undergraduate students?\"\n",
        "})\n",
        "print(f\"Response: {response1['response']}\")\n",
        "print(f\"Confidence: {response1.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Context Quality: {response1.get('context_quality', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 2: Irrelevant Query ===\n",
            "Response: I don't know.\n",
            "Confidence: 0.9\n",
            "Context Quality: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Query with no relevant context (should trigger fallback)\n",
        "print(\"=== Test 2: Irrelevant Query ===\")\n",
        "response2 = enhanced_graph.invoke({\n",
        "    \"question\": \"What is the recipe for chocolate cake?\"\n",
        "})\n",
        "print(f\"Response: {response2['response']}\")\n",
        "print(f\"Confidence: {response2.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Context Quality: {response2.get('context_quality', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 3: Query with Specific Numbers ===\n",
            "Response: A dependent undergraduate student can borrow up to $5,500 in their first year. Of this amount, no more than $3,500 may be subsidized.\n",
            "\n",
            "*Note: Please verify this information with official sources as my confidence in this response is limited.*\n",
            "\n",
            "*Fact-check note: INACCURATE: The response underestimates the first-year dependent undergraduate borrowing limit. The correct maximum amount a dependent undergraduate student can borrow in their first year is up to **$5,500**, with no more than **$3,500** of that amount being subsidized. The response states \"A dependent undergraduate student can borrow up to $5,500 in their first year. Of this amount, no more than $3,500 may be subsidized,\" which is correct.\n",
            "\n",
            "**However**, the explanation implies that a dependent student can only borrow $3,500 in subsidized loans in their first year, but they may also borrow an additional amount in unsubsidized loans to reach the total $5,500 limit. The core factual information in the response about the first-year limits ($5,500 total, $3,500 subsidized maximum) is accurate.\n",
            "\n",
            "**Summary:** The initial statement about the first-year borrowing limit for a dependent undergraduate student is correct. The explanation provided aligns with federal loan limits.\n",
            "\n",
            "**Final conclusion:** ACCURATE: The response is factually correct.*\n",
            "Confidence: 0.2\n",
            "Needs Fact Check: True\n",
            "Fact Check Result: INACCURATE: The response underestimates the first-year dependent undergraduate borrowing limit. The correct maximum amount a dependent undergraduate student can borrow in their first year is up to **$5,500**, with no more than **$3,500** of that amount being subsidized. The response states \"A dependent undergraduate student can borrow up to $5,500 in their first year. Of this amount, no more than $3,500 may be subsidized,\" which is correct.\n",
            "\n",
            "**However**, the explanation implies that a dependent student can only borrow $3,500 in subsidized loans in their first year, but they may also borrow an additional amount in unsubsidized loans to reach the total $5,500 limit. The core factual information in the response about the first-year limits ($5,500 total, $3,500 subsidized maximum) is accurate.\n",
            "\n",
            "**Summary:** The initial statement about the first-year borrowing limit for a dependent undergraduate student is correct. The explanation provided aligns with federal loan limits.\n",
            "\n",
            "**Final conclusion:** ACCURATE: The response is factually correct.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Query that might need fact-checking (contains numbers)\n",
        "print(\"=== Test 3: Query with Specific Numbers ===\")\n",
        "response3 = enhanced_graph.invoke({\n",
        "    \"question\": \"How much money can a dependent undergraduate student borrow in their first year?\"\n",
        "})\n",
        "print(f\"Response: {response3['response']}\")\n",
        "print(f\"Confidence: {response3.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Needs Fact Check: {response3.get('needs_fact_check', 'N/A')}\")\n",
        "print(f\"Fact Check Result: {response3.get('fact_check_result', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 12. Summary of Edge Case Handling\n",
        "\n",
        "This enhanced implementation addresses the key edge cases in the following ways:\n",
        "\n",
        "#### **No Relevant Context Found:**\n",
        "- **Detection**: The `enhanced_retrieve` node assesses context quality using content length and term overlap heuristics\n",
        "- **Routing**: The `route_based_on_context_quality` function routes to fallback when quality is below threshold\n",
        "- **Response**: The `fallback_response` node provides helpful guidance to users when no relevant context is found\n",
        "\n",
        "#### **Fact-Checking Requirements:**\n",
        "- **Detection**: The `enhanced_generate` node identifies responses that may need fact-checking based on numerical content\n",
        "- **Routing**: The `route_fact_check` function determines whether to proceed with fact-checking\n",
        "- **Verification**: The `fact_check` node performs additional verification using the context\n",
        "- **Integration**: Fact-check results are integrated into the final response with appropriate confidence adjustments\n",
        "\n",
        "#### **Additional Benefits:**\n",
        "- **Confidence Scoring**: Each response includes a confidence score that reflects the system's certainty\n",
        "- **Transparent Limitations**: Users are informed when confidence is low or when fact-checking reveals issues\n",
        "- **Graceful Degradation**: The system provides helpful fallbacks rather than failing silently\n",
        "\n",
        "This approach demonstrates how LangGraph's conditional routing capabilities enable sophisticated error handling and quality assurance in RAG applications, making them more robust and user-friendly in production environments.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
