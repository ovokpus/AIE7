{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47eTBHYNP4g1"
      },
      "source": [
        "# Introduction to LCEL and LangGraph: LangChain Powered RAG\n",
        "\n",
        "In the following notebook we're going to focus on learning how to navigate and build useful applications using LangChain, specifically LCEL, and how to integrate different APIs together into a coherent RAG application!\n",
        "\n",
        "In the notebook, you'll complete the following Tasks:\n",
        "\n",
        "- 🤝 Breakout Room #1:\n",
        "  1. Install LangGraph\n",
        "  2. Understanding States and Nodes\n",
        "  3. Building a Basic Graph\n",
        "  4. Implementing a Simple RAG Graph\n",
        "  5. Extending the Graph with Complex Flows\n",
        "\n",
        "Let's get started!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ayVXHXHRE_t"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHd6POM0JFN"
      },
      "source": [
        "## Installing Required Libraries\n",
        "\n",
        "We'll start by grabbing all of our LangChain related packages!\n",
        "\n",
        "> NOTE: DO NOT RUN THIS CELL IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCC2AR-Q0m0x",
        "outputId": "cbd49ab6-f2fb-420c-e64c-e656ad21524e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU \"langgraph>=0.5.0\", \"langsmith>=0.4.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6wTp9C5qbY"
      },
      "source": [
        "## Set Environment Variables\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs - so we'll set our `OPENAI_API_KEY` `env` variable here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pKAfycq73wE",
        "outputId": "0b5702c2-028b-4bf4-ae8a-fffe243574a7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsujAkpRWpJ"
      },
      "source": [
        "### A Note On Runnables\n",
        "\n",
        "# Understanding LangChain Runnables and LCEL\n",
        "\n",
        "In LangChain, a Runnable is like a LEGO brick in your AI application - it's a standardized component that can be easily connected with other components. The real power of Runnables comes from their ability to be combined in flexible ways using LCEL (LangChain Expression Language).\n",
        "\n",
        "## Key Features of Runnables\n",
        "\n",
        "### 1. Universal Interface\n",
        "Every Runnable in LangChain follows the same pattern:\n",
        "- Takes an input\n",
        "- Performs some operation\n",
        "- Returns an output\n",
        "\n",
        "This consistency means you can treat different components (like models, retrievers, or parsers) in the same way.\n",
        "\n",
        "### 2. Built-in Parallelization\n",
        "Runnables come with methods for handling multiple inputs efficiently:\n",
        "```python\n",
        "# Process inputs in parallel, maintain order\n",
        "results = chain.batch([input1, input2, input3])\n",
        "\n",
        "# Process inputs as they complete\n",
        "for result in chain.batch_as_completed([input1, input2, input3]):\n",
        "    print(result)\n",
        "```\n",
        "\n",
        "### 3. Streaming Support\n",
        "Perfect for responsive applications:\n",
        "```python\n",
        "# Stream outputs as they're generated\n",
        "for chunk in chain.stream({\"query\": \"Tell me a story\"}):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "```\n",
        "\n",
        "### 4. Easy Composition\n",
        "The `|` operator makes building pipelines intuitive:\n",
        "```python\n",
        "# Create a basic RAG chain\n",
        "rag_chain = retriever | prompt | model | output_parser\n",
        "```\n",
        "\n",
        "## Common Types of Runnables\n",
        "\n",
        "- **Language Models**: Like our `ChatOpenAI` instance\n",
        "- **Prompt Templates**: Format inputs consistently\n",
        "- **Retrievers**: Get relevant context from a vector store\n",
        "- **Output Parsers**: Structure model outputs\n",
        "- **LangGraph Nodes**: Individual components in our graph\n",
        "\n",
        "Think of Runnables as the building blocks of your LLM application. Just like how you can combine LEGO bricks in countless ways, you can mix and match Runnables to create increasingly sophisticated applications!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaVlJiilDzwM"
      },
      "source": [
        "## LangGraph Based RAG\n",
        "\n",
        "Now that we have a reasonable grasp of LCEL and the idea of Runnables - let's see how we can use LangGraph to build the same system!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77-NKo1EowG"
      },
      "source": [
        "### Primer: What is LangGraph?\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "#### Why Cycles?\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "#### Why LangGraph?\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!\n",
        "\n",
        "> NOTE: We're going to focus on building a simple DAG for today's assignment as an introduction to LangGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfLCnMXNE_Qc"
      },
      "source": [
        "### Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "> coordinated multi-actor and stateful applications\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "However, in our example here, we're focusing on a simpler `State` object:\n",
        "\n",
        "```python\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: list[Document]\n",
        "    response: str\n",
        "```\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. **We initialize our state object**:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "2. **Our user submits a query to our application.**  \n",
        "   We store the user's question in `state[\"question\"]`. Now we have:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [],\n",
        "       \"response\": \"\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "3. **We pass our state object to an Agent node** which is able to read the current state. It will use the value of `state[\"question\"]` as input and might retrieve some context documents related to the question. It then generates a response which it stores in `state[\"response\"]`. For example:\n",
        "   ```python\n",
        "   {\n",
        "       \"question\": \"How tall is the Eiffel Tower?\",\n",
        "       \"context\": [Document(page_content=\"...some data...\")],\n",
        "       \"response\": \"The Eiffel Tower is about 324 meters tall...\"\n",
        "   }\n",
        "   ```\n",
        "\n",
        "That's it! The important part is that we have a consistent object (`State`) that's passed around, holding the crucial information as we go from one node to the next. This ensures our application has a single source of truth about what has happened so far and what is happening now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kxczzsfVFNWT"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: list[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l6xFY0_HoXG"
      },
      "source": [
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL Runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keL9O1drInw1"
      },
      "source": [
        "### Building Nodes\n",
        "\n",
        "We're going to need two nodes:\n",
        "\n",
        "A node for retrieval, and a node for generation.\n",
        "\n",
        "Let's start with our `retrieve` node!\n",
        "\n",
        "Notice how we do not need to update the state object in the node, but can instead return a modification directly to our state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Building a Retriever with LangChain\n",
        "\n",
        "In order to build our `retrieve` node, we'll first need to build a retriever!\n",
        "\n",
        "This will involve the following steps: \n",
        "\n",
        "1. Ingesting Data\n",
        "2. Chunking the Data\n",
        "3. Vectorizing the Data and Storing it in a Vector Database\n",
        "4. Converting it to a Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Retreiver Step 1: Ingesting Data\n",
        "\n",
        "In today's lesson, we're going to be building a RAG system to answer questions about loan complaints - and we will pull information into our index (vectorized chunks stored in our vector store) through LangChain's [`CSVLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> NOTE: We'll be using an async loader during our document ingesting - but our Jupyter Kernel is already running in an asyc loop! This means we'll want the ability to *nest* async loops. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we're good to load our documents through the [`PyMuPDFLoader`](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "\n",
        "loan_knowledge_resources = directory_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Volume 3\\nAcademic Calendars, Cost of Attendance, and\\nPackaging\\nIntroduction\\nThis volume of the Federal Student Aid (FSA) Handbook discusses the academic calendar, payment period, and\\ndisbursement requirements for awarding aid under the Title IV student financial aid programs, determining a student9s\\ncost of attendance, and packaging Title IV aid.\\nThroughout this volume of the Handbook, the words \"we,\" \"our,\" and \"us\" refer to the United States Department of\\nEducation (the Department). The word \"you\" refers to the primary audience of the Handbook, school financial aid\\nadministrators. In other volumes of the Handbook we use \"institution,\" \"school,\" and \"college\" interchangeably, unless a\\nmore specific meaning is provided. In this volume we consistently use the term \"school.\" <HEA= refers to the Higher\\nEducation Act of 1965, as amended. Title IV refers to the student financial aid programs authorized under Title IV of the\\nHEA.\\nWe appreciate any comments that you have on this volume as wel'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_knowledge_resources[0].page_content[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TextSplitting aka Chunking\n",
        "\n",
        "We'll use the `RecursiveCharacterTextSplitter` to create our toy example.\n",
        "\n",
        "It will split based on the following rules:\n",
        "\n",
        "- Each chunk has a maximum size of 1000 tokens\n",
        "- It will try and split first on the `\\n\\n` character, then on the `\\n`, then on the `<SPACE>` character, and finally it will split on individual tokens.\n",
        "\n",
        "Let's implement it and see the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "loan_knowledge_chunks = text_splitter.split_documents(loan_knowledge_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 🏗️ Activity #1:\n",
        "\n",
        "While there's nothing specifically wrong with the chunking method used above - it is a naive approach that is not sensitive to specific data formats.\n",
        "\n",
        "Brainstorm some ideas that would split large single documents into smaller documents.\n",
        "\n",
        "#### ✅ Answer:\n",
        "\n",
        "## Sophisticated Document Chunking Strategies\n",
        "See [ACTIVITIES_QUESTIONS](./ACTIVITIES_QUESTIONS.md) for detailed code snippet examples\n",
        "\n",
        "### 1. **Semantic Boundary Chunking**\n",
        "\n",
        "This approach uses natural language processing to identify logical content boundaries, ensuring chunks maintain semantic coherence. Instead of splitting at arbitrary character counts, it identifies topic transitions, paragraph breaks, and section headers.\n",
        "\n",
        "**Process:**\n",
        "- Parse document structure (headers, paragraphs, sections)\n",
        "- Use sentence tokenization to identify natural breakpoints\n",
        "- Apply sliding window with overlap to maintain context\n",
        "- Validate chunk size constraints while preserving meaning\n",
        "\n",
        "### 2. **Hierarchical Structure-Aware Chunking**\n",
        "\n",
        "This method leverages document structure (tables, lists, code blocks, headers) to create chunks that respect the document's logical organization. It's particularly effective for technical documentation and structured content.\n",
        "\n",
        "**Process:**\n",
        "- Parse markdown/HTML structure to identify elements\n",
        "- Group related elements (tables with captions, code with explanations)\n",
        "- Maintain parent-child relationships in metadata\n",
        "- Create variable-sized chunks based on content type\n",
        "\n",
        "\n",
        "### 3. **Token-Optimized Sliding Window Chunking**\n",
        "\n",
        "This strategy optimizes for LLM token limits while maintaining context continuity. It uses actual tokenization to ensure precise token counts and implements intelligent overlap strategies.\n",
        "\n",
        "**Process:**\n",
        "- Use model-specific tokenizer for accurate token counting\n",
        "- Implement sliding window with contextual overlap\n",
        "- Preserve sentence boundaries within token constraints\n",
        "- Add metadata for chunk relationships and context\n",
        "\n",
        "\n",
        "### 4. **Embedding-Based Semantic Clustering Chunking**\n",
        "\n",
        "This advanced strategy uses vector embeddings to group semantically related content, even when it's not physically adjacent. It creates more coherent chunks by understanding content similarity at a deeper level than simple text analysis.\n",
        "\n",
        "**Process:**\n",
        "- Generate embeddings for sentences/paragraphs using sentence transformers\n",
        "- Apply clustering algorithms (K-means, DBSCAN) to group similar content\n",
        "- Create chunks from clusters while respecting size constraints\n",
        "- Maintain topic coherence across non-contiguous text sections\n",
        "\n",
        "\n",
        "### 5. **Multi-Modal Content-Type Aware Chunking**\n",
        "\n",
        "This sophisticated approach recognizes different content types (code blocks, tables, lists, prose) and applies specialized chunking strategies for each, maintaining the integrity of structured content while optimizing for downstream processing.\n",
        "\n",
        "**Process:**\n",
        "- Parse and classify content blocks by type (markdown, code, tables, etc.)\n",
        "- Apply type-specific chunking rules and size constraints\n",
        "- Maintain content relationships and dependencies\n",
        "- Create unified metadata schema across content types\n",
        "\n",
        "### 6. **Dependency-Aware Graph-Based Chunking**\n",
        "\n",
        "This cutting-edge approach models document content as a knowledge graph, identifying relationships and dependencies between concepts to create chunks that maintain logical coherence and reference integrity.\n",
        "\n",
        "**Process:**\n",
        "- Extract entities and relationships using NLP (spaCy, Stanford NER)\n",
        "- Build directed graph of content dependencies and references\n",
        "- Apply graph clustering algorithms to identify cohesive subgraphs\n",
        "- Generate chunks that preserve critical relationships and minimize broken references\n",
        "\n",
        "\n",
        "These sophisticated strategies leverage machine learning, graph theory, and advanced NLP to create more intelligent chunking that preserves semantic meaning, content structure, and logical relationships across document boundaries. Each strategy addresses different use cases: semantic chunking for general text processing, structure-aware for technical docs, and token-optimized for LLM applications. The choice depends on your document types and downstream processing requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Embeddings and Dense Vector Search\n",
        "\n",
        "Now that we have our individual chunks, we need a system to correctly select the relevant pieces of information to answer our query.\n",
        "\n",
        "This sounds like a perfect job for embeddings!\n",
        "\n",
        "We'll be using OpenAI's `text-embedding-3` model as our embedding model today!\n",
        "\n",
        "Let's load it up through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "What is the embedding dimension, given that we're using `text-embedding-3-small`?\n",
        "\n",
        "You will need to fill the next cell out correctly with your embedding dimension for the rest of the notebook to run.\n",
        "\n",
        "> HINT: Check out the docs to help you answer this question.\n",
        "\n",
        "#### ✅ Answer:\n",
        "\n",
        "Based on the OpenAI documentation and search results, **`text-embedding-3-small` has a default embedding dimension of 1536**.\n",
        "\n",
        "Key details about the dimensions:\n",
        "\n",
        "- **Default dimensions**: 1536 (same as the previous `text-embedding-ada-002` model)\n",
        "- **Configurable dimensions**: Can be shortened to as few as 512 dimensions using the `dimensions` parameter\n",
        "- **Flexible sizing**: You can specify any dimension size between 512 and 1536 without losing the concept-representing properties\n",
        "\n",
        "The model creates embeddings with 1536 dimensions by default, but OpenAI implemented Matryoshka Representation Learning (MRL) which allows you to truncate the embeddings to smaller sizes while maintaining most of the semantic quality.\n",
        "\n",
        "This is particularly useful for:\n",
        "\n",
        "- **Cost optimization**: Smaller dimensions = lower storage costs in vector databases\n",
        "- **Performance tuning**: Balance between accuracy and computational efficiency  \n",
        "- **Infrastructure constraints**: Some vector stores have dimension limits\n",
        "\n",
        "For example, in your chunking pipeline, you could use:\n",
        "\n",
        "```python\n",
        "# Full dimensions (1536)\n",
        "response = openai.embeddings.create(\n",
        "    input=chunks,\n",
        "    model=\"text-embedding-3-small\"\n",
        ")\n",
        "\n",
        "# Reduced dimensions (512) for cost savings\n",
        "response = openai.embeddings.create(\n",
        "    input=chunks,\n",
        "    model=\"text-embedding-3-small\",\n",
        "    dimensions=512\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim =  1536"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Using A Vector Database - Intoduction to Qdrant\n",
        "\n",
        "Up to this point, we've been using a dictionary to hold our embeddings - typically, we'll want to use a more robust strategy.\n",
        "\n",
        "In this bootcamp - we'll be focusing on leveraging [Qdrant's vector database](https://qdrant.tech/qdrant-vector-database/).\n",
        "\n",
        "Let's take a look at how we set-up Qdrant!\n",
        "\n",
        "> NOTE: We'll be spending a lot of time learning about Qdrant throughout the remainder of our time together - but for an initial primer, please check out [this resource](https://qdrant.tech/articles/what-is-a-vector-database/)\n",
        "\n",
        "We are going to be using an \"in-memory\" Qdrant client, which means that our vectors will be held in our system's memory (RAM) - this is useful for prototyping and developement at smaller scales - but would need to be modified when moving to production. Luckily for us, this modification is trivial!\n",
        "\n",
        "> NOTE: While LangChain uses the terminology \"VectorStore\" (also known as a Vector Library), Qdrant is a \"Vector Database\" - more info. on that [here.](https://weaviate.io/blog/vector-library-vs-vector-database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to create a collection - a collection is a specific...collection of vectors within the Qdrant client.\n",
        "\n",
        "These are useful as they allow us to create multiple different \"warehouses\" in a single client, which can be leveraged for personalization and more!\n",
        "\n",
        "Also notice that we define what our vector shapes are (embedding dim) as well as our desired distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.create_collection(\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    vectors_config=VectorParams(size=embedding_dim, distance=Distance.COSINE),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can assemble our vector database! Notice that we provide our client, our created collection, and our embedding model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"loan_knowledge_index\",\n",
        "    embedding=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have our vector database set-up, we can add our documents into it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=loan_knowledge_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "Now that we have an idea of how we're getting our most relevant information - let's see how we could create a pipeline that would automatically extract the closest chunk to our query and use it as context for our prompt!\n",
        "\n",
        "This will involve a popular LangChain interace known as `as_retriever`!\n",
        "\n",
        "> NOTE: We can still specify how many documents we wish to retrieve per vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 25, '_id': 'f18bc670e812446881cd978f20e47f33', '_collection_name': 'loan_knowledge_index'}, page_content='hour, or non-SE9W nonstandard term program is offered in modules, the minimum loan period is still the lesser of the\\nacademic year or the program length (or remaining portion of the program).\\nFor Title IV aid purposes, students are allowed to skip one or more modules. However, if a loan period includes modules\\nthat the student does not attend, the COA for the loan period may not include costs associated with those modules.\\nMinimum Loan Period: Standard Term Combined With an Intersession\\nAs we explain under <Intersessions= in Volume 3, Chapter 1, in limited cases for academic programs offered in standard\\nterms, a short nonstandard term (often called an <intersession=) may be combined with a preceding or following standard\\nterm and considered to be a single standard term. In such cases, the minimum loan period for a Direct Loan is different\\ndepending on whether a student attends the intersession. If a student who attends the intersession requests a loan for the\\ncombined term, the loan period includes the standard term plus the intersession. However, if the student attends only the\\nstandard term and is not enrolled in the intersession that is attached to that term, the loan period includes only the\\nstandard term.\\nMaximum Loan Periods\\nThe maximum period for which you may originate a Direct Loan is generally an academic year. However, if your school\\napplies the annual loan limit for Direct Subsidized Loans and Direct Unsubsidized Loans to a period of time greater than\\nan academic year, you may originate a Direct Loan for that longer period of time. For example, a school might offer an\\n1100 clock-hour program and define the academic year as 900 clock hours but could choose to allow students to receive\\njust one annual loan limit for the entire 1100-hour program. In that case, the loan period would correspond to the length\\nof the program, a period of time that is longer than the academic year.\\nDirect Loan Disbursement Requirements\\nFor general guidance on the timing of disbursements made under the Title IV programs, see Volume 3, Chapter 1. For\\nguidance on reporting Title IV program disbursements through the COD System and the rules for making early\\ndisbursements, late disbursements, and retroactive payments, see Volume 4, Chapter 2. In this section we discuss certain\\nother disbursement requirements that are specific to the Direct Loan Program.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal Direct Loan disbursement\\nrequirements that apply when periods of clinical work are included in a standard term.\\nRequirement for Substantially Equal Disbursements\\nDirect Loans must be disbursed in substantially equal installments, regardless of any difference in costs for different\\npayment periods that are within the same loan period, and no Direct Loan disbursement may exceed one-half of the loan\\nMaximum Loan Period\\n34 CFR 685.301(a)(10)(iv)\\nDetermining Direct Loan Disbursement Dates and Amounts\\n34 CFR 685.303(d)'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 23, '_id': '46a902856edf478e8e9dc850f3172d26', '_collection_name': 'loan_knowledge_index'}, page_content='period are separated by one or more terms in which the student is ineligible. For example, if a student is expected to be\\nenrolled on at least a half-time basis in the fall and spring quarters of an academic year consisting of the fall, winter, and\\nspring quarters, but the student indicates that they do not plan to attend the winter quarter (or that they plan to be\\nenrolled on a less than half-time basis during that quarter), the school may still originate a loan for a loan period covering\\nthe fall, winter, and spring quarters. Of course, no costs associated with winter quarter may be included in the student9s\\nCOA when determining the loan amount the student is eligible to receive for the fall and spring quarters. Similarly, if a\\nschool initially originates a loan for a fall-winter-spring loan period based on a student9s anticipated enrollment status of\\nat least half time during all three quarters, but the student subsequently does not attend the winter quarter or temporarily\\ndrops below half-time status for that term, and then resumes at least half-time enrollment in the spring, the school is not\\nrequired to make any changes to the original fall-winter-spring loan period. However, it may be necessary for the school\\nto adjust the originally approved loan amount if that amount is no longer supported by the reduced costs for the fall and\\nspring quarters only.\\nIn the first scenario described above the school could also choose to originate two separate loans for fall-only and spring-\\nonly loan periods. In the second scenario the school would also have the option of adjusting the original fall-winter-spring\\nloan period to fall-only, and then originating a new spring-only loan. Note, however, that in both cases the school would\\nthen be required to separately subtract the student9s full SAI from the fall-only and spring-only costs when determining\\nthe student9s Direct Subsidized Loan eligibility for those terms (see <No Alternate SAI When Originating Loans for Periods\\nOther Than Nine Months= earlier in this chapter). In some cases this could significantly reduce or even eliminate a\\nstudent9s need for Direct Subsidized Loans. In contrast, using a fall-winter-spring loan period (excluding all costs\\nassociated with the winter quarter) would allow the school to subtract the full SAI from the higher combined costs for the\\nfall and spring terms, partially mitigating the effect of not having alternate SAIs for periods of enrollment other than nine\\nmonths.\\nThe limited exception described above applies only if a student is eligible to receive a Direct Loan during the first and last\\nterms within the loan period. The term in which the student is ineligible cannot be the first or last term in the loan period.\\nFor instance, a school may not originate a loan for a fall-winter-spring loan period if the student does not attend the fall\\nterm or the spring term.\\nNote: See the guidance at the end of this chapter for certain exceptions to the normal loan period rules that apply when\\nperiods of clinical work are included in a standard term.\\nMinimum Loan Periods\\nThe minimum period for which a school may originate a Direct Loan varies depending on the school9s academic calendar.\\nAs explained below and in Chapter 7, different rules apply for purposes of determining the minimum loan period for a\\nDirect Loan and the type of academic year that a school may use to monitor Direct Loan annual loan limits depending on\\nwhether a program is term-based (including subscription-based programs; see Volume 3, Chapter 1) with either standard'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 22, '_id': '460bcc8e71214469860a6f54650b5c3a', '_collection_name': 'loan_knowledge_index'}, page_content=\"or to prevent the total aid package from exceeding the student9s need.\\nAlthough a school isn9t required to return Direct Loan funds that were disbursed to the borrower (either directly or by\\napplying them to the student's account) before the overaward situation occurred, the law doesn9t prevent your school\\nfrom returning funds that were applied to the student account if you choose to do so. A borrower who receives a direct\\npayment of loan funds is not required to repay an overawarded amount, unless the overaward was caused by the\\nborrower9s misreporting or withholding of information.\\nLoan Periods\\nThe loan period (also referred to as the <period of enrollment=) is the period for which a Direct Loan is intended. It must\\ncoincide with an academic period established by the school for which institutional charges are generally assessed (e.g.,\\nsemester, trimester, quarter, length of the student9s program, or academic year). It9s important to define the loan period\\nat the beginning of the loan awarding process, because the timing and amount of Direct Loan disbursements are tied to\\nthe loan period.\\nGenerally, the loan period may not include terms in which a student is ineligible (for example, if the student is not enrolled\\nduring a particular term or is enrolled less than half time during a term). There is a limited exception to this rule if the loan\\nperiod begins and ends with a term in which the student is eligible for Direct Loans, but the first and last terms of the loan\"),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 24, '_id': '0af29552e3a3476a97b8d61e5c7552d9', '_collection_name': 'loan_knowledge_index'}, page_content='2. \\nNonstandard terms that are substantially equal, but one or more of the terms in the academic year\\ncontains fewer than nine weeks.\\nNon-\\nSE9W\\n3. \\nNonstandard terms that are not substantially equal in length (one or more of the terms in the academic\\nyear differs in length from another term by more than two weeks).\\nNon-\\nSE9W\\nWe refer to the first type of nonstandard term as <SE9W= nonstandard terms. We group the second and third types\\ntogether and refer to them as <non-SE9W= nonstandard terms.\\nPrograms with SE9W nonstandard terms are treated the same as standard-term programs for purposes of determining\\nminimum loan period length and monitoring annual loan limits. However, programs with non-SE9W nonstandard terms are\\ntreated the same as non-term programs for these purposes.\\nNote that substantially equal nonstandard terms (the first two types of nonstandard terms described above) are treated\\ndifferently for purposes of determining Direct Loan payment periods than for determining minimum loan period length\\nand monitoring annual loan limits. As explained in Volume 1, Chapter 1, if a program is offered in standard terms or in\\nnonstandard terms that are substantially equal in length (regardless of the length of the nonstandard term), the payment\\nperiod is the term.\\nHowever, for purposes of determining the minimum loan period for a Direct Loan and monitoring Direct Loan annual loan\\nlimits, substantially equal nonstandard terms that contain fewer than nine weeks are treated the same as nonstandard\\nterms that are not substantially equal. This means that if a program has substantially equal nonstandard terms that are\\nless than nine weeks in length, you must make a Direct Loan disbursement each term (the same as would be the case if\\nthe program were offered in standard terms), but the minimum loan period and the type of academic year used to\\nmonitor Direct Loan annual loan limits must be determined in accordance with the rules that apply to non-term programs.\\nFor detailed information on standard term, nonstandard term, and non-term programs, see Volume 1, Chapter 1.\\nMinimum Loan Period: Standard Term and SE9W Nonstandard Term Programs\\nFor credit-hour programs with standard terms (semesters, quarters, or trimesters), or with SE9W\\nnonstandard terms, the minimum loan period is a single academic term. For example, if a student will be enrolled in the\\nfall semester only and will skip the spring semester, you may originate a loan with a loan period that covers only the fall\\nterm.\\nMinimum Loan Period: Clock-Hour, Non-Term, and Non-SE9W Nonstandard Term Programs\\nFor all other programs (i.e., clock-hour, non-term, and non-SE9W nonstandard term programs), the minimum\\nloan period is generally the lesser of the program length (or remainder of the program, if there is less than full academic\\nyear remaining) or the academic year. There are exceptions to this minimum loan period rule when originating loans for\\ntransfer students, or for students who complete or otherwise cease enrollment in one program and then begin a different\\nprogram at the same school. We discuss these exceptions in detail in Chapter 7 of this volume.\\nMinimum Loan Period: Programs Offered in Modules\\nIf a program is offered in modules, this does not change the minimum loan period rules for Direct Loans. For example, if a\\nstandard or SE9W nonstandard term is divided into two or more modules, the minimum loan period for a Direct Loan is'),\n",
              " Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 70, '_id': 'ce037550bc6942d79228f644954a3468', '_collection_name': 'loan_knowledge_index'}, page_content='credit-hour program.) The loan period will be for the first full academic year of the new program (the period\\nduring which the student will be expected to complete 24 semester hours and 30 weeks of instructional time).')]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"What is the loan repayment period?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating the Node\n",
        "\n",
        "We're finally ready to create our node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "05qhncktIwK_"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Node\n",
        "\n",
        "Next, let's create our `generate` node - which will leverage LangChain and something called an \"LCEL Chain\" which you can read more about [here](https://python.langchain.com/docs/concepts/lcel/)!\n",
        "\n",
        "We'll want to create a chain that does the following: \n",
        "\n",
        "1. Formats our inputs into a chat template suitable for RAG\n",
        "2. Takes that chat template and sends it to an LLM\n",
        "3. Parses that output into `str` format\n",
        "\n",
        "Let's get chaining!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: RAG Chat Template\n",
        "\n",
        "We'll create a chat template that takes in some query and formats it as a RAG prompt using LangChain's prompt template!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context response with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n#CONTEXT:\\nOUR CONTEXT HERE\\n\\nQUERY:\\nOUR QUERY HERE\\n\\nUse the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it\\'s not contained in the provided context response with \"I don\\'t know\"\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt.invoke({\"context\" : \"OUR CONTEXT HERE\", \"query\" : \"OUR QUERY HERE\"}).messages[0].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Chain Components: Generator\n",
        "\n",
        "We'll next set-up the generator - which will be OpenAI's `gpt-4o-nano` for today!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now call our model with a formatted prompt.\n",
        "\n",
        "Notice that we have some nested calls here - we'll see that this is made easier by LCEL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 72, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BqRAcQ817ExllHTZSLp3V1CVh4uR7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6d8c4f8c-436f-49d9-b3e8-847600a65332-0', usage_metadata={'input_tokens': 72, 'output_tokens': 7, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai_chat_model.invoke(chat_prompt.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chain Components: `str` Parser\n",
        "\n",
        "Finally, let's set-up our `StrOutputParser()` which will transform our model's output into a simple `str` to be provided to the user.\n",
        "\n",
        "> NOTE: You can see us leveraging LCEL in the example below to avoid needing to do nested calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The capital of France is Paris.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "\n",
        "generator_chain.invoke({\"context\" : \"Paris is the capital of France\", \"query\" : \"What is the capital of France?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `generate` Node: \n",
        "\n",
        "Now we can create our `generate` Node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XiL2isC8JS0l"
      },
      "outputs": [],
      "source": [
        "def generate(state: State) -> State:\n",
        "  generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtriMEcJxeR"
      },
      "source": [
        "Now we can start defining our graph!\n",
        "\n",
        "Think of the graph's state as a blank canvas that we can add nodes and edges to.\n",
        "\n",
        "Every graph starts with two special nodes - START and END - the act as the entry and exit point to the other nodes in the graphs.  \n",
        "\n",
        "All valid graphs must start at the START node and end at the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ia9IWM9AJ4bx"
      },
      "outputs": [],
      "source": [
        "# Start with the blank canvas\n",
        "graph_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kro8bQEL2Yj"
      },
      "source": [
        "Now we can add a sequence to our \"canvas\" (graph) - this can be done by providing a list of nodes, the will automatically have edges that connect the i-th element to the i+1-th element in the list. The final element will be added to the END node unless otherwise specified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OSfDMlXUL2kh"
      },
      "outputs": [],
      "source": [
        "graph_builder = graph_builder.add_sequence([retrieve, generate])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g79NZf5VL4en"
      },
      "source": [
        "Next, let's connect our START node to our `retrieve` node by adding an edge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "w1kTJKGNL4qA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x160fda180>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder.add_edge(START, \"retrieve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EiVyt8-L6_5"
      },
      "source": [
        "Finally we can compile our graph! This will do basic verification to ensure that the Runnables have the correct inputs/outputs and can be matched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TM4My6geL7FW"
      },
      "outputs": [],
      "source": [
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvoQcfCP3xI"
      },
      "source": [
        "Finally, we can visualize our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x1610310a0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRCjvvyP8DA"
      },
      "source": [
        "Let's take it for a spin!\n",
        "\n",
        "We invoke our graph like we do any other Runnable in LCEL!\n",
        "\n",
        "> NOTE: That's right, even a compiled graph is a Runnable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mSbsRLurKOKd",
        "outputId": "114185f3-4b98-4c66-96cd-65f4e4e3ef1d"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Applying for and securing a student loan in 2025 is not necessarily a terrible idea based on the provided context. The documents mention that the application process for federal student aid, such as FAFSA, begins with deadlines starting October 1, 2024, and applications are accepted through June 30, 2026. It also outlines the importance of understanding loan limits, eligibility requirements, and counseling options to ensure responsible borrowing. While the context emphasizes careful consideration of aid and loan packaging, it does not directly state that obtaining a loan in 2025 is a bad idea. Therefore, whether it is a good or bad idea depends on individual circumstances and how the loans are managed, but no statement in the context labels it as \"terrible.\""
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "response = graph.invoke({\"question\" : \"Is applying for and securing a student loan in 2025 a terrible idea?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_jEmE_rKwED",
        "outputId": "c5fac807-2a24-4cf9-8cca-105def13e3d8"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, the maximum loan amounts a student may receive from the government depend on the specific program and circumstances:\n",
              "\n",
              "- For general programs at School B, the total loan amount may be up to $1,815, with no more than $1,155 of that being subsidized. If the student receives the maximum subsidized loan during an abbreviated period, there is no remaining eligibility afterward.\n",
              "\n",
              "- For dependent undergraduate students enrolled in a 900 clock-hour program, the combined annual loan limit (subsidized and unsubsidized) is $5,500, with no more than $3,500 subsidized.\n",
              "\n",
              "- The overall aggregate loan limits (including subsidized and unsubsidized) are also specified:\n",
              "  - For dependent undergraduates (excluding certain cases), up to $31,000 in total, with no more than $23,000 subsidized.\n",
              "  - For independent undergraduates, up to $57,500 total, with no more than $23,000 subsidized.\n",
              "  - For graduate and professional students, up to $138,500 total, with no more than $65,500 subsidized.\n",
              "\n",
              "There are proration rules applied if the program is shorter than an academic year, which can reduce the amount of loan money a student is eligible for. The school is responsible for adjusting disbursements if the maximum allowable loan amount is exceeded.\n",
              "\n",
              "Thus, there are caps on the total loan amounts students can borrow, determined by their program, year in school, and previous borrowing history."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"How much loan money can I actually get from the government to go to school these days? Is there a cap?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Based on the provided context, grants and scholarships available for free include Pell Grants, FSEOG (Federal Supplemental Educational Opportunity Grants), state grants, and scholarships that do not require future employment or other conditions requiring repayment."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"What grants and scholarships are available for free?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "I don't know"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"Who is Batman?\"})\n",
        "display(Markdown(response[\"response\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_LRYXvvRjOp"
      },
      "source": [
        "#### ❓ Question #2:\n",
        "LangGraph's graph-based approach lets us visualize and manage complex flows naturally. How could we extend our current implementation to handle edge cases? For example:\n",
        "- What if the retriever finds no relevant context?  \n",
        "- What if the response needs fact-checking?\n",
        "Consider how you would modify the graph to handle these scenarios.\n",
        "\n",
        "##### Solution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ✅ Answer:\n",
        "\n",
        "## Enhanced LangGraph RAG with Edge Case Handling\n",
        "\n",
        "To handle edge cases in our RAG system, we'll extend the graph with additional nodes and conditional routing. Here's how we can address the scenarios you mentioned:\n",
        "\n",
        "### 1. Enhanced State Definition\n",
        "\n",
        "First, let's extend our state to track additional information needed for edge case handling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Optional, Literal\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Enhanced State with edge case handling\n",
        "class EnhancedState(TypedDict):\n",
        "    question: str\n",
        "    context: list[Document]\n",
        "    response: str\n",
        "    context_quality: Optional[float]  # Score for context relevance\n",
        "    needs_fact_check: Optional[bool]  # Flag for fact-checking requirement\n",
        "    fact_check_result: Optional[str]  # Result of fact-checking\n",
        "    fallback_response: Optional[str]  # Response when no context found\n",
        "    confidence_score: Optional[float]  # Overall confidence in the response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 2. Enhanced Retrieval Node\n",
        "\n",
        "We'll modify the retrieval node to assess context quality and handle cases where no relevant context is found:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_retrieve(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Enhanced retrieval with context quality assessment using the same Qdrant vector store\"\"\"\n",
        "    \n",
        "    # Use the same retriever from the previous implementation\n",
        "    # This ensures we're using the same Qdrant vector database and embedding model\n",
        "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "    \n",
        "    # Assess context quality using similarity scores and content analysis\n",
        "    context_quality = 0.0\n",
        "    \n",
        "    if retrieved_docs:\n",
        "        # Enhanced quality assessment using the same similarity scoring approach\n",
        "        # Get similarity scores by performing a similarity search with scores\n",
        "        scored_docs = vector_store.similarity_search_with_score(\n",
        "            state[\"question\"], \n",
        "            k=5\n",
        "        )\n",
        "        \n",
        "        # Calculate context quality based on similarity scores\n",
        "        if scored_docs:\n",
        "            # Use the highest similarity score as base quality\n",
        "            # Note: Qdrant with cosine distance returns distance, not similarity\n",
        "            # So we convert distance to similarity (1 - distance)\n",
        "            max_similarity = 1 - min(score for _, score in scored_docs)\n",
        "            context_quality = max(0.0, max_similarity)\n",
        "            \n",
        "            # Boost quality if we have multiple good matches\n",
        "            good_matches = sum(1 for _, score in scored_docs if (1 - score) > 0.7)\n",
        "            if good_matches >= 2:\n",
        "                context_quality = min(1.0, context_quality + 0.2)\n",
        "        \n",
        "        # Additional quality check based on content relevance\n",
        "        question_terms = set(state[\"question\"].lower().split())\n",
        "        for doc in retrieved_docs:\n",
        "            doc_terms = set(doc.page_content.lower().split())\n",
        "            overlap = len(question_terms.intersection(doc_terms))\n",
        "            if overlap > 2:  # If more than 2 terms overlap, boost quality\n",
        "                context_quality = min(1.0, context_quality + 0.1)\n",
        "                break\n",
        "    \n",
        "    return {\n",
        "        \"context\": retrieved_docs,\n",
        "        \"context_quality\": context_quality\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 3. Context Quality Router\n",
        "\n",
        "This node decides whether to proceed with generation or provide a fallback response.\n",
        "\n",
        "**Note on LangGraph Best Practice:**\n",
        "Router functions should return the actual node names directly (like \"enhanced_generate\", \"fallback_response\"). This follows LangGraph conventions and avoids unnecessary mapping layers that can complicate debugging and maintenance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_based_on_context_quality(state: EnhancedState):\n",
        "    \"\"\"Route based on context quality assessment\"\"\"\n",
        "    \n",
        "    context_quality = state.get(\"context_quality\", 0.0)\n",
        "    context = state.get(\"context\", [])\n",
        "    \n",
        "    # If no context found or quality is too low, use fallback\n",
        "    if not context or context_quality < 0.3:\n",
        "        return \"fallback_response\"  # Direct node name - LangGraph best practice\n",
        "    else:\n",
        "        return \"enhanced_generate\"  # Direct node name - LangGraph best practice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 4. Fallback Response Node\n",
        "\n",
        "This node handles cases where no relevant context is found:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fallback_response(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Provide fallback response when no relevant context is found\"\"\"\n",
        "    \n",
        "    fallback_msg = (\"I apologize, but I couldn't find relevant information in my knowledge base \"\n",
        "                   \"to answer your question about student loans and financial aid. \"\n",
        "                   \"For the most accurate and up-to-date information, I recommend contacting \"\n",
        "                   \"your school's financial aid office or visiting studentaid.gov.\")\n",
        "    \n",
        "    return {\n",
        "        \"response\": fallback_msg,\n",
        "        \"fallback_response\": fallback_msg,\n",
        "        \"confidence_score\": 0.1\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 5. Enhanced Generation Node\n",
        "\n",
        "This node generates responses and determines if fact-checking is needed:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhanced_generate(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Enhanced generation with fact-checking assessment using the same chat prompt and model\"\"\"\n",
        "    \n",
        "    # Use the same generator chain from the previous implementation\n",
        "    # This ensures we're using the same chat_prompt and openai_chat_model\n",
        "    generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "    response = generator_chain.invoke({\n",
        "        \"query\": state[\"question\"], \n",
        "        \"context\": state[\"context\"]\n",
        "    })\n",
        "    \n",
        "    # Determine if fact-checking is needed based on content analysis\n",
        "    needs_fact_check = False\n",
        "    confidence_score = 0.8\n",
        "    \n",
        "    # Base confidence on context quality from retrieval\n",
        "    context_quality = state.get(\"context_quality\", 0.5)\n",
        "    confidence_score = max(0.3, min(0.9, context_quality))\n",
        "    \n",
        "    # Check for numerical values that might need verification\n",
        "    import re\n",
        "    if re.search(r'\\$[\\d,]+|\\d+%|\\d{4}', response):\n",
        "        needs_fact_check = True\n",
        "        confidence_score = max(0.4, confidence_score - 0.2)\n",
        "    \n",
        "    # Check for specific financial terms that need verification\n",
        "    financial_terms = ['loan limit', 'maximum', 'aggregate', 'annual', 'interest rate', 'cap']\n",
        "    if any(term in response.lower() for term in financial_terms):\n",
        "        needs_fact_check = True\n",
        "        confidence_score = max(0.5, confidence_score - 0.1)\n",
        "    \n",
        "    return {\n",
        "        \"response\": response,\n",
        "        \"needs_fact_check\": needs_fact_check,\n",
        "        \"confidence_score\": confidence_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 6. Fact-Checking Router\n",
        "\n",
        "This node determines whether to proceed with fact-checking or return the response:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def route_fact_check(state: EnhancedState):\n",
        "    \"\"\"Route to fact-checking if needed\"\"\"\n",
        "    \n",
        "    needs_fact_check = state.get(\"needs_fact_check\", False)\n",
        "    \n",
        "    if needs_fact_check:\n",
        "        return \"fact_check\"  # Direct node name - LangGraph best practice\n",
        "    else:\n",
        "        return \"finalize_response\"  # Direct node name - LangGraph best practice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 7. Fact-Checking Node\n",
        "\n",
        "This node performs fact-checking on the generated response:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fact_check(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Perform fact-checking on the generated response using the same OpenAI model\"\"\"\n",
        "    \n",
        "    # Create a fact-checking prompt\n",
        "    fact_check_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"human\", \"\"\"\n",
        "        Please fact-check the following response about student loans and financial aid:\n",
        "        \n",
        "        ORIGINAL QUESTION: {question}\n",
        "        \n",
        "        RESPONSE TO CHECK: {response}\n",
        "        \n",
        "        CONTEXT USED: {context}\n",
        "        \n",
        "        Please verify if the information in the response is accurate based on the context.\n",
        "        If you find any inaccuracies, please provide corrections.\n",
        "        Respond with either:\n",
        "        - \"ACCURATE: The response is factually correct.\"\n",
        "        - \"INACCURATE: [specific corrections needed]\"\n",
        "        \"\"\")\n",
        "    ])\n",
        "    \n",
        "    # Create fact-checking chain using the same openai_chat_model from previous implementation\n",
        "    fact_check_chain = fact_check_prompt | openai_chat_model | StrOutputParser()\n",
        "    \n",
        "    # Perform fact-checking\n",
        "    fact_check_result = fact_check_chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"response\": state[\"response\"],\n",
        "        \"context\": \"\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
        "    })\n",
        "    \n",
        "    # Update confidence based on fact-check result and context quality\n",
        "    confidence_score = state.get(\"confidence_score\", 0.6)\n",
        "    context_quality = state.get(\"context_quality\", 0.5)\n",
        "    \n",
        "    if fact_check_result.startswith(\"ACCURATE\"):\n",
        "        # Boost confidence if fact-check passes and context quality is good\n",
        "        confidence_boost = 0.2 if context_quality > 0.7 else 0.1\n",
        "        confidence_score = min(1.0, confidence_score + confidence_boost)\n",
        "    else:\n",
        "        # Reduce confidence if fact-check fails, but consider context quality\n",
        "        confidence_reduction = 0.3 if context_quality < 0.5 else 0.2\n",
        "        confidence_score = max(0.2, confidence_score - confidence_reduction)\n",
        "    \n",
        "    return {\n",
        "        \"fact_check_result\": fact_check_result,\n",
        "        \"confidence_score\": confidence_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 8. Response Finalization Node\n",
        "\n",
        "This node finalizes the response with confidence information:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def finalize_response(state: EnhancedState) -> EnhancedState:\n",
        "    \"\"\"Finalize the response with confidence and fact-check information\"\"\"\n",
        "    \n",
        "    response = state[\"response\"]\n",
        "    confidence_score = state.get(\"confidence_score\", 0.8)\n",
        "    fact_check_result = state.get(\"fact_check_result\", \"\")\n",
        "    \n",
        "    # Add confidence indicator to response if confidence is low\n",
        "    if confidence_score < 0.5:\n",
        "        response += \"\\n\\n*Note: Please verify this information with official sources as my confidence in this response is limited.*\"\n",
        "    \n",
        "    # Add fact-check information if available\n",
        "    if fact_check_result and fact_check_result.startswith(\"INACCURATE\"):\n",
        "        response += f\"\\n\\n*Fact-check note: {fact_check_result}*\"\n",
        "    \n",
        "    return {\n",
        "        \"response\": response\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 9. Building the Enhanced Graph\n",
        "\n",
        "Now let's build the enhanced graph with conditional routing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import END from langgraph\n",
        "from langgraph.graph import END\n",
        "\n",
        "# Build the enhanced graph using the same components from the previous implementation:\n",
        "# - Same Qdrant vector_store and retriever for document retrieval\n",
        "# - Same embedding_model (OpenAI text-embedding-3-small) for vector similarity\n",
        "# - Same chat_prompt and openai_chat_model (gpt-4.1-nano) for generation\n",
        "# - Same StrOutputParser for response formatting\n",
        "enhanced_graph_builder = StateGraph(EnhancedState)\n",
        "\n",
        "# Add all nodes\n",
        "enhanced_graph_builder.add_node(\"enhanced_retrieve\", enhanced_retrieve)\n",
        "enhanced_graph_builder.add_node(\"fallback_response\", fallback_response)\n",
        "enhanced_graph_builder.add_node(\"enhanced_generate\", enhanced_generate)\n",
        "enhanced_graph_builder.add_node(\"fact_check\", fact_check)\n",
        "enhanced_graph_builder.add_node(\"finalize_response\", finalize_response)\n",
        "\n",
        "# Add edges with conditional routing\n",
        "enhanced_graph_builder.add_edge(START, \"enhanced_retrieve\")\n",
        "\n",
        "# Route based on context quality - using direct node names (LangGraph best practice)\n",
        "enhanced_graph_builder.add_conditional_edges(\n",
        "    \"enhanced_retrieve\",\n",
        "    route_based_on_context_quality,\n",
        "    # No mapping needed when router returns direct node names\n",
        "    [\"enhanced_generate\", \"fallback_response\"]\n",
        ")\n",
        "\n",
        "# Route based on fact-checking needs - using direct node names (LangGraph best practice)\n",
        "enhanced_graph_builder.add_conditional_edges(\n",
        "    \"enhanced_generate\",\n",
        "    route_fact_check,\n",
        "    # No mapping needed when router returns direct node names\n",
        "    [\"fact_check\", \"finalize_response\"]\n",
        ")\n",
        "\n",
        "# Connect fact-check to finalize\n",
        "enhanced_graph_builder.add_edge(\"fact_check\", \"finalize_response\")\n",
        "\n",
        "# Both fallback and finalize go to END\n",
        "enhanced_graph_builder.add_edge(\"fallback_response\", END)\n",
        "enhanced_graph_builder.add_edge(\"finalize_response\", END)\n",
        "\n",
        "# Compile the enhanced graph\n",
        "enhanced_graph = enhanced_graph_builder.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 10. Visualizing the Enhanced Graph\n",
        "\n",
        "Let's visualize our enhanced graph to see the conditional routing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x14d658b90>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Visualize the enhanced graph\n",
        "enhanced_graph\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 11. Testing the Enhanced Graph\n",
        "\n",
        "Let's test our enhanced graph with different scenarios:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 1: Normal Query ===\n",
            "Response: The maximum loan amount for undergraduate students depends on their dependency status and the type of loans. \n",
            "\n",
            "- For dependent undergraduates (excluding those whose parents cannot get Direct PLUS Loans), the total (subsidized and unsubsidized) loan limit is $31,000, with no more than $23,000 of this amount in subsidized loans.\n",
            "- For independent undergraduates (and dependent undergraduates whose parents cannot get Direct PLUS Loans), the total limit is $57,500, with no more than $23,000 subsidized.\n",
            "- The annual loan limit for dependent undergraduates is $5,500 (no more than $3,500 of which may be subsidized), prorated if enrolled in a program shorter than an academic year.\n",
            "- The aggregate loan limit for undergraduate students is $23,000 in subsidized loans and $31,000 overall.\n",
            "\n",
            "These limits can be prorated if the program is shorter than an academic year.\n",
            "\n",
            "*Note: Please verify this information with official sources as my confidence in this response is limited.*\n",
            "\n",
            "*Fact-check note: INACCURATE: The response contains inaccuracies and some lack of clarity regarding the specific loan limits. Here are the corrections and clarifications:\n",
            "\n",
            "1. **Maximum Loan Amounts:**\n",
            "   - For **dependent undergraduate students**, the **total (subsidized + unsubsidized) loan limit** is **$31,000**. For **independent undergraduates**, it is **$57,500**.  \n",
            "   - **However**, these are **aggregate loan limits** over a student’s entire undergraduate career, **not** annual limits.  \n",
            "   - The **annual loan limit** for dependent undergraduates is **$5,500** in the first year, with no more than **$3,500** subsidized. In subsequent years, the annual limits increase (e.g., up to $6,500, then $7,500, etc., depending on the year of study), but the initial figures are for the first year.\n",
            "\n",
            "2. **Confusing or partly incorrect statements:**  \n",
            "   - The statement **\"The total (subsidized and unsubsidized) loan limit is $31,000, with no more than $23,000 of this amount in subsidized loans\"** is accurate as an **aggregate limit**, **not** an annual limit.  \n",
            "   - Similarly, **$57,500 total and $23,000 subsidized** are **aggregate limits** for independent undergraduates, **not** annual limits.  \n",
            "   - The mention of **\"annual loan limit for dependent undergraduates is $5,500 (no more than $3,500 of which may be subsidized)\"** is correct but *only* for the first year, and the limits vary for other years.\n",
            "\n",
            "3. **Prorated limits and program length:**  \n",
            "   - The response correctly notes that loan limits can be prorated for shorter programs but should specify that prorating involves multiplying the annual limit by the fractional length of the program relative to the full academic year.\n",
            "\n",
            "4. **Graduate and professional students:**  \n",
            "   - The mention of a **$138,500** aggregate limit for graduate and professional students **including undergraduate loans** is accurate.  \n",
            "   - The higher **annual limits for graduate/ professional students** are also true, but should specify that they are **unsubsidized only** and vary by program.\n",
            "\n",
            "5. **Clarification needed:**  \n",
            "   - The response should emphasize that the **$5,500** figure is the **first-year dependent undergraduate** annual loan limit, and higher limits apply in subsequent years (e.g., **$6,500, then $7,500**, and so on).  \n",
            "   - The initial figures cited (e.g., \"$31,000\" total) are **aggregate loan limits**, not annual.  \n",
            "   - The statement **\"The aggregate loan limit for undergraduate students is $23,000 in subsidized loans and $31,000 overall\"** is **correct**, but should clearly specify that these are **aggregate caps** over the undergraduate career.\n",
            "\n",
            "**Summary:**  \n",
            "The response mixes **annual** and **aggregate** loan limits, leading to potential confusion. It correctly states the **aggregate** limits but needs to clarify that the figures like **$5,500** are **annual limits for first-year students**, with higher limits in later years, and that the **$31,000** and **$57,500** are total aggregate caps over undergraduate studies.\n",
            "\n",
            "**Therefore, the overall assessment is:**  \n",
            "**\"INACCURATE: [specific corrections needed]\"***\n",
            "Confidence: 0.2\n",
            "Context Quality: 0.49706157203818446\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Normal query with good context\n",
        "print(\"=== Test 1: Normal Query ===\")\n",
        "response1 = enhanced_graph.invoke({\n",
        "    \"question\": \"What is the maximum loan amount for undergraduate students?\"\n",
        "})\n",
        "print(f\"Response: {response1['response']}\")\n",
        "print(f\"Confidence: {response1.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Context Quality: {response1.get('context_quality', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 2: Irrelevant Query ===\n",
            "Response: I don't know.\n",
            "Confidence: 0.9\n",
            "Context Quality: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Query with no relevant context (should trigger fallback)\n",
        "print(\"=== Test 2: Irrelevant Query ===\")\n",
        "response2 = enhanced_graph.invoke({\n",
        "    \"question\": \"What is the recipe for chocolate cake?\"\n",
        "})\n",
        "print(f\"Response: {response2['response']}\")\n",
        "print(f\"Confidence: {response2.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Context Quality: {response2.get('context_quality', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test 3: Query with Specific Numbers ===\n",
            "Response: A dependent undergraduate student can borrow up to $5,500 in their first year, with no more than $3,500 of this amount being subsidized.\n",
            "\n",
            "*Note: Please verify this information with official sources as my confidence in this response is limited.*\n",
            "\n",
            "*Fact-check note: INACCURATE: The response contains a key inaccuracy regarding the first-year borrowing limit for dependent undergraduate students. The correct statutory maximum for a dependent undergraduate student in their first year is up to **$5,500 total**, with **no more than $3,500 of this amount being subsidized**. The response correctly states the total limit but slightly confuses the description by implying a restriction that may be misunderstood.\n",
            "\n",
            "The main correction is clarifying that:\n",
            "- A dependent undergraduate first-year student can borrow **up to $5,500 in total**, with **no more than $3,500 subsidized**.\n",
            "- If the student has no subsidized eligibility, they may borrow up to the full $5,500 in unsubsidized loans.\n",
            "\n",
            "Additionally, while the context elaborates extensively on loan limits, prorating, and aggregate limits, the core answer to \"How much money can a dependent undergraduate student borrow in their first year?\" should generally be summarized as:\n",
            "\n",
            "**\"A dependent undergraduate student can borrow up to $5,500 in their first year, with no more than $3,500 of this being subsidized.\"**\n",
            "\n",
            "Everything else in the detailed context supports this, but the initial statement effectively captures the main fact.\n",
            "\n",
            "**Summary:** The original response's figure is correct, but it should explicitly state the maximum **$5,500** combined limit, not just $5,000, to reflect current federal loan limits accurately.\n",
            "\n",
            "**Final conclusion:**  \n",
            "**\"ACCURATE: The response is factually correct\"** with the understanding that it correctly states the first-year borrowing limit for dependent undergraduates as **up to $5,500 total, with no more than $3,500 subsidized.***\n",
            "Confidence: 0.2\n",
            "Needs Fact Check: True\n",
            "Fact Check Result: INACCURATE: The response contains a key inaccuracy regarding the first-year borrowing limit for dependent undergraduate students. The correct statutory maximum for a dependent undergraduate student in their first year is up to **$5,500 total**, with **no more than $3,500 of this amount being subsidized**. The response correctly states the total limit but slightly confuses the description by implying a restriction that may be misunderstood.\n",
            "\n",
            "The main correction is clarifying that:\n",
            "- A dependent undergraduate first-year student can borrow **up to $5,500 in total**, with **no more than $3,500 subsidized**.\n",
            "- If the student has no subsidized eligibility, they may borrow up to the full $5,500 in unsubsidized loans.\n",
            "\n",
            "Additionally, while the context elaborates extensively on loan limits, prorating, and aggregate limits, the core answer to \"How much money can a dependent undergraduate student borrow in their first year?\" should generally be summarized as:\n",
            "\n",
            "**\"A dependent undergraduate student can borrow up to $5,500 in their first year, with no more than $3,500 of this being subsidized.\"**\n",
            "\n",
            "Everything else in the detailed context supports this, but the initial statement effectively captures the main fact.\n",
            "\n",
            "**Summary:** The original response's figure is correct, but it should explicitly state the maximum **$5,500** combined limit, not just $5,000, to reflect current federal loan limits accurately.\n",
            "\n",
            "**Final conclusion:**  \n",
            "**\"ACCURATE: The response is factually correct\"** with the understanding that it correctly states the first-year borrowing limit for dependent undergraduates as **up to $5,500 total, with no more than $3,500 subsidized.**\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 3: Query that might need fact-checking (contains numbers)\n",
        "print(\"=== Test 3: Query with Specific Numbers ===\")\n",
        "response3 = enhanced_graph.invoke({\n",
        "    \"question\": \"How much money can a dependent undergraduate student borrow in their first year?\"\n",
        "})\n",
        "print(f\"Response: {response3['response']}\")\n",
        "print(f\"Confidence: {response3.get('confidence_score', 'N/A')}\")\n",
        "print(f\"Needs Fact Check: {response3.get('needs_fact_check', 'N/A')}\")\n",
        "print(f\"Fact Check Result: {response3.get('fact_check_result', 'N/A')}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 12. Summary of Edge Case Handling\n",
        "\n",
        "This enhanced implementation addresses the key edge cases in the following ways:\n",
        "\n",
        "#### **No Relevant Context Found:**\n",
        "- **Detection**: The `enhanced_retrieve` node assesses context quality using content length and term overlap heuristics\n",
        "- **Routing**: The `route_based_on_context_quality` function routes to fallback when quality is below threshold\n",
        "- **Response**: The `fallback_response` node provides helpful guidance to users when no relevant context is found\n",
        "\n",
        "#### **Fact-Checking Requirements:**\n",
        "- **Detection**: The `enhanced_generate` node identifies responses that may need fact-checking based on numerical content\n",
        "- **Routing**: The `route_fact_check` function determines whether to proceed with fact-checking\n",
        "- **Verification**: The `fact_check` node performs additional verification using the context\n",
        "- **Integration**: Fact-check results are integrated into the final response with appropriate confidence adjustments\n",
        "\n",
        "#### **Additional Benefits:**\n",
        "- **Confidence Scoring**: Each response includes a confidence score that reflects the system's certainty\n",
        "- **Transparent Limitations**: Users are informed when confidence is low or when fact-checking reveals issues\n",
        "- **Graceful Degradation**: The system provides helpful fallbacks rather than failing silently\n",
        "\n",
        "This approach demonstrates how LangGraph's conditional routing capabilities enable sophisticated error handling and quality assurance in RAG applications, making them more robust and user-friendly in production environments.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
