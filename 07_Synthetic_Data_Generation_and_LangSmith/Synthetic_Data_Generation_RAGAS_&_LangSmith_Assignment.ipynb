{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCk2Rx4cjlYF"
      },
      "source": [
        "# Synthetic Data Generation Using RAGAS - RAG Evaluation with LangSmith\n",
        "\n",
        "In the following notebook we'll explore a use-case for RAGAS' synthetic testset generation workflow!\n",
        "\n",
        "\n",
        "\n",
        "- 🤝 BREAKOUT ROOM #1\n",
        "  1. Use RAGAS to Generate Synthetic Data\n",
        "\n",
        "- 🤝 BREAKOUT ROOM #2\n",
        "  1. Load them into a LangSmith Dataset\n",
        "  2. Evaluate our RAG chain against the synthetic test data\n",
        "  3. Make changes to our pipeline\n",
        "  4. Evaluate the modified pipeline\n",
        "\n",
        "SDG is a critical piece of the puzzle, especially for early iteration! Without it, it would not be nearly as easy to get high quality early signal for our application's performance.\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bG2ta-B478G"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VUI7vF_kbv9"
      },
      "source": [
        "## Task 1: Dependencies and API Keys\n",
        "\n",
        "We'll need to install a number of API keys and dependencies, since we'll be leveraging a number of great technologies for this pipeline!\n",
        "\n",
        "1. OpenAI's endpoints to handle the Synthetic Data Generation\n",
        "2. OpenAI's Endpoints for our RAG pipeline and LangSmith evaluation\n",
        "3. QDrant as our vectorstore\n",
        "4. LangSmith for our evaluation coordinator!\n",
        "\n",
        "Let's install and provide all the required information below!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies and API Keys:\n",
        "\n",
        "> NOTE: DO NOT RUN THESE CELLS IF YOU ARE RUNNING THIS NOTEBOOK LOCALLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m160.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#!pip install -qU ragas==0.2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NLTK Import\n",
        "\n",
        "To prevent errors that may occur based on OS - we'll import NLTK and download the needed packages to ensure correct handling of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/ovookpubuluku/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/ovookpubuluku/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll also want to set a project name to make things easier for ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - SDG - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenAI's API Key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - which should hopefull be familiar at this point since it's our Loan Data use-case!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unrolled SDG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ovookpubuluku/project-repos/ai-makerspace/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/segmenter.py:66: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  for match in re.finditer('{0}\\s*'.format(re.escape(sent)), self.original_text):\n",
            "/Users/ovookpubuluku/project-repos/ai-makerspace/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/lang/arabic.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n",
            "/Users/ovookpubuluku/project-repos/ai-makerspace/AIE7/07_Synthetic_Data_Generation_and_LangSmith/.venv/lib/python3.13/site-packages/pysbd/lang/persian.py:29: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  txt = re.sub('(?<={0})\\.'.format(am), '∯', txt)\n"
          ]
        }
      ],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to instantiate our Knowledge Graph.\n",
        "\n",
        "This graph will contain N number of nodes that have M number of relationships. These nodes and relationships (AKA \"edges\") will define our knowledge graph and be used later to construct relevant questions and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 0, relationships: 0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import KnowledgeGraph\n",
        "\n",
        "kg = KnowledgeGraph()\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step we're going to take is to simply insert each of our full documents into the graph. This will provide a base that we can apply transformations to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 20, relationships: 0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.graph import Node, NodeType\n",
        "\n",
        "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
        "for doc in docs[:20]:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we'll apply the *default* transformations to our knowledge graph. This will take the nodes currently on the graph and transform them based on a set of [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms).\n",
        "\n",
        "These default transformations are dependent on the corpus length, in our case:\n",
        "\n",
        "- Producing Summaries -> produces summaries of the documents\n",
        "- Extracting Headlines -> finding the overall headline for the document\n",
        "- Theme Extractor -> extracts broad themes about the documents\n",
        "\n",
        "It then uses cosine-similarity and heuristics between the embeddings of the above transformations to construct relationships between the nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ae29e1befbe465090c53cdd386a170b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69f7065c163548a8b01b2e9b9fba3917",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32d67d06199547b3acc06fdf54edb9f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '7ef641'. Skipping!\n",
            "Property 'summary' already exists in node 'ac5b0b'. Skipping!\n",
            "Property 'summary' already exists in node 'fa5cbd'. Skipping!\n",
            "Property 'summary' already exists in node '3dff28'. Skipping!\n",
            "Property 'summary' already exists in node 'd33dd4'. Skipping!\n",
            "Property 'summary' already exists in node '0e89f9'. Skipping!\n",
            "Property 'summary' already exists in node 'e61445'. Skipping!\n",
            "Property 'summary' already exists in node '94bd64'. Skipping!\n",
            "Property 'summary' already exists in node '539eb2'. Skipping!\n",
            "Property 'summary' already exists in node '4b0b86'. Skipping!\n",
            "Property 'summary' already exists in node 'b41752'. Skipping!\n",
            "Property 'summary' already exists in node '104660'. Skipping!\n",
            "Property 'summary' already exists in node '0011a7'. Skipping!\n",
            "Property 'summary' already exists in node 'dd68ce'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db73816893d34859a45ba565b0dc9706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10e10814b58e455894557927651930e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '7ef641'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'fa5cbd'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '0e89f9'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'dd68ce'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '4b0b86'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'd33dd4'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '94bd64'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b41752'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '3dff28'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '104660'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '539eb2'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'ac5b0b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'e61445'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '0011a7'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4abc7f4277bf4c27abcef4695d0b65a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 40, relationships: 480)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.transforms import default_transforms, apply_transforms\n",
        "\n",
        "transformer_llm = generator_llm\n",
        "embedding_model = generator_embeddings\n",
        "\n",
        "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
        "apply_transforms(kg, default_transforms)\n",
        "kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can save and load our knowledge graphs as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 40, relationships: 480)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"loan_data_kg.json\")\n",
        "loan_data_kg = KnowledgeGraph.load(\"loan_data_kg.json\")\n",
        "loan_data_kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using our knowledge graph, we can construct a \"test set generator\" - which will allow us to create queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loan_data_kg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we'd like to be able to define the kinds of queries we're generating - which is made simple by Ragas having pre-created a number of different \"QuerySynthesizer\"s.\n",
        "\n",
        "Each of these Synthetsizers is going to tackle a separate kind of query which will be generated from a scenario and a persona.\n",
        "\n",
        "In essence, Ragas will use an LLM to generate a persona of someone who would interact with the data - and then use a scenario to construct a question from that data and persona."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "\n",
        "query_distribution = [\n",
        "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
        "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "What are the three types of query synthesizers doing? Describe each one in simple terms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use our `TestSetGenerator` to generate our testset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59116d5536254b53a3309b5584bb4c4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4d33757e4534350889801b40ad77482",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3127d82dafdf43c084faad0aadbc3a05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Whas is the School Participaton Divsion?</td>\n",
              "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
              "      <td>The context does not provide a specific defini...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What does the regulation 34 CFR 668.3(b) speci...</td>\n",
              "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
              "      <td>Regulatory citations indicate that 34 CFR 668....</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chapter 3 what is it and how does it relate to...</td>\n",
              "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
              "      <td>Inclusion of Clinical Work in a Standard Term ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is the FWS program considered a payment period...</td>\n",
              "      <td>[Non-Term Characteristics A program that measu...</td>\n",
              "      <td>No, the FWS program is not considered a paymen...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is Volume 7 about?</td>\n",
              "      <td>[both the credit or clock hours and the weeks ...</td>\n",
              "      <td>Volume 7 provides guidance on the disbursement...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>whats the disbursement timing in subscriptn ba...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
              "      <td>In subscription-based programs, for the first ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Include clinical work in standard term periods...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
              "      <td>Inclusion of clinical work in standard term pe...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do the guidelines and exceptions for inclu...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
              "      <td>The guidelines specify that clinical work cond...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Whitch chapters cover disbursement timing and ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
              "      <td>Chapter 2 discusses disbursement timing in sub...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How do Volume 7 and Volume 8 relate to disburs...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
              "      <td>Volume 7 explains that the Pell Grant and TEAC...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How do the definitions of academic years in Vo...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
              "      <td>Volume 2 explains that the academic year for c...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0            Whas is the School Participaton Divsion?   \n",
              "1   What does the regulation 34 CFR 668.3(b) speci...   \n",
              "2   Chapter 3 what is it and how does it relate to...   \n",
              "3   Is the FWS program considered a payment period...   \n",
              "4                             What is Volume 7 about?   \n",
              "5   whats the disbursement timing in subscriptn ba...   \n",
              "6   Include clinical work in standard term periods...   \n",
              "7   How do the guidelines and exceptions for inclu...   \n",
              "8   Whitch chapters cover disbursement timing and ...   \n",
              "9   How do Volume 7 and Volume 8 relate to disburs...   \n",
              "10  How do the definitions of academic years in Vo...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
              "1   [Regulatory Citations Academic year minimums: ...   \n",
              "2   [Inclusion of Clinical Work in a Standard Term...   \n",
              "3   [Non-Term Characteristics A program that measu...   \n",
              "4   [both the credit or clock hours and the weeks ...   \n",
              "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
              "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
              "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
              "8   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
              "9   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
              "10  [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The context does not provide a specific defini...   \n",
              "1   Regulatory citations indicate that 34 CFR 668....   \n",
              "2   Inclusion of Clinical Work in a Standard Term ...   \n",
              "3   No, the FWS program is not considered a paymen...   \n",
              "4   Volume 7 provides guidance on the disbursement...   \n",
              "5   In subscription-based programs, for the first ...   \n",
              "6   Inclusion of clinical work in standard term pe...   \n",
              "7   The guidelines specify that clinical work cond...   \n",
              "8   Chapter 2 discusses disbursement timing in sub...   \n",
              "9   Volume 7 explains that the Pell Grant and TEAC...   \n",
              "10  Volume 2 explains that the academic year for c...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   single_hop_specifc_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f785f49906b24189b14f52b5eda3facb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/17 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97ec938fbfd74ee1856070ceea2a5129",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n",
            "unable to apply transformation: 'headlines' property not found in this node\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05abc56b8d3c4d49a42ce58a5441742f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary' already exists in node '0dcc07'. Skipping!\n",
            "Property 'summary' already exists in node 'c86d0b'. Skipping!\n",
            "Property 'summary' already exists in node '6b5ecb'. Skipping!\n",
            "Property 'summary' already exists in node '0b44dc'. Skipping!\n",
            "Property 'summary' already exists in node 'bbc490'. Skipping!\n",
            "Property 'summary' already exists in node '389a44'. Skipping!\n",
            "Property 'summary' already exists in node 'bf2d13'. Skipping!\n",
            "Property 'summary' already exists in node '9e6f71'. Skipping!\n",
            "Property 'summary' already exists in node '532c3e'. Skipping!\n",
            "Property 'summary' already exists in node 'ddfffa'. Skipping!\n",
            "Property 'summary' already exists in node 'b257f6'. Skipping!\n",
            "Property 'summary' already exists in node '361cf8'. Skipping!\n",
            "Property 'summary' already exists in node '7696e4'. Skipping!\n",
            "Property 'summary' already exists in node '3d820b'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3961a56ae9384afdbbc8670075ad775b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/6 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c6e5df46a3440cb8436dfaa40a910f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'summary_embedding' already exists in node '0dcc07'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '0b44dc'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '389a44'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '532c3e'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bbc490'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'bf2d13'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'c86d0b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'b257f6'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '9e6f71'. Skipping!\n",
            "Property 'summary_embedding' already exists in node 'ddfffa'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '3d820b'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '6b5ecb'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '7696e4'. Skipping!\n",
            "Property 'summary_embedding' already exists in node '361cf8'. Skipping!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1739c0c3a6b42f2ab406ef516e78049",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10910e729e05427980c154a23932e67c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1e2622f3e874c96aa63bb26be83704b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562b61c2e2784192b9d69c3644778988",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs[:20], testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Volume 2 about in the context of acade...</td>\n",
              "      <td>[Chapter 1 Academic Years, Academic Calendars,...</td>\n",
              "      <td>The context provided does not specify the cont...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is 34 CFR 668.3(b)?</td>\n",
              "      <td>[Regulatory Citations Academic year minimums: ...</td>\n",
              "      <td>34 CFR 668.3(b) pertains to weeks of instructi...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Chapter 3 specify regarding the incl...</td>\n",
              "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
              "      <td>Chapter 3 states that clinical work conducted ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the significance of Title IV in relati...</td>\n",
              "      <td>[Non-Term Characteristics A program that measu...</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do Title IV programs determine disbursemen...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the differences between standard and no...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
              "      <td>The inclusion of clinical work in standard ter...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the disbursement timing requirements di...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
              "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How does credit hour allocation for clinical e...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
              "      <td>Credit hour allocation for clinical experience...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Volume 8 and Volume 8 how does that affect dis...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
              "      <td>The first volume explains that disbursement of...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Chapter 3 disbursement rules and clinical work...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
              "      <td>Disbursement timing in Chapter 3 explains that...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Volume 2 and Volume 8 disbursements how do the...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
              "      <td>Volume 2 explains disbursement timing in subsc...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do the disbursement timing rules outlined ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
              "      <td>The rules in Volume 7 specify that, for the fi...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   What is Volume 2 about in the context of acade...   \n",
              "1                            What is 34 CFR 668.3(b)?   \n",
              "2   What does Chapter 3 specify regarding the incl...   \n",
              "3   What is the significance of Title IV in relati...   \n",
              "4   How do Title IV programs determine disbursemen...   \n",
              "5   How do the differences between standard and no...   \n",
              "6   How do the disbursement timing requirements di...   \n",
              "7   How does credit hour allocation for clinical e...   \n",
              "8   Volume 8 and Volume 8 how does that affect dis...   \n",
              "9   Chapter 3 disbursement rules and clinical work...   \n",
              "10  Volume 2 and Volume 8 disbursements how do the...   \n",
              "11  How do the disbursement timing rules outlined ...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [Chapter 1 Academic Years, Academic Calendars,...   \n",
              "1   [Regulatory Citations Academic year minimums: ...   \n",
              "2   [Inclusion of Clinical Work in a Standard Term...   \n",
              "3   [Non-Term Characteristics A program that measu...   \n",
              "4   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
              "5   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
              "6   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
              "7   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
              "8   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
              "9   [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
              "10  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
              "11  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The context provided does not specify the cont...   \n",
              "1   34 CFR 668.3(b) pertains to weeks of instructi...   \n",
              "2   Chapter 3 states that clinical work conducted ...   \n",
              "3   Title IV programs require disbursements to be ...   \n",
              "4   Title IV programs require disbursements to be ...   \n",
              "5   The inclusion of clinical work in standard ter...   \n",
              "6   In clock-hour or non-term credit-hour programs...   \n",
              "7   Credit hour allocation for clinical experience...   \n",
              "8   The first volume explains that disbursement of...   \n",
              "9   Disbursement timing in Chapter 3 explains that...   \n",
              "10  Volume 2 explains disbursement timing in subsc...   \n",
              "11  The rules in Volume 7 specify that, for the fi...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vSRr2MXk0P_"
      },
      "source": [
        "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLDUsLJg43k7"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLtk1GtnyoY"
      },
      "source": [
        "## Task 4: LangSmith Dataset\n",
        "\n",
        "Now we can move on to creating a dataset for LangSmith!\n",
        "\n",
        "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
        "\n",
        "We'll name our Dataset to make it easy to work with later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TLgm6OjvYSsm"
      },
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = \"Loan Synthetic Data\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Loan Synthetic Data\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64SmXMBnzXWm"
      },
      "source": [
        "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
        "\n",
        "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8nFQ6di_XnY7"
      },
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EbQVyZq-2j"
      },
      "source": [
        "## Basic RAG Chain\n",
        "\n",
        "Time for some RAG!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4njbUAIsaYjB"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQorBy8H1AZR"
      },
      "source": [
        "To keep things simple, we'll just use LangChain's recursive character text splitter!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qWo3Ajaragv1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kghuTb9R01oO"
      },
      "source": [
        "We'll create our vectorstore using OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UwfJCzP3aqKI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpCLS-a01Ft2"
      },
      "source": [
        "As usual, we will power our RAG application with Qdrant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "58Ypj_NgbEsi"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan RAG\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SbKSjfSkbTYo"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxUOMaQX1K2N"
      },
      "source": [
        "To get the \"A\" in RAG, we'll provide a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1sLeY1oWbVqO"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnHDh4e1Ou5"
      },
      "source": [
        "For our LLM, we will be using TogetherAI's endpoints as well!\n",
        "\n",
        "We're going to be using Meta Llama 3.1 70B Instruct Turbo - a powerful model which should get us powerful results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6nx-ue1XbciV"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmTL6-pc1ZGz"
      },
      "source": [
        "Finally, we can set-up our RAG LCEL chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TjWj0OLIbbFc"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQ7bEweo4IIb",
        "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The kinds of loans available are:\\n\\n- Direct Subsidized Loans  \\n- Direct Unsubsidized Loans  \\n- Direct PLUS Loans (including student Federal PLUS Loans and parent Direct PLUS Loans)  \\n- Federal Stafford Loans (Subsidized and Unsubsidized) made under the FFEL Program before July 1, 2010  \\n- Federal SLS Loans  \\n- Federal PLUS Loans made under the FFEL Program before July 1, 2010  \\n\\nNote: No new loans have been made under the FFEL Program since July 1, 2010; current loans are under the Direct Loan program.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9hBh5YPrdGJ"
      },
      "source": [
        "## LangSmith Evaluation Set-up\n",
        "\n",
        "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gfwPYdIkcvpF"
      },
      "outputs": [],
      "source": [
        "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b8pToKH2K28"
      },
      "source": [
        "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PXSG-_ajckp6"
      },
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": (\n",
        "                \"Is this submission helpful to the user,\"\n",
        "                \" taking into account the correct reference answer?\"\n",
        "            )\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    },\n",
        "    prepare_data=lambda run, example: {\n",
        "        \"prediction\": run.outputs[\"output\"],\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "empathy_evaluator = LangChainStringEvaluator(\n",
        "    \"criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"empathy\": \"Is this response empathetic? Does it make the user feel like they are being heard?\",\n",
        "        },\n",
        "        \"llm\" : eval_llm\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0SQP_FoCetP"
      },
      "source": [
        "#### 🏗️ Activity #2:\n",
        "\n",
        "Highlight what each evaluator is evaluating.\n",
        "\n",
        "- `qa_evaluator`:\n",
        "- `labeled_helpfulness_evaluator`:\n",
        "- `empathy_evaluator`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R35sQMHVrnpl"
      },
      "source": [
        "## LangSmith Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "122b1bd1f0e9417a8dcb57d4eebe4d2e",
            "e0c233ad01604540a6c873f4a731982d",
            "e9a01115c75b499884f7e0ef32e9e599",
            "5faba4ad609448b2b49024add4ad3b8e",
            "ef25efa751304e4699910f1fbc14345f",
            "0b44cb0f8e34446c8dde668a75d3d8ad",
            "edaac6587b2d4bd5be52b89bb097f99f",
            "7cb241365f604419af454c1c28de197a",
            "9cf586576ff44dba86ba2eb389593c61",
            "849b5c95008541d49f1ceedf0a59ac60",
            "f3665a86662746c4ac7cb0796604781d"
          ]
        },
        "id": "t7t_Uz0tdumL",
        "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'damp-community-70' at:\n",
            "https://smith.langchain.com/o/7ffaf126-290e-4d08-9a81-6ef0b42d5153/datasets/131cc58c-8dcf-40f5-a863-ccb1a45a90c5/compare?selectedSessions=df922d11-f939-4f64-9501-6913fba644c0\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "499327e1ad084295b8c9ee8ec66dc247",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.empathy</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the disbursement timing rules outlined ...</td>\n",
              "      <td>Based on the provided context, the disbursemen...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rules in Volume 7 specify that, for the fi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.942066</td>\n",
              "      <td>18fc5b9c-6241-4597-aabb-9143142bc454</td>\n",
              "      <td>a3e5cd06-b8bb-49cd-b30f-bb44c9ba7560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Volume 2 and Volume 8 disbursements how do the...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>None</td>\n",
              "      <td>Volume 2 explains disbursement timing in subsc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.228413</td>\n",
              "      <td>16f633ac-1c34-4760-9b00-646dbebe1c60</td>\n",
              "      <td>6ba3b436-1da3-473a-830d-49a300683adb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chapter 3 disbursement rules and clinical work...</td>\n",
              "      <td>Chapter 3 discusses disbursement rules related...</td>\n",
              "      <td>None</td>\n",
              "      <td>Disbursement timing in Chapter 3 explains that...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.930541</td>\n",
              "      <td>6fbca36f-a727-4aff-b8ad-c8c1d9ef7702</td>\n",
              "      <td>c82bcc0a-006f-4054-a726-a11e542e195c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Volume 8 and Volume 8 how does that affect dis...</td>\n",
              "      <td>Based on the provided context, Volume 8 for 20...</td>\n",
              "      <td>None</td>\n",
              "      <td>The first volume explains that disbursement of...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.881505</td>\n",
              "      <td>e16fe381-b13e-4555-ab54-ca5682b3003d</td>\n",
              "      <td>62516b27-2c3d-4037-aa93-fb5cc2857691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does credit hour allocation for clinical e...</td>\n",
              "      <td>Based on the provided context:\\n\\nCredit hours...</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit hour allocation for clinical experience...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.120342</td>\n",
              "      <td>4fa55414-af4b-4cec-8a03-f7860eb4de86</td>\n",
              "      <td>618903cc-b45d-40c7-b50b-6067c5c683f7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the disbursement timing requirements di...</td>\n",
              "      <td>Based on the provided context, the disbursemen...</td>\n",
              "      <td>None</td>\n",
              "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.943350</td>\n",
              "      <td>24837152-7e96-4d76-8321-0c3bebefd0c9</td>\n",
              "      <td>196432db-bf96-4f75-a8ee-29b59a26ef5f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the differences between standard and no...</td>\n",
              "      <td>Based on the provided context, the differences...</td>\n",
              "      <td>None</td>\n",
              "      <td>The inclusion of clinical work in standard ter...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.413070</td>\n",
              "      <td>0f75f34b-dfb6-4641-9912-a4d8b9a3be91</td>\n",
              "      <td>8a541691-ffb8-46fe-a71e-212bb5d576f2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do Title IV programs determine disbursemen...</td>\n",
              "      <td>Based on the provided context, Title IV progra...</td>\n",
              "      <td>None</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.228356</td>\n",
              "      <td>b45cea75-7efd-46ce-8e6a-17e86b3d970b</td>\n",
              "      <td>a95ad2e1-baa4-441f-bfae-f722c08dce79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the significance of Title IV in relati...</td>\n",
              "      <td>Title IV program disbursements, except for Fed...</td>\n",
              "      <td>None</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3.393706</td>\n",
              "      <td>d92921f5-1264-493f-89eb-b3627b766b51</td>\n",
              "      <td>456c22df-2b27-4164-80ec-9976975ce806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What does Chapter 3 specify regarding the incl...</td>\n",
              "      <td>Chapter 3 specifies that periods of medical an...</td>\n",
              "      <td>None</td>\n",
              "      <td>Chapter 3 states that clinical work conducted ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.955122</td>\n",
              "      <td>62df5fa5-cfee-49b4-be75-b43c5d4520a7</td>\n",
              "      <td>8210474e-038e-46f2-8034-adc938c3dfc3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is 34 CFR 668.3(b)?</td>\n",
              "      <td>34 CFR 668.3(b) refers to the \"Weeks of instru...</td>\n",
              "      <td>None</td>\n",
              "      <td>34 CFR 668.3(b) pertains to weeks of instructi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.417353</td>\n",
              "      <td>9beb0e44-b431-47cb-9def-ff2afecf830c</td>\n",
              "      <td>07cb247f-04e4-4ab2-b1fe-9875e43a784a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is Volume 2 about in the context of acade...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>None</td>\n",
              "      <td>The context provided does not specify the cont...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.690488</td>\n",
              "      <td>b1bcecd5-45ae-4cd4-a40f-f875677b17d1</td>\n",
              "      <td>e831f67d-0dbc-4d3e-bbd2-8c4d04393e31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults damp-community-70>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        empathy_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"default_chain_init\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq7fCVinrpI4"
      },
      "source": [
        "## Dope-ifying Our Application\n",
        "\n",
        "We'll be making a few changes to our RAG chain to increase its performance on our SDG evaluation test dataset!\n",
        "\n",
        "- Include a \"dope\" prompt augmentation\n",
        "- Use larger chunks\n",
        "- Improve the retriever model to: `text-embedding-3-large`\n",
        "\n",
        "Let's see how this changes our evaluation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "z56pXwyUgFUt"
      },
      "outputs": [],
      "source": [
        "EMPATHY_RAG_PROMPT = \"\"\"\\\n",
        "Given a provided context and question, you must answer the question based only on context.\n",
        "\n",
        "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
        "\n",
        "You must answer the question using empathy and kindness, and make sure the user feels heard.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "empathy_rag_prompt = ChatPromptTemplate.from_template(EMPATHY_RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "rZLcTstJgfv5"
      },
      "outputs": [],
      "source": [
        "rag_documents = docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-LYsyirngj6n"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "rag_documents = text_splitter.split_documents(rag_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spldiPuTCzDO"
      },
      "source": [
        "#### ❓Question #2:\n",
        "\n",
        "Why would modifying our chunk size modify the performance of our application?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "b9MI2Bm2go1r"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBbjG6cKC8BQ"
      },
      "source": [
        "#### ❓Question #3:\n",
        "\n",
        "Why would modifying our embedding model modify the performance of our application?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hVUY25FKgxXx"
      },
      "outputs": [],
      "source": [
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=rag_documents,\n",
        "    embedding=embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan Data for RAG\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q4TOZNYIg2v1"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYGFrnKDB91"
      },
      "source": [
        "Setting up our new and improved DOPE RAG CHAIN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HqnTqeXMhAdx"
      },
      "outputs": [],
      "source": [
        "empathy_rag_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | empathy_rag_prompt | llm | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pTxoqJDI1Y"
      },
      "source": [
        "Let's test it on the same output that we saw before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OfZZ3MoN3fKv",
        "outputId": "d65722dd-92c2-4e4e-9cca-c42ee6f3f208"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Thank you for your question—it's important to understand the different loan options available for students. Based on the context provided, there are several types of loans mentioned:\\n\\n1. **Direct Subsidized Loans** – These loans are based on the student's financial need and have limits, such as maximum subsidized annual loan limits depending on the student's year and dependency status.\\n\\n2. **Direct Unsubsidized Loans** – These loans are available regardless of financial need, and students may qualify for these in addition to subsidized loans. They can also be used to cover unmet financial needs or replace other aid.\\n\\n3. **Direct PLUS Loans** – These loans can be taken out by a parent of a dependent student (Direct PLUS Loan) or by independent students (student Direct PLUS Loan) to cover the cost of attendance not met by other financial aid. There is no fixed loan limit for PLUS Loans, but the amount cannot exceed the student's cost of attendance minus other financial aid.\\n\\nI hope this helps clarify the types of loans available. If you have more questions or need further support, please feel free to ask—I'm here to help!\""
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "empathy_rag_chain.invoke({\"question\" : \"What kinds of loans are available?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpj7v1inDLnQ"
      },
      "source": [
        "Finally, we can evaluate the new chain on the same test set!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "bf8dcc0895054529af356da401c513f6",
            "7dce19ac55264f2b88a0e4730e55867b",
            "2a0755d4476543feb4a64538e3e37213",
            "158212a630f04cbd884c937f2f60f5c8",
            "11c7f66acc1d45be9517d0addf49331e",
            "ddffd834e09940a4bd3874c3f39b4e21",
            "ef63c3b2d51e452da03cdae5d9b034be",
            "c20b539cd70b4ba99601ad1d69fd9cec",
            "a6d681eeafa44d18b933a4c5dec88382",
            "d1d54ccd56494c4d831f71b416a1f880",
            "530f696feefe499da08c6312047379b2"
          ]
        },
        "id": "Dx11S2b-hIM8",
        "outputId": "d3a3ea78-aa32-4bd2-8c2a-d0d0303695c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'aching-quiet-6' at:\n",
            "https://smith.langchain.com/o/7ffaf126-290e-4d08-9a81-6ef0b42d5153/datasets/131cc58c-8dcf-40f5-a863-ccb1a45a90c5/compare?selectedSessions=e842dbe6-8c62-4b6a-8c97-927c956b2d57\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b73f05e9c06449cb69e1f87c7dd999a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.answer</th>\n",
              "      <th>feedback.correctness</th>\n",
              "      <th>feedback.helpfulness</th>\n",
              "      <th>feedback.empathy</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do the disbursement timing rules outlined ...</td>\n",
              "      <td>Thank you for your thoughtful question—it's cl...</td>\n",
              "      <td>None</td>\n",
              "      <td>The rules in Volume 7 specify that, for the fi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.056688</td>\n",
              "      <td>18fc5b9c-6241-4597-aabb-9143142bc454</td>\n",
              "      <td>050363a6-6a24-460f-bead-ef860286d2d3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Volume 2 and Volume 8 disbursements how do the...</td>\n",
              "      <td>Thank you for your thoughtful question about h...</td>\n",
              "      <td>None</td>\n",
              "      <td>Volume 2 explains disbursement timing in subsc...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.279129</td>\n",
              "      <td>16f633ac-1c34-4760-9b00-646dbebe1c60</td>\n",
              "      <td>d4adadff-3bd5-4b96-89a6-10c13a3bdfcd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chapter 3 disbursement rules and clinical work...</td>\n",
              "      <td>Thank you for your question—it's clear you're ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Disbursement timing in Chapter 3 explains that...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.839254</td>\n",
              "      <td>6fbca36f-a727-4aff-b8ad-c8c1d9ef7702</td>\n",
              "      <td>89bc88c4-c757-4721-a648-52ef45e283ca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Volume 8 and Volume 8 how does that affect dis...</td>\n",
              "      <td>Thank you for your thoughtful question. Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The first volume explains that disbursement of...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.837253</td>\n",
              "      <td>e16fe381-b13e-4555-ab54-ca5682b3003d</td>\n",
              "      <td>ba3cf118-d882-4e72-b220-7e397c62192e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does credit hour allocation for clinical e...</td>\n",
              "      <td>Thank you for your thoughtful question. It sho...</td>\n",
              "      <td>None</td>\n",
              "      <td>Credit hour allocation for clinical experience...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.670182</td>\n",
              "      <td>4fa55414-af4b-4cec-8a03-f7860eb4de86</td>\n",
              "      <td>1d375645-1b90-4ef1-bbd1-3e7909fdb3ac</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How do the disbursement timing requirements di...</td>\n",
              "      <td>Thank you for your thoughtful question. Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.853747</td>\n",
              "      <td>24837152-7e96-4d76-8321-0c3bebefd0c9</td>\n",
              "      <td>9f2f6dcb-e095-44fb-8b0d-3c618e1a099a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How do the differences between standard and no...</td>\n",
              "      <td>Thank you for your thoughtful question. Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>The inclusion of clinical work in standard ter...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9.111094</td>\n",
              "      <td>0f75f34b-dfb6-4641-9912-a4d8b9a3be91</td>\n",
              "      <td>53e6ee5b-653a-48f1-aaf1-cc7b0eecea3c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How do Title IV programs determine disbursemen...</td>\n",
              "      <td>Thank you for your thoughtful question. Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.349280</td>\n",
              "      <td>b45cea75-7efd-46ce-8e6a-17e86b3d970b</td>\n",
              "      <td>b9b677cf-c426-4105-8de0-00341a6b4717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the significance of Title IV in relati...</td>\n",
              "      <td>Thank you for your thoughtful question. Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Title IV programs require disbursements to be ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.941990</td>\n",
              "      <td>d92921f5-1264-493f-89eb-b3627b766b51</td>\n",
              "      <td>327763d1-b19b-4eec-8e91-37d007a7bbe8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What does Chapter 3 specify regarding the incl...</td>\n",
              "      <td>Thank you for your thoughtful question! Based ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Chapter 3 states that clinical work conducted ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.106724</td>\n",
              "      <td>62df5fa5-cfee-49b4-be75-b43c5d4520a7</td>\n",
              "      <td>35f4e0a8-1f45-4dce-a613-b77b0f18bc3b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is 34 CFR 668.3(b)?</td>\n",
              "      <td>Thank you for your question. I understand you'...</td>\n",
              "      <td>None</td>\n",
              "      <td>34 CFR 668.3(b) pertains to weeks of instructi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.676977</td>\n",
              "      <td>9beb0e44-b431-47cb-9def-ff2afecf830c</td>\n",
              "      <td>c5791cd0-6ea4-415c-ae3b-b12883baa898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What is Volume 2 about in the context of acade...</td>\n",
              "      <td>Thank you for your thoughtful question. I unde...</td>\n",
              "      <td>None</td>\n",
              "      <td>The context provided does not specify the cont...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.756079</td>\n",
              "      <td>b1bcecd5-45ae-4cd4-a40f-f875677b17d1</td>\n",
              "      <td>ee81651e-5580-48a5-8cd9-6b7c85103f58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "<ExperimentResults aching-quiet-6>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(\n",
        "    empathy_rag_chain.invoke,\n",
        "    data=dataset_name,\n",
        "    evaluators=[\n",
        "        qa_evaluator,\n",
        "        labeled_helpfulness_evaluator,\n",
        "        empathy_evaluator\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"empathy_rag_chain\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7migvlDPZT",
        "tags": [
          "Activity 3"
        ]
      },
      "source": [
        "#### 🏗️ Activity #3:\n",
        "\n",
        "Provide a screenshot of the difference between the two chains, and explain why you believe certain metrics changed in certain ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "Bonus Cell"
        ],
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### 🏗️ BONUS ACTIVITY (OPTIONAL):\n",
        "\n",
        "Reproduce the RAGAS Synthetic Data Generation Steps - but utilize a LangGraph Agent Graph, instead of the Knowledge Graph approach.\n",
        "\n",
        "This generation should leverage the [Evol Instruct](https://arxiv.org/pdf/2304.12244) method to generate synthetic data.\n",
        "\n",
        "Your final state (output) should contain (at least, not limited to):\n",
        "\n",
        "1. `List(dict)`: Evolved Questions, their IDs, and their Evolution Type.\n",
        "2. `List(dict)`: Question IDs, and Answer to the referenced Evolved Question.\n",
        "3. `List(dict)`: Question IDs, and the relevant Context(s) to the Evolved Question.\n",
        "\n",
        "The Graph should handle:\n",
        "\n",
        "1. Simple Evolution.\n",
        "2. Multi-Context Evolution.\n",
        "3. Reasoning Evolution.\n",
        "\n",
        "It should take, as input, a list of LangChain Documents.\n",
        "\n",
        "\n",
        "##### ✅ Answer:\n",
        "\n",
        "### 🚀 LangGraph-Based Synthetic Data Generation with Evol Instruct\n",
        "\n",
        "\n",
        "In this section, we'll implement a synthetic data generation system using LangGraph and the Evol Instruct methodology instead of the traditional Knowledge Graph approach used by RAGAS.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Evol Instruct method focuses on evolving simple questions into more complex ones through various transformation techniques:\n",
        "\n",
        "- **Simple Evolution**: Basic complexity increases\n",
        "- **Multi-Context Evolution**: Questions requiring multiple document contexts\n",
        "- **Reasoning Evolution**: Questions requiring multi-step reasoning\n",
        "\n",
        "Our LangGraph agent will process documents and generate evolved questions with their corresponding answers and contexts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 🎯 Step 1: Import Dependencies and Define Core Types\n",
        "\n",
        "The first step in our LangGraph implementation is to import the necessary libraries and define the fundamental data types we'll use throughout our synthetic data generation system.\n",
        "\n",
        "**Key Components:**\n",
        "- **LangGraph**: For building our agent workflow with nodes and edges\n",
        "- **TypedDict & Dataclasses**: For structured data handling and type safety\n",
        "- **EvolutionType Enum**: Defines the three evolution strategies we'll implement\n",
        "\n",
        "This foundational setup ensures our system is well-typed and organized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for LangGraph and Evol Instruct implementation\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "import uuid\n",
        "from langchain.schema import Document\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "# Define evolution types\n",
        "class EvolutionType(Enum):\n",
        "    SIMPLE = \"simple_evolution\"\n",
        "    MULTI_CONTEXT = \"multi_context_evolution\"\n",
        "    REASONING = \"reasoning_evolution\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 🏗️ Step 2: Define Data Structures for Synthetic Data Generation\n",
        "\n",
        "Here we create the data structures that will hold our synthetic data throughout the generation process. These dataclasses provide a clean, typed interface for working with our evolved questions and their associated metadata.\n",
        "\n",
        "**Data Structures:**\n",
        "- **EvolvedQuestion**: Contains the evolved question text, its unique ID, evolution type, source contexts, and complexity level\n",
        "- **QuestionAnswer**: Links question IDs to their generated answers\n",
        "- **QuestionContext**: Associates question IDs with their relevant document contexts\n",
        "- **SyntheticDataState**: The complete state object that flows through our LangGraph workflow\n",
        "\n",
        "These structures ensure data consistency and make it easy to track relationships between questions, answers, and contexts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define data structures for synthetic data generation\n",
        "\n",
        "@dataclass\n",
        "class EvolvedQuestion:\n",
        "    \"\"\"Represents an evolved question with metadata\"\"\"\n",
        "    id: str\n",
        "    question: str\n",
        "    evolution_type: EvolutionType\n",
        "    source_context_ids: List[str]\n",
        "    complexity_level: int\n",
        "\n",
        "@dataclass \n",
        "class QuestionAnswer:\n",
        "    \"\"\"Represents a question-answer pair\"\"\"\n",
        "    question_id: str\n",
        "    answer: str\n",
        "\n",
        "@dataclass\n",
        "class QuestionContext:\n",
        "    \"\"\"Represents question with its relevant contexts\"\"\"\n",
        "    question_id: str\n",
        "    contexts: List[str]\n",
        "\n",
        "# Define the state for our LangGraph\n",
        "class SyntheticDataState(TypedDict):\n",
        "    documents: List[Document]\n",
        "    base_questions: List[Dict[str, Any]]\n",
        "    evolved_questions: List[Dict[str, Any]]\n",
        "    question_answers: List[Dict[str, Any]]\n",
        "    question_contexts: List[Dict[str, Any]]\n",
        "    current_iteration: int\n",
        "    max_iterations: int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 📝 Step 3: Define Evolution Prompts Based on Evol Instruct Methodology\n",
        "\n",
        "This step implements the core of the Evol Instruct approach through carefully crafted prompts. Each evolution type has a specialized prompt designed to transform simple questions into more complex, challenging versions.\n",
        "\n",
        "**Evolution Strategies:**\n",
        "1. **Simple Evolution**: Increases complexity while maintaining answerability from the original context\n",
        "2. **Multi-Context Evolution**: Creates questions requiring synthesis from multiple document sources\n",
        "3. **Reasoning Evolution**: Develops questions that require logical inference and multi-step thinking\n",
        "\n",
        "**Additional Prompts:**\n",
        "- **Answer Generation**: Ensures answers are grounded in the provided contexts\n",
        "- **Base Question Generation**: Creates foundational questions from document content\n",
        "\n",
        "These prompts are the \"intelligence\" of our system, encoding the strategies for creating high-quality synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define prompts for different evolution types\n",
        "\n",
        "SIMPLE_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at evolving questions to make them more complex while maintaining their essence.\n",
        "\n",
        "            Given the following context and base question, create a more complex version of the question.\n",
        "            The evolved question should:\n",
        "            1. Require deeper understanding of the content\n",
        "            2. Be more specific and detailed\n",
        "            3. Still be answerable from the given context\n",
        "\n",
        "            Context: {context}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "MULTI_CONTEXT_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at creating questions that require information from multiple sources.\n",
        "\n",
        "            Given the following contexts and base question, create a question that requires synthesizing information from multiple contexts.\n",
        "            The evolved question should:\n",
        "            1. Require information from at least 2 different contexts\n",
        "            2. Ask for comparison, relationship, or synthesis\n",
        "            3. Be more complex than the original question\n",
        "\n",
        "            Contexts:\n",
        "            {contexts}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "REASONING_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at creating questions that require multi-step reasoning.\n",
        "\n",
        "            Given the following context and base question, create a question that requires logical reasoning, inference, or multi-step thinking.\n",
        "            The evolved question should:\n",
        "            1. Require the reader to make logical connections\n",
        "            2. Involve cause-and-effect relationships or implications\n",
        "            3. Require step-by-step reasoning to answer\n",
        "\n",
        "            Context: {context}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "ANSWER_GENERATION_PROMPT = \"\"\"\n",
        "            You are an expert at answering questions based on provided context.\n",
        "\n",
        "            Given the following context(s) and question, provide a comprehensive and accurate answer.\n",
        "            Base your answer strictly on the information provided in the context(s).\n",
        "\n",
        "            Context(s):\n",
        "            {contexts}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Answer:\"\"\"\n",
        "\n",
        "BASE_QUESTION_GENERATION_PROMPT = \"\"\"\n",
        "            You are an expert at generating simple, foundational questions from document content.\n",
        "\n",
        "            Given the following document content, generate 3-5 simple, factual questions that can be answered directly from the content.\n",
        "            The questions should be:\n",
        "            1. Clear and straightforward\n",
        "            2. Answerable from the given content\n",
        "            3. Cover different aspects of the content\n",
        "            4. Suitable for evolution into more complex questions\n",
        "\n",
        "            Content: {content}\n",
        "\n",
        "            Generate questions in this format:\n",
        "            1. [Question 1]\n",
        "            2. [Question 2]\n",
        "            3. [Question 3]\n",
        "            etc.\n",
        "\n",
        "            Questions:\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### ⚙️ Step 4: Initialize LLM and Create Base Question Generation Node\n",
        "\n",
        "This step sets up the language model that will power our synthetic data generation and implements the first node in our LangGraph workflow. The base question generation node is responsible for extracting foundational questions from each document that will later be evolved into more complex forms.\n",
        "\n",
        "**Key Functions:**\n",
        "- **Base Question Generation**: Creates simple, factual questions from document content\n",
        "- **Simple Evolution Node**: Transforms basic questions into more complex versions\n",
        "- **Question Parsing**: Extracts and cleans questions from LLM responses\n",
        "\n",
        "The base questions serve as the foundation for all subsequent evolution steps, so their quality is crucial for the final output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM for synthetic data generation\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Use the same LLM as defined earlier in the notebook\n",
        "synthetic_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
        "\n",
        "def generate_base_questions(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Generate base questions from documents\"\"\"\n",
        "    print(\"🔄 Generating base questions from documents...\")\n",
        "    \n",
        "    base_questions = []\n",
        "    \n",
        "    for i, doc in enumerate(state[\"documents\"]):\n",
        "        prompt = ChatPromptTemplate.from_template(BASE_QUESTION_GENERATION_PROMPT)\n",
        "        \n",
        "        # Get questions for this document\n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(content=doc.page_content[:2000])  # Limit content length\n",
        "        )\n",
        "        \n",
        "        # Parse the response to extract questions\n",
        "        questions_text = response.content\n",
        "        questions = []\n",
        "        \n",
        "        for line in questions_text.split('\\n'):\n",
        "            if line.strip() and (line.strip().startswith(tuple('123456789')) or line.strip().startswith('-')):\n",
        "                # Clean up the question\n",
        "                question = line.split('.', 1)[-1].strip() if '.' in line else line.strip()\n",
        "                question = question.lstrip('- ').strip()\n",
        "                if question and question.endswith('?'):\n",
        "                    questions.append(question)\n",
        "        \n",
        "        # Add questions with metadata\n",
        "        for question in questions[:3]:  # Limit to 3 questions per document\n",
        "            base_questions.append({\n",
        "                \"id\": str(uuid.uuid4()),\n",
        "                \"question\": question,\n",
        "                \"source_doc_index\": i,\n",
        "                \"context\": doc.page_content\n",
        "            })\n",
        "    \n",
        "    state[\"base_questions\"] = base_questions\n",
        "    print(f\"✅ Generated {len(base_questions)} base questions\")\n",
        "    return state\n",
        "\n",
        "def simple_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply simple evolution to base questions\"\"\"\n",
        "    print(\"🔄 Applying simple evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions for simple evolution\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(3, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        prompt = ChatPromptTemplate.from_template(SIMPLE_EVOLUTION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                context=base_q[\"context\"][:1500],\n",
        "                base_question=base_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        evolved_question = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"question\": response.content.strip(),\n",
        "            \"evolution_type\": EvolutionType.SIMPLE.value,\n",
        "            \"source_context_ids\": [base_q[\"id\"]],\n",
        "            \"complexity_level\": 2\n",
        "        }\n",
        "        \n",
        "        evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"✅ Created {len(questions_to_evolve)} simple evolved questions\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 🔄 Step 5: Implement Advanced Evolution Nodes\n",
        "\n",
        "This step implements the more sophisticated evolution strategies that transform simple questions into complex, multi-dimensional challenges. These nodes represent the core innovation of the Evol Instruct methodology.\n",
        "\n",
        "**Evolution Strategies:**\n",
        "- **Multi-Context Evolution**: Combines information from multiple documents to create questions requiring synthesis\n",
        "- **Reasoning Evolution**: Develops questions that require logical inference and step-by-step thinking\n",
        "\n",
        "**Key Features:**\n",
        "- **Context Selection**: Intelligently chooses relevant contexts from different documents\n",
        "- **Complexity Scaling**: Assigns complexity levels to track question difficulty\n",
        "- **Randomized Selection**: Ensures diverse question types and prevents overfitting to specific documents\n",
        "\n",
        "These evolution nodes are what differentiate our approach from simple question generation, creating truly challenging evaluation scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multi_context_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply multi-context evolution to questions\"\"\"\n",
        "    print(\"🔄 Applying multi-context evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions and pair them with multiple contexts\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(2, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        # Select additional contexts from other documents\n",
        "        other_docs = [doc for i, doc in enumerate(state[\"documents\"]) \n",
        "                     if i != base_q[\"source_doc_index\"]]\n",
        "        \n",
        "        if other_docs:\n",
        "            additional_context = random.choice(other_docs).page_content[:1000]\n",
        "            combined_contexts = f\"Context 1:\\n{base_q['context'][:1000]}\\n\\nContext 2:\\n{additional_context}\"\n",
        "            \n",
        "            prompt = ChatPromptTemplate.from_template(MULTI_CONTEXT_EVOLUTION_PROMPT)\n",
        "            \n",
        "            response = synthetic_llm.invoke(\n",
        "                prompt.format_messages(\n",
        "                    contexts=combined_contexts,\n",
        "                    base_question=base_q[\"question\"]\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            evolved_question = {\n",
        "                \"id\": str(uuid.uuid4()),\n",
        "                \"question\": response.content.strip(),\n",
        "                \"evolution_type\": EvolutionType.MULTI_CONTEXT.value,\n",
        "                \"source_context_ids\": [base_q[\"id\"], \"additional_context\"],\n",
        "                \"complexity_level\": 3\n",
        "            }\n",
        "            \n",
        "            evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"✅ Created {len(questions_to_evolve)} multi-context evolved questions\")\n",
        "    return state\n",
        "\n",
        "def reasoning_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply reasoning evolution to questions\"\"\"\n",
        "    print(\"🔄 Applying reasoning evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions for reasoning evolution\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(2, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        prompt = ChatPromptTemplate.from_template(REASONING_EVOLUTION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                context=base_q[\"context\"][:1500],\n",
        "                base_question=base_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        evolved_question = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"question\": response.content.strip(),\n",
        "            \"evolution_type\": EvolutionType.REASONING.value,\n",
        "            \"source_context_ids\": [base_q[\"id\"]],\n",
        "            \"complexity_level\": 4\n",
        "        }\n",
        "        \n",
        "        evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"✅ Created {len(questions_to_evolve)} reasoning evolved questions\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 💬 Step 6: Answer Generation and Context Extraction\n",
        "\n",
        "This step completes the synthetic data generation pipeline by creating high-quality answers for the evolved questions and organizing the relevant contexts. This ensures each generated question has both a ground-truth answer and the supporting context needed for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answers_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Generate answers for all evolved questions\"\"\"\n",
        "    print(\"🔄 Generating answers for evolved questions...\")\n",
        "    \n",
        "    question_answers = []\n",
        "    \n",
        "    for evolved_q in state[\"evolved_questions\"]:\n",
        "        # Find relevant contexts for this question\n",
        "        contexts = []\n",
        "        \n",
        "        if evolved_q[\"evolution_type\"] == EvolutionType.MULTI_CONTEXT.value:\n",
        "            # For multi-context questions, use multiple document contexts\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1000])\n",
        "            \n",
        "            # Add additional context from other documents\n",
        "            other_docs = [doc for doc in state[\"documents\"]]\n",
        "            if other_docs:\n",
        "                additional_context = random.choice(other_docs).page_content[:1000]\n",
        "                contexts.append(additional_context)\n",
        "        else:\n",
        "            # For simple and reasoning questions, use the original context\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1500])\n",
        "        \n",
        "        # Generate answer using the contexts\n",
        "        combined_contexts = \"\\n\\n\".join(f\"Context {i+1}:\\n{ctx}\" for i, ctx in enumerate(contexts))\n",
        "        \n",
        "        prompt = ChatPromptTemplate.from_template(ANSWER_GENERATION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                contexts=combined_contexts,\n",
        "                question=evolved_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        answer = {\n",
        "            \"question_id\": evolved_q[\"id\"],\n",
        "            \"answer\": response.content.strip()\n",
        "        }\n",
        "        \n",
        "        question_answers.append(answer)\n",
        "    \n",
        "    state[\"question_answers\"] = question_answers\n",
        "    print(f\"✅ Generated {len(question_answers)} answers\")\n",
        "    return state\n",
        "\n",
        "def extract_contexts_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Extract and organize contexts for each question\"\"\"\n",
        "    print(\"🔄 Extracting contexts for questions...\")\n",
        "    \n",
        "    question_contexts = []\n",
        "    \n",
        "    for evolved_q in state[\"evolved_questions\"]:\n",
        "        contexts = []\n",
        "        \n",
        "        if evolved_q[\"evolution_type\"] == EvolutionType.MULTI_CONTEXT.value:\n",
        "            # For multi-context questions, include multiple contexts\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1000])\n",
        "            \n",
        "            # Add additional context\n",
        "            other_docs = [doc for doc in state[\"documents\"]]\n",
        "            if other_docs:\n",
        "                additional_context = random.choice(other_docs).page_content[:1000]\n",
        "                contexts.append(additional_context)\n",
        "        else:\n",
        "            # For simple and reasoning questions\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1500])\n",
        "        \n",
        "        question_context = {\n",
        "            \"question_id\": evolved_q[\"id\"],\n",
        "            \"contexts\": contexts\n",
        "        }\n",
        "        \n",
        "        question_contexts.append(question_context)\n",
        "    \n",
        "    state[\"question_contexts\"] = question_contexts\n",
        "    print(f\"✅ Extracted contexts for {len(question_contexts)} questions\")\n",
        "    return state\n",
        "\n",
        "def should_continue(state: SyntheticDataState) -> str:\n",
        "    \"\"\"Determine if we should continue processing or end\"\"\"\n",
        "    return \"end\" if state[\"current_iteration\"] >= state[\"max_iterations\"] else \"continue\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 🏗️ Step 7: Create and Configure the LangGraph Workflow\n",
        "\n",
        "This step assembles all the individual nodes into a cohesive LangGraph workflow. The graph defines the execution order and data flow between different stages of the synthetic data generation process.\n",
        "\n",
        "**Workflow Architecture:**\n",
        "- **Sequential Processing**: Each evolution type runs in sequence to build upon previous results\n",
        "- **State Management**: The `SyntheticDataState` flows through each node, accumulating results\n",
        "- **Modular Design**: Each node is independent and can be modified or replaced easily\n",
        "\n",
        "**Execution Flow:**\n",
        "1. Generate base questions from documents\n",
        "2. Apply simple evolution transformations\n",
        "3. Apply multi-context evolution transformations\n",
        "4. Apply reasoning evolution transformations\n",
        "5. Generate answers for all evolved questions\n",
        "6. Extract and organize contexts\n",
        "\n",
        "This graph architecture ensures consistent, reproducible synthetic data generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the LangGraph for Synthetic Data Generation\n",
        "def create_synthetic_data_graph():\n",
        "    \"\"\"Create and configure the LangGraph for synthetic data generation\"\"\"\n",
        "    \n",
        "    # Initialize the graph\n",
        "    workflow = StateGraph(SyntheticDataState)\n",
        "    \n",
        "    # Add nodes to the graph\n",
        "    workflow.add_node(\"generate_base_questions\", generate_base_questions)\n",
        "    workflow.add_node(\"simple_evolution\", simple_evolution_node)\n",
        "    workflow.add_node(\"multi_context_evolution\", multi_context_evolution_node)\n",
        "    workflow.add_node(\"reasoning_evolution\", reasoning_evolution_node)\n",
        "    workflow.add_node(\"generate_answers\", generate_answers_node)\n",
        "    workflow.add_node(\"extract_contexts\", extract_contexts_node)\n",
        "    \n",
        "    # Define the flow\n",
        "    workflow.set_entry_point(\"generate_base_questions\")\n",
        "    \n",
        "    # After generating base questions, run all evolution types in parallel\n",
        "    workflow.add_edge(\"generate_base_questions\", \"simple_evolution\")\n",
        "    workflow.add_edge(\"simple_evolution\", \"multi_context_evolution\")\n",
        "    workflow.add_edge(\"multi_context_evolution\", \"reasoning_evolution\")\n",
        "    \n",
        "    # After all evolutions, generate answers and extract contexts\n",
        "    workflow.add_edge(\"reasoning_evolution\", \"generate_answers\")\n",
        "    workflow.add_edge(\"generate_answers\", \"extract_contexts\")\n",
        "    \n",
        "    # End the workflow\n",
        "    workflow.add_edge(\"extract_contexts\", END)\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Create the graph\n",
        "synthetic_data_graph = create_synthetic_data_graph()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 🚀 Step 8: Main Execution Function and Demo Run\n",
        "\n",
        "This step provides the main entry point for running the synthetic data generation system. The function handles initialization, execution, and result formatting, making it easy to use the system with any set of documents.\n",
        "\n",
        "**Main Function Features:**\n",
        "- **Easy Interface**: Simple function call with documents and optional parameters\n",
        "- **Progress Tracking**: Real-time feedback on generation progress\n",
        "- **Result Organization**: Structured output with all required data formats\n",
        "- **Error Handling**: Robust execution with proper state management\n",
        "\n",
        "**Demo Execution:**\n",
        "- Uses a subset of documents to demonstrate the system\n",
        "- Generates evolved questions across all three evolution types\n",
        "- Produces the final output in the required format (question IDs, answers, contexts)\n",
        "\n",
        "This demonstration shows the complete end-to-end workflow in action.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_synthetic_data_generation(documents: List[Document], max_iterations: int = 1) -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Run the synthetic data generation process\n",
        "    \n",
        "    Args:\n",
        "        documents: List of LangChain Document objects\n",
        "        max_iterations: Maximum number of iterations to run\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing evolved questions, answers, and contexts\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state = {\n",
        "        \"documents\": documents,\n",
        "        \"base_questions\": [],\n",
        "        \"evolved_questions\": [],\n",
        "        \"question_answers\": [],\n",
        "        \"question_contexts\": [],\n",
        "        \"current_iteration\": 0,\n",
        "        \"max_iterations\": max_iterations\n",
        "    }\n",
        "    \n",
        "    print(\"🚀 Starting LangGraph-based Synthetic Data Generation with Evol Instruct\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Run the graph\n",
        "    final_state = synthetic_data_graph.invoke(initial_state)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"🎉 Synthetic Data Generation Complete!\")\n",
        "    print(f\"📊 Generated {len(final_state['evolved_questions'])} evolved questions\")\n",
        "    print(f\"💬 Generated {len(final_state['question_answers'])} answers\")\n",
        "    print(f\"📝 Extracted {len(final_state['question_contexts'])} context sets\")\n",
        "    \n",
        "    return {\n",
        "        \"evolved_questions\": final_state[\"evolved_questions\"],\n",
        "        \"question_answers\": final_state[\"question_answers\"],\n",
        "        \"question_contexts\": final_state[\"question_contexts\"]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using documents from the earlier notebook sections...\n",
            "Number of documents available: 269\n",
            "Using 5 documents for demonstration\n",
            "🚀 Starting LangGraph-based Synthetic Data Generation with Evol Instruct\n",
            "======================================================================\n",
            "🔄 Generating base questions from documents...\n",
            "✅ Generated 15 base questions\n",
            "🔄 Applying simple evolution...\n",
            "✅ Created 3 simple evolved questions\n",
            "🔄 Applying multi-context evolution...\n",
            "✅ Created 2 multi-context evolved questions\n",
            "🔄 Applying reasoning evolution...\n",
            "✅ Created 2 reasoning evolved questions\n",
            "🔄 Generating answers for evolved questions...\n",
            "✅ Generated 7 answers\n",
            "🔄 Extracting contexts for questions...\n",
            "✅ Extracted contexts for 7 questions\n",
            "\n",
            "======================================================================\n",
            "🎉 Synthetic Data Generation Complete!\n",
            "📊 Generated 7 evolved questions\n",
            "💬 Generated 7 answers\n",
            "📝 Extracted 7 context sets\n"
          ]
        }
      ],
      "source": [
        "# Run the LangGraph-based synthetic data generation\n",
        "print(\"Using documents from the earlier notebook sections...\")\n",
        "print(f\"Number of documents available: {len(docs)}\")\n",
        "\n",
        "# Use a subset of documents for demonstration (to manage cost and time)\n",
        "demo_docs = docs[:5]  # Use first 5 documents\n",
        "print(f\"Using {len(demo_docs)} documents for demonstration\")\n",
        "\n",
        "# Run the synthetic data generation\n",
        "synthetic_results = run_synthetic_data_generation(demo_docs, max_iterations=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 📊 Step 9: Results Analysis and Display\n",
        "\n",
        "This step provides comprehensive analysis and visualization of the generated synthetic data. It helps understand the distribution of evolution types, quality of questions, and overall system performance.\n",
        "\n",
        "**Analysis Features:**\n",
        "- **Evolution Type Distribution**: Shows how many questions were generated for each evolution strategy\n",
        "- **Sample Questions Display**: Provides examples of evolved questions with their answers and contexts\n",
        "- **Quality Assessment**: Demonstrates the complexity and diversity of generated questions\n",
        "- **Data Structure Validation**: Confirms all required outputs are properly formatted\n",
        "\n",
        "**Display Components:**\n",
        "- **Summary Statistics**: Quick overview of generation results\n",
        "- **Detailed Examples**: In-depth look at sample questions across all evolution types\n",
        "- **Context Analysis**: Shows how contexts are associated with different question types\n",
        "\n",
        "This analysis helps validate the effectiveness of the Evol Instruct approach and the quality of the synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 SYNTHETIC DATA GENERATION RESULTS ANALYSIS\n",
            "============================================================\n",
            "\n",
            "📊 EVOLUTION TYPE DISTRIBUTION:\n",
            "------------------------------\n",
            "  simple_evolution: 3 questions\n",
            "  multi_context_evolution: 2 questions\n",
            "  reasoning_evolution: 2 questions\n",
            "\n",
            "💡 SAMPLE EVOLVED QUESTIONS BY TYPE:\n",
            "----------------------------------------\n",
            "\n",
            "🎯 SIMPLE EVOLUTION:\n",
            "   1. Considering the regulatory standards outlined for academic years, how do the minimum credit or clock hour requirements differ between undergraduate and graduate or professional programs, and what implications might the absence of such minimum hour mandates for graduate and professional programs have on the definition of an academic year, the calculation of Title IV awards such as Pell Grants, and the timing or progression of Direct Loan disbursements?\n",
            "      Answer: The regulatory standards for an academic year differ notably between undergraduate programs and graduate or professional programs in terms of minimum credit or clock hour requirements:\n",
            "\n",
            "1. **Undergrad...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "   2. How does the measurement of academic progress differ between non-term academic calendars that utilize credit hours versus those that use clock hours, and in what specific scenarios might a term-based program be treated as a non-term program for Title IV purposes?\n",
            "      Answer: Academic progress measurement differs between non-term academic calendars using credit hours and those using clock hours primarily in the unit of measurement. In non-term academic calendars, classes d...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "\n",
            "🎯 MULTI CONTEXT EVOLUTION:\n",
            "   1. How do the requirements for instructional support and student engagement in asynchronous distance education programs compare to the structural differences between term-based, non-term, and subscription-based academic calendars, and what implications do these differences have for measuring academic progress and scheduling coursework?\n",
            "      Answer: Based strictly on the provided contexts, the requirements for instructional support and student engagement in asynchronous distance education programs reflect the need for flexibility in scheduling an...\n",
            "      Contexts: 2 context(s)\n",
            "\n",
            "   2. How does Volume 3’s consistent use of the term for educational institutions relate to the distinctions made between different academic calendar types, such as standard term, non-term, and subscription-based programs, in terms of Title IV financial aid administration?\n",
            "      Answer: Volume 3 of the Federal Student Aid (FSA) Handbook consistently uses the term \"school\" to refer to educational institutions, rather than alternating between \"institution,\" \"school,\" or \"college.\" This...\n",
            "      Contexts: 2 context(s)\n",
            "\n",
            "\n",
            "🎯 REASONING EVOLUTION:\n",
            "   1. Evolved Question:  \n",
            "If a full-time undergraduate student is enrolled in a program measured in semester credit hours and completes only 18 credit hours after 30 weeks of instructional time, how might this affect the school's ability to define the academic year and the student’s eligibility for Pell Grant awards? Explain the cause-and-effect relationship based on the regulatory minimums and the definition of an academic year.\n",
            "      Answer: Based on the provided context, the regulatory minimum standards for a full-time undergraduate student in an academic year are as follows:\n",
            "\n",
            "- For programs measured in credit hours, the academic year mu...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "   2. Evolved Question:  \n",
            "If a full-time undergraduate student is enrolled in a program measured in clock hours and the school defines the academic year as 900 clock hours but only 28 weeks of instructional time, how might this discrepancy affect the student's Pell Grant awards and the timing of Direct Loan disbursements, considering the regulatory minimums for both clock hours and weeks of instructional time? Explain the step-by-step reasoning behind the implications of this academic year definition.\n",
            "      Answer: Based on the provided context, here is a comprehensive explanation of how defining an academic year as 900 clock hours but only 28 weeks of instructional time might affect a full-time undergraduate st...\n",
            "      Contexts: 1 context(s)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display and analyze the synthetic data generation results\n",
        "import pandas as pd\n",
        "\n",
        "def display_results(results):\n",
        "    \"\"\"Display the synthetic data generation results in a structured format\"\"\"\n",
        "    \n",
        "    print(\"🔍 SYNTHETIC DATA GENERATION RESULTS ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Analyze evolved questions by type\n",
        "    evolved_questions = results[\"evolved_questions\"]\n",
        "    question_answers = results[\"question_answers\"]\n",
        "    question_contexts = results[\"question_contexts\"]\n",
        "    \n",
        "    # Create DataFrame for better visualization\n",
        "    questions_df = pd.DataFrame(evolved_questions)\n",
        "    \n",
        "    print(f\"\\n📊 EVOLUTION TYPE DISTRIBUTION:\")\n",
        "    print(\"-\" * 30)\n",
        "    if not questions_df.empty:\n",
        "        type_counts = questions_df['evolution_type'].value_counts()\n",
        "        for evo_type, count in type_counts.items():\n",
        "            print(f\"  {evo_type}: {count} questions\")\n",
        "    \n",
        "    print(f\"\\n💡 SAMPLE EVOLVED QUESTIONS BY TYPE:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for evo_type in [EvolutionType.SIMPLE.value, EvolutionType.MULTI_CONTEXT.value, EvolutionType.REASONING.value]:\n",
        "        type_questions = [q for q in evolved_questions if q['evolution_type'] == evo_type]\n",
        "        if type_questions:\n",
        "            print(f\"\\n🎯 {evo_type.upper().replace('_', ' ')}:\")\n",
        "            for i, q in enumerate(type_questions[:2], 1):  # Show first 2 of each type\n",
        "                print(f\"   {i}. {q['question']}\")\n",
        "                \n",
        "                # Find corresponding answer\n",
        "                answer = next((a['answer'] for a in question_answers if a['question_id'] == q['id']), \"No answer found\")\n",
        "                print(f\"      Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\")\n",
        "                \n",
        "                # Find corresponding contexts\n",
        "                context_info = next((c for c in question_contexts if c['question_id'] == q['id']), None)\n",
        "                if context_info:\n",
        "                    print(f\"      Contexts: {len(context_info['contexts'])} context(s)\")\n",
        "                print()\n",
        "    \n",
        "    return questions_df\n",
        "\n",
        "# Display the results\n",
        "results_df = display_results(synthetic_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 📋 Step 10: Final Output Formatting and Export\n",
        "\n",
        "This step formats the generated synthetic data according to the specified requirements and exports the results for use in evaluation frameworks. The output follows the exact structure requested in the assignment.\n",
        "\n",
        "**Required Output Formats:**\n",
        "1. **Evolved Questions**: List of dictionaries with question IDs, questions, evolution types, and complexity levels\n",
        "2. **Question Answers**: List of dictionaries linking question IDs to their corresponding answers\n",
        "3. **Question Contexts**: List of dictionaries associating question IDs with their relevant document contexts\n",
        "\n",
        "**Export Features:**\n",
        "- **JSON Export**: Saves results in a structured format for easy loading and analysis\n",
        "- **Validation Summary**: Confirms all required outputs are present and properly formatted\n",
        "- **Data Integrity**: Ensures consistency between questions, answers, and contexts\n",
        "\n",
        "**Usage Ready:**\n",
        "The exported data can be directly imported into evaluation frameworks, LangSmith datasets, or other synthetic data evaluation pipelines. The structured format makes it easy to work with programmatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📋 FINAL OUTPUT SUMMARY:\n",
            "==================================================\n",
            "✅ Evolved Questions: 7 items\n",
            "✅ Question Answers: 7 items\n",
            "✅ Question Contexts: 7 items\n",
            "\n",
            "💾 Results saved to 'langgraph_synthetic_data.json'\n"
          ]
        }
      ],
      "source": [
        "# Create the final output in the required format\n",
        "def format_final_output(results):\n",
        "    \"\"\"Format results according to the specified requirements\"\"\"\n",
        "    \n",
        "    evolved_questions = results[\"evolved_questions\"]\n",
        "    question_answers = results[\"question_answers\"]\n",
        "    question_contexts = results[\"question_contexts\"]\n",
        "    \n",
        "    # Format 1: List[dict] - Evolved Questions, their IDs, and their Evolution Type\n",
        "    evolved_questions_output = [\n",
        "        {\n",
        "            \"question_id\": q[\"id\"],\n",
        "            \"question\": q[\"question\"],\n",
        "            \"evolution_type\": q[\"evolution_type\"],\n",
        "            \"complexity_level\": q[\"complexity_level\"]\n",
        "        }\n",
        "        for q in evolved_questions\n",
        "    ]\n",
        "    \n",
        "    # Format 2: List[dict] - Question IDs and Answer to the referenced Evolved Question\n",
        "    question_answers_output = [\n",
        "        {\n",
        "            \"question_id\": qa[\"question_id\"],\n",
        "            \"answer\": qa[\"answer\"]\n",
        "        }\n",
        "        for qa in question_answers\n",
        "    ]\n",
        "    \n",
        "    # Format 3: List[dict] - Question IDs and the relevant Context(s) to the Evolved Question\n",
        "    question_contexts_output = [\n",
        "        {\n",
        "            \"question_id\": qc[\"question_id\"],\n",
        "            \"contexts\": qc[\"contexts\"]\n",
        "        }\n",
        "        for qc in question_contexts\n",
        "    ]\n",
        "    \n",
        "    return {\n",
        "        \"evolved_questions\": evolved_questions_output,\n",
        "        \"question_answers\": question_answers_output,\n",
        "        \"question_contexts\": question_contexts_output\n",
        "    }\n",
        "\n",
        "# Format the final output\n",
        "final_output = format_final_output(synthetic_results)\n",
        "\n",
        "print(\"📋 FINAL OUTPUT SUMMARY:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"✅ Evolved Questions: {len(final_output['evolved_questions'])} items\")\n",
        "print(f\"✅ Question Answers: {len(final_output['question_answers'])} items\")\n",
        "print(f\"✅ Question Contexts: {len(final_output['question_contexts'])} items\")\n",
        "\n",
        "# Save results to JSON for later use\n",
        "import json\n",
        "with open(\"langgraph_synthetic_data.json\", \"w\") as f:\n",
        "    json.dump(final_output, f, indent=2)\n",
        "\n",
        "print(f\"\\n💾 Results saved to 'langgraph_synthetic_data.json'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔄 Comparison: LangGraph vs. RAGAS Knowledge Graph Approach\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "| Aspect | RAGAS Knowledge Graph | LangGraph + Evol Instruct |\n",
        "|--------|----------------------|---------------------------|\n",
        "| **Architecture** | Knowledge Graph with nodes and relationships | Agent-based workflow with sequential processing |\n",
        "| **Question Evolution** | Graph-based similarity and relationships | Prompt-based evolution with specific strategies |\n",
        "| **Evolution Types** | SingleHop, MultiHop Abstract/Specific | Simple, Multi-Context, Reasoning |\n",
        "| **Context Handling** | Automatic relationship discovery | Explicit context selection and combination |\n",
        "| **Scalability** | Graph complexity grows with data | Linear processing with controlled complexity |\n",
        "| **Customization** | Limited to graph transformations | Highly customizable prompts and evolution strategies |\n",
        "| **Processing Flow** | Parallel graph operations | Sequential workflow with defined stages |\n",
        "\n",
        "### Advantages of LangGraph Approach\n",
        "\n",
        "1. **🎯 Targeted Evolution**: Each evolution type has specific prompts designed for particular question characteristics\n",
        "2. **🔧 Customizable**: Easy to modify prompts and add new evolution strategies\n",
        "3. **📊 Transparent**: Clear workflow with visible processing stages\n",
        "4. **⚡ Efficient**: No need to build complex graph relationships\n",
        "5. **🎮 Controllable**: Direct control over question complexity and evolution paths\n",
        "\n",
        "### Output Quality\n",
        "\n",
        "The LangGraph approach provides:\n",
        "- More focused question evolution based on specific strategies\n",
        "- Better control over question-answer consistency\n",
        "- Explicit handling of multi-context scenarios\n",
        "- Clear traceability from base questions to evolved versions\n",
        "\n",
        "This implementation demonstrates how modern agent-based approaches can effectively replace traditional graph-based methods for synthetic data generation while providing greater flexibility and control.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 📖 Step 11: Usage Guide and System Overview\n",
        "\n",
        "This final step provides a complete usage guide and demonstrates how to use the LangGraph-based synthetic data generation system. It includes practical examples and showcases the system's capabilities.\n",
        "\n",
        "**System Capabilities:**\n",
        "- **Document Input**: Accepts any list of LangChain Document objects\n",
        "- **Flexible Configuration**: Customizable iteration counts and evolution parameters  \n",
        "- **Multiple Evolution Types**: Supports Simple, Multi-Context, and Reasoning evolution strategies\n",
        "- **Structured Output**: Provides exactly the format required for evaluation frameworks\n",
        "\n",
        "**Usage Benefits:**\n",
        "- **Easy Integration**: Simple function call interface for immediate use\n",
        "- **Scalable Processing**: Handles any number of input documents\n",
        "- **Quality Control**: Built-in validation and error handling\n",
        "- **Extensible Design**: Easy to add new evolution strategies or modify existing ones\n",
        "\n",
        "**Real-World Applications:**\n",
        "This system can be used for creating evaluation datasets, testing RAG systems, generating training data for question-answering models, and benchmarking information retrieval systems. The Evol Instruct approach ensures high-quality, challenging questions that properly test system capabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🚀 LangGraph Synthetic Data Generation System Usage Guide\n",
        "\n",
        "### 📖 Usage Example\n",
        "\n",
        "```python\n",
        "# 1. Import your documents\n",
        "documents = [Document(page_content=\"...\", metadata={...}), ...]\n",
        "\n",
        "# 2. Run the generation\n",
        "results = run_synthetic_data_generation(documents, max_iterations=1)\n",
        "\n",
        "# 3. Access the outputs\n",
        "evolved_questions = results[\"evolved_questions\"]  # Questions with IDs and evolution types\n",
        "question_answers = results[\"question_answers\"]    # Question IDs with their answers\n",
        "question_contexts = results[\"question_contexts\"]  # Question IDs with relevant contexts\n",
        "```\n",
        "\n",
        "### 📊 Sample Output Structure\n",
        "\n",
        "#### 🎯 Evolved Questions Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Evolution Type**: simple_evolution\n",
        "- **Question**: \"Considering the regulatory standards outlined for academic years, how do the minimum credit or clock...\"\n",
        "- **Complexity Level**: 2\n",
        "\n",
        "#### 💬 Question Answers Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Answer**: \"The regulatory standards for an academic year differ notably between undergraduate programs and grad...\"\n",
        "\n",
        "#### 📝 Question Contexts Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Number of Contexts**: 1\n",
        "- **First Context**: \"Credit or Clock Hours in an Academic Year For undergraduate educational programs, the law and regula...\"\n",
        "\n",
        "### 🎉 System Successfully Implemented!\n",
        "\n",
        "- **Total Questions Generated**: 7\n",
        "- **Evolution Types Supported**: Simple, Multi-Context, Reasoning\n",
        "- **Output Format**: Structured dictionaries with IDs and metadata\n",
        "- **Export Format**: JSON file (langgraph_synthetic_data.json) ready for evaluation frameworks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07ab3dc0790241bbb85a7f488a42ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7710c7377cbc4c30b55b28b4bc99e88f",
              "IPY_MODEL_41bdd49fab5f4826959d0d50663ff539",
              "IPY_MODEL_60168d85131d4afc99d55d61ab954ee6"
            ],
            "layout": "IPY_MODEL_9edf898aeeab40dda9b9475395776521"
          }
        },
        "095f680d37a3430fb82d223615662db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b44cb0f8e34446c8dde668a75d3d8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10df31709059484c99f102453d780473": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1160a44dc18e47b0890f70c40eaa7eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11c7f66acc1d45be9517d0addf49331e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122b1bd1f0e9417a8dcb57d4eebe4d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c233ad01604540a6c873f4a731982d",
              "IPY_MODEL_e9a01115c75b499884f7e0ef32e9e599",
              "IPY_MODEL_5faba4ad609448b2b49024add4ad3b8e"
            ],
            "layout": "IPY_MODEL_ef25efa751304e4699910f1fbc14345f"
          }
        },
        "158212a630f04cbd884c937f2f60f5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1d54ccd56494c4d831f71b416a1f880",
            "placeholder": "​",
            "style": "IPY_MODEL_530f696feefe499da08c6312047379b2",
            "value": " 20/? [01:43&lt;00:00,  5.25s/it]"
          }
        },
        "23863bc37a8645029934b8c106622c51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2508d229935744cbb5fc340222e2d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a0755d4476543feb4a64538e3e37213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20b539cd70b4ba99601ad1d69fd9cec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6d681eeafa44d18b933a4c5dec88382",
            "value": 1
          }
        },
        "33f063017b7c4c7fa8cbafc89674350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6864c81e2bcf459bbaf5acbb36bdfcbe",
              "IPY_MODEL_59d6e269eadf429a924f6f79bc8ba4ba",
              "IPY_MODEL_ca791fc471e34b9da2f9070fc1053c0f"
            ],
            "layout": "IPY_MODEL_8baf0ed3d0f743f294e07f2b5407e820"
          }
        },
        "3a8537e37fc14fd9b16ca0ceee4fede6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bdd49fab5f4826959d0d50663ff539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eb8b2e3262c45248708a2082c366f0a",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_095f680d37a3430fb82d223615662db5",
            "value": 64
          }
        },
        "530f696feefe499da08c6312047379b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59d6e269eadf429a924f6f79bc8ba4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_890e0dd7fa524ceca1e805cb6253ee71",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b52ff459214129b8f7e6d67b192b78",
            "value": 20
          }
        },
        "5ab5f08afa5841709aedb2f78a52a11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2fda99d4204d85b1bf7ad354fd58d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5faba4ad609448b2b49024add4ad3b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849b5c95008541d49f1ceedf0a59ac60",
            "placeholder": "​",
            "style": "IPY_MODEL_f3665a86662746c4ac7cb0796604781d",
            "value": " 20/? [01:27&lt;00:00,  6.45s/it]"
          }
        },
        "60168d85131d4afc99d55d61ab954ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8537e37fc14fd9b16ca0ceee4fede6",
            "placeholder": "​",
            "style": "IPY_MODEL_1160a44dc18e47b0890f70c40eaa7eb0",
            "value": " 61/64 [00:02&lt;00:00, 23.36it/s]"
          }
        },
        "61b52ff459214129b8f7e6d67b192b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6864c81e2bcf459bbaf5acbb36bdfcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10df31709059484c99f102453d780473",
            "placeholder": "​",
            "style": "IPY_MODEL_2508d229935744cbb5fc340222e2d660",
            "value": "Generating: 100%"
          }
        },
        "6eb8b2e3262c45248708a2082c366f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7710c7377cbc4c30b55b28b4bc99e88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c2fda99d4204d85b1bf7ad354fd58d4",
            "placeholder": "​",
            "style": "IPY_MODEL_93cd4d35c5fd41f5904ca1d52d1f52a8",
            "value": "embedding nodes:  95%"
          }
        },
        "7cb241365f604419af454c1c28de197a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7dce19ac55264f2b88a0e4730e55867b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddffd834e09940a4bd3874c3f39b4e21",
            "placeholder": "​",
            "style": "IPY_MODEL_ef63c3b2d51e452da03cdae5d9b034be",
            "value": ""
          }
        },
        "849b5c95008541d49f1ceedf0a59ac60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "890e0dd7fa524ceca1e805cb6253ee71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8baf0ed3d0f743f294e07f2b5407e820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cd4d35c5fd41f5904ca1d52d1f52a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cf586576ff44dba86ba2eb389593c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9edf898aeeab40dda9b9475395776521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a6d681eeafa44d18b933a4c5dec88382": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8dcc0895054529af356da401c513f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dce19ac55264f2b88a0e4730e55867b",
              "IPY_MODEL_2a0755d4476543feb4a64538e3e37213",
              "IPY_MODEL_158212a630f04cbd884c937f2f60f5c8"
            ],
            "layout": "IPY_MODEL_11c7f66acc1d45be9517d0addf49331e"
          }
        },
        "c20b539cd70b4ba99601ad1d69fd9cec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca791fc471e34b9da2f9070fc1053c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23863bc37a8645029934b8c106622c51",
            "placeholder": "​",
            "style": "IPY_MODEL_5ab5f08afa5841709aedb2f78a52a11c",
            "value": " 20/20 [00:52&lt;00:00,  4.50s/it]"
          }
        },
        "d1d54ccd56494c4d831f71b416a1f880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddffd834e09940a4bd3874c3f39b4e21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c233ad01604540a6c873f4a731982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b44cb0f8e34446c8dde668a75d3d8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_edaac6587b2d4bd5be52b89bb097f99f",
            "value": ""
          }
        },
        "e9a01115c75b499884f7e0ef32e9e599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cb241365f604419af454c1c28de197a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cf586576ff44dba86ba2eb389593c61",
            "value": 1
          }
        },
        "edaac6587b2d4bd5be52b89bb097f99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef25efa751304e4699910f1fbc14345f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef63c3b2d51e452da03cdae5d9b034be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3665a86662746c4ac7cb0796604781d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
