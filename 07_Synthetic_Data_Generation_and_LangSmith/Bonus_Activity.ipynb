{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üèóÔ∏è BONUS ACTIVITY: LangGraph-Based Synthetic Data Generation with Evol Instruct\n",
        "\n",
        "This notebook contains the bonus activity from the main synthetic data generation assignment. Here we implement a LangGraph-based approach using the Evol Instruct methodology as an alternative to the traditional Knowledge Graph approach used by RAGAS.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Evol Instruct method focuses on evolving simple questions into more complex ones through various transformation techniques:\n",
        "\n",
        "- **Simple Evolution**: Basic complexity increases\n",
        "- **Multi-Context Evolution**: Questions requiring multiple document contexts\n",
        "- **Reasoning Evolution**: Questions requiring multi-step reasoning\n",
        "\n",
        "Our LangGraph agent will process documents and generate evolved questions with their corresponding answers and contexts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Requirements\n",
        "\n",
        "Reproduce the RAGAS Synthetic Data Generation Steps - but utilize a LangGraph Agent Graph, instead of the Knowledge Graph approach.\n",
        "\n",
        "This generation should leverage the [Evol Instruct](https://arxiv.org/pdf/2304.12244) method to generate synthetic data.\n",
        "\n",
        "Your final state (output) should contain (at least, not limited to):\n",
        "\n",
        "1. `List(dict)`: Evolved Questions, their IDs, and their Evolution Type.\n",
        "2. `List(dict)`: Question IDs, and Answer to the referenced Evolved Question.\n",
        "3. `List(dict)`: Question IDs, and the relevant Context(s) to the Evolved Question.\n",
        "\n",
        "The Graph should handle:\n",
        "\n",
        "1. Simple Evolution.\n",
        "2. Multi-Context Evolution.\n",
        "3. Reasoning Evolution.\n",
        "\n",
        "It should take, as input, a list of LangChain Documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üéØ Step 1: Import Dependencies and Define Core Types\n",
        "\n",
        "The first step in our LangGraph implementation is to import the necessary libraries and define the fundamental data types we'll use throughout our synthetic data generation system.\n",
        "\n",
        "**Key Components:**\n",
        "- **LangGraph**: For building our agent workflow with nodes and edges\n",
        "- **TypedDict & Dataclasses**: For structured data handling and type safety\n",
        "- **EvolutionType Enum**: Defines the three evolution strategies we'll implement\n",
        "\n",
        "This foundational setup ensures our system is well-typed and organized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Core Python imports\n",
        "import os\n",
        "import getpass\n",
        "import json\n",
        "import random\n",
        "import uuid\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "# LangGraph imports for agent workflow\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# LangChain core imports\n",
        "from langchain.schema import Document, StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# LangChain OpenAI integration\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# LangChain community loaders (for loading documents)\n",
        "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "# LangChain core runnables\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from operator import itemgetter\n",
        "\n",
        "# LangSmith for evaluation\n",
        "from langsmith import Client\n",
        "\n",
        "# Data analysis\n",
        "import pandas as pd\n",
        "\n",
        "print(\"‚úÖ All imports loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîë API Keys Setup\n",
        "\n",
        "Set up the required API keys for OpenAI and LangSmith integration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up LangSmith tracing and API key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "\n",
        "# Set a project name for LangSmith tracking\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - Bonus SDG - {uuid.uuid4().hex[0:8]}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìÑ Document Loading\n",
        "\n",
        "Load documents from the data directory for synthetic data generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 269 documents from data/\n"
          ]
        }
      ],
      "source": [
        "# Load documents from the data directory\n",
        "try:\n",
        "    path = \"data/\"\n",
        "    # Use type ignore to handle loader_cls type compatibility\n",
        "    loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)  # type: ignore\n",
        "    docs = loader.load()\n",
        "    print(f\"‚úÖ Loaded {len(docs)} documents from {path}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading documents: {e}\")\n",
        "    print(\"Creating sample documents for demonstration...\")\n",
        "    # Create sample documents if loading fails\n",
        "    docs = [\n",
        "        Document(page_content=\"This is a sample document about loan programs and eligibility criteria.\", metadata={\"source\": \"sample1\"}),\n",
        "        Document(page_content=\"Federal student aid provides funding for undergraduate and graduate students.\", metadata={\"source\": \"sample2\"}),\n",
        "        Document(page_content=\"Academic calendars determine the timing of financial aid disbursements.\", metadata={\"source\": \"sample3\"})\n",
        "    ]\n",
        "    print(f\"‚úÖ Created {len(docs)} sample documents for demonstration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for LangGraph and Evol Instruct implementation\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "import uuid\n",
        "from langchain.schema import Document\n",
        "from enum import Enum\n",
        "import json\n",
        "\n",
        "# Define evolution types\n",
        "class EvolutionType(Enum):\n",
        "    SIMPLE = \"simple_evolution\"\n",
        "    MULTI_CONTEXT = \"multi_context_evolution\"\n",
        "    REASONING = \"reasoning_evolution\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üèóÔ∏è Step 2: Define Data Structures for Synthetic Data Generation\n",
        "\n",
        "Here we create the data structures that will hold our synthetic data throughout the generation process. These dataclasses provide a clean, typed interface for working with our evolved questions and their associated metadata.\n",
        "\n",
        "**Data Structures:**\n",
        "- **EvolvedQuestion**: Contains the evolved question text, its unique ID, evolution type, source contexts, and complexity level\n",
        "- **QuestionAnswer**: Links question IDs to their generated answers\n",
        "- **QuestionContext**: Associates question IDs with their relevant document contexts\n",
        "- **SyntheticDataState**: The complete state object that flows through our LangGraph workflow\n",
        "\n",
        "These structures ensure data consistency and make it easy to track relationships between questions, answers, and contexts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define data structures for synthetic data generation\n",
        "\n",
        "@dataclass\n",
        "class EvolvedQuestion:\n",
        "    \"\"\"Represents an evolved question with metadata\"\"\"\n",
        "    id: str\n",
        "    question: str\n",
        "    evolution_type: EvolutionType\n",
        "    source_context_ids: List[str]\n",
        "    complexity_level: int\n",
        "\n",
        "@dataclass \n",
        "class QuestionAnswer:\n",
        "    \"\"\"Represents a question-answer pair\"\"\"\n",
        "    question_id: str\n",
        "    answer: str\n",
        "\n",
        "@dataclass\n",
        "class QuestionContext:\n",
        "    \"\"\"Represents question with its relevant contexts\"\"\"\n",
        "    question_id: str\n",
        "    contexts: List[str]\n",
        "\n",
        "# Define the state for our LangGraph\n",
        "class SyntheticDataState(TypedDict):\n",
        "    documents: List[Document]\n",
        "    base_questions: List[Dict[str, Any]]\n",
        "    evolved_questions: List[Dict[str, Any]]\n",
        "    question_answers: List[Dict[str, Any]]\n",
        "    question_contexts: List[Dict[str, Any]]\n",
        "    current_iteration: int\n",
        "    max_iterations: int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üìù Step 3: Define Evolution Prompts Based on Evol Instruct Methodology\n",
        "\n",
        "This step implements the core of the Evol Instruct approach through carefully crafted prompts. Each evolution type has a specialized prompt designed to transform simple questions into more complex, challenging versions.\n",
        "\n",
        "**Evolution Strategies:**\n",
        "1. **Simple Evolution**: Increases complexity while maintaining answerability from the original context\n",
        "2. **Multi-Context Evolution**: Creates questions requiring synthesis from multiple document sources\n",
        "3. **Reasoning Evolution**: Develops questions that require logical inference and multi-step thinking\n",
        "\n",
        "**Additional Prompts:**\n",
        "- **Answer Generation**: Ensures answers are grounded in the provided contexts\n",
        "- **Base Question Generation**: Creates foundational questions from document content\n",
        "\n",
        "These prompts are the \"intelligence\" of our system, encoding the strategies for creating high-quality synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define prompts for different evolution types\n",
        "\n",
        "SIMPLE_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at evolving questions to make them more complex while maintaining their essence.\n",
        "\n",
        "            Given the following context and base question, create a more complex version of the question.\n",
        "            The evolved question should:\n",
        "            1. Require deeper understanding of the content\n",
        "            2. Be more specific and detailed\n",
        "            3. Still be answerable from the given context\n",
        "\n",
        "            Context: {context}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "MULTI_CONTEXT_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at creating questions that require information from multiple sources.\n",
        "\n",
        "            Given the following contexts and base question, create a question that requires synthesizing information from multiple contexts.\n",
        "            The evolved question should:\n",
        "            1. Require information from at least 2 different contexts\n",
        "            2. Ask for comparison, relationship, or synthesis\n",
        "            3. Be more complex than the original question\n",
        "\n",
        "            Contexts:\n",
        "            {contexts}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "REASONING_EVOLUTION_PROMPT = \"\"\"\n",
        "            You are an expert at creating questions that require multi-step reasoning.\n",
        "\n",
        "            Given the following context and base question, create a question that requires logical reasoning, inference, or multi-step thinking.\n",
        "            The evolved question should:\n",
        "            1. Require the reader to make logical connections\n",
        "            2. Involve cause-and-effect relationships or implications\n",
        "            3. Require step-by-step reasoning to answer\n",
        "\n",
        "            Context: {context}\n",
        "\n",
        "            Base Question: {base_question}\n",
        "\n",
        "            Evolved Question:\"\"\"\n",
        "\n",
        "ANSWER_GENERATION_PROMPT = \"\"\"\n",
        "            You are an expert at answering questions based on provided context.\n",
        "\n",
        "            Given the following context(s) and question, provide a comprehensive and accurate answer.\n",
        "            Base your answer strictly on the information provided in the context(s).\n",
        "\n",
        "            Context(s):\n",
        "            {contexts}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Answer:\"\"\"\n",
        "\n",
        "BASE_QUESTION_GENERATION_PROMPT = \"\"\"\n",
        "            You are an expert at generating simple, foundational questions from document content.\n",
        "\n",
        "            Given the following document content, generate 3-5 simple, factual questions that can be answered directly from the content.\n",
        "            The questions should be:\n",
        "            1. Clear and straightforward\n",
        "            2. Answerable from the given content\n",
        "            3. Cover different aspects of the content\n",
        "            4. Suitable for evolution into more complex questions\n",
        "\n",
        "            Content: {content}\n",
        "\n",
        "            Generate questions in this format:\n",
        "            1. [Question 1]\n",
        "            2. [Question 2]\n",
        "            3. [Question 3]\n",
        "            etc.\n",
        "\n",
        "            Questions:\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### ‚öôÔ∏è Step 4: Initialize LLM and Create Base Question Generation Node\n",
        "\n",
        "This step sets up the language model that will power our synthetic data generation and implements the first node in our LangGraph workflow. The base question generation node is responsible for extracting foundational questions from each document that will later be evolved into more complex forms.\n",
        "\n",
        "**Key Functions:**\n",
        "- **Base Question Generation**: Creates simple, factual questions from document content\n",
        "- **Simple Evolution Node**: Transforms basic questions into more complex versions\n",
        "- **Question Parsing**: Extracts and cleans questions from LLM responses\n",
        "\n",
        "The base questions serve as the foundation for all subsequent evolution steps, so their quality is crucial for the final output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LLM for synthetic data generation\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Initialize LLM - update this to match your preferred model\n",
        "synthetic_llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
        "\n",
        "def generate_base_questions(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Generate base questions from documents\"\"\"\n",
        "    print(\"üîÑ Generating base questions from documents...\")\n",
        "    \n",
        "    base_questions = []\n",
        "    \n",
        "    for i, doc in enumerate(state[\"documents\"]):\n",
        "        prompt = ChatPromptTemplate.from_template(BASE_QUESTION_GENERATION_PROMPT)\n",
        "        \n",
        "        # Get questions for this document\n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(content=doc.page_content[:2000])  # Limit content length\n",
        "        )\n",
        "        \n",
        "        # Parse the response to extract questions\n",
        "        questions_text = str(response.content) if hasattr(response, 'content') else str(response)\n",
        "        questions = []\n",
        "        \n",
        "        for line in questions_text.split('\\n'):\n",
        "            if line.strip() and (line.strip().startswith(tuple('123456789')) or line.strip().startswith('-')):\n",
        "                # Clean up the question\n",
        "                question = line.split('.', 1)[-1].strip() if '.' in line else line.strip()\n",
        "                question = question.lstrip('- ').strip()\n",
        "                if question and question.endswith('?'):\n",
        "                    questions.append(question)\n",
        "        \n",
        "        # Add questions with metadata\n",
        "        for question in questions[:3]:  # Limit to 3 questions per document\n",
        "            base_questions.append({\n",
        "                \"id\": str(uuid.uuid4()),\n",
        "                \"question\": question,\n",
        "                \"source_doc_index\": i,\n",
        "                \"context\": doc.page_content\n",
        "            })\n",
        "    \n",
        "    state[\"base_questions\"] = base_questions\n",
        "    print(f\"‚úÖ Generated {len(base_questions)} base questions\")\n",
        "    return state\n",
        "\n",
        "def simple_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply simple evolution to base questions\"\"\"\n",
        "    print(\"üîÑ Applying simple evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions for simple evolution\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(3, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        prompt = ChatPromptTemplate.from_template(SIMPLE_EVOLUTION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                context=base_q[\"context\"][:1500],\n",
        "                base_question=base_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        evolved_question = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"question\": str(response.content).strip() if hasattr(response, 'content') else str(response).strip(),\n",
        "            \"evolution_type\": EvolutionType.SIMPLE.value,\n",
        "            \"source_context_ids\": [base_q[\"id\"]],\n",
        "            \"complexity_level\": 2\n",
        "        }\n",
        "        \n",
        "        evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"‚úÖ Created {len(questions_to_evolve)} simple evolved questions\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üîÑ Step 5: Implement Advanced Evolution Nodes\n",
        "\n",
        "This step implements the more sophisticated evolution strategies that transform simple questions into complex, multi-dimensional challenges. These nodes represent the core innovation of the Evol Instruct methodology.\n",
        "\n",
        "**Evolution Strategies:**\n",
        "- **Multi-Context Evolution**: Combines information from multiple documents to create questions requiring synthesis\n",
        "- **Reasoning Evolution**: Develops questions that require logical inference and step-by-step thinking\n",
        "\n",
        "**Key Features:**\n",
        "- **Context Selection**: Intelligently chooses relevant contexts from different documents\n",
        "- **Complexity Scaling**: Assigns complexity levels to track question difficulty\n",
        "- **Randomized Selection**: Ensures diverse question types and prevents overfitting to specific documents\n",
        "\n",
        "These evolution nodes are what differentiate our approach from simple question generation, creating truly challenging evaluation scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multi_context_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply multi-context evolution to questions\"\"\"\n",
        "    print(\"üîÑ Applying multi-context evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions and pair them with multiple contexts\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(2, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        # Select additional contexts from other documents\n",
        "        other_docs = [doc for i, doc in enumerate(state[\"documents\"]) \n",
        "                     if i != base_q[\"source_doc_index\"]]\n",
        "        \n",
        "        if other_docs:\n",
        "            additional_context = random.choice(other_docs).page_content[:1000]\n",
        "            combined_contexts = f\"Context 1:\\n{base_q['context'][:1000]}\\n\\nContext 2:\\n{additional_context}\"\n",
        "            \n",
        "            prompt = ChatPromptTemplate.from_template(MULTI_CONTEXT_EVOLUTION_PROMPT)\n",
        "            \n",
        "            response = synthetic_llm.invoke(\n",
        "                prompt.format_messages(\n",
        "                    contexts=combined_contexts,\n",
        "                    base_question=base_q[\"question\"]\n",
        "                )\n",
        "            )\n",
        "            \n",
        "            evolved_question = {\n",
        "                \"id\": str(uuid.uuid4()),\n",
        "                \"question\": str(response.content).strip() if hasattr(response, 'content') else str(response).strip(),\n",
        "                \"evolution_type\": EvolutionType.MULTI_CONTEXT.value,\n",
        "                \"source_context_ids\": [base_q[\"id\"], \"additional_context\"],\n",
        "                \"complexity_level\": 3\n",
        "            }\n",
        "            \n",
        "            evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"‚úÖ Created {len(questions_to_evolve)} multi-context evolved questions\")\n",
        "    return state\n",
        "\n",
        "def reasoning_evolution_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Apply reasoning evolution to questions\"\"\"\n",
        "    print(\"üîÑ Applying reasoning evolution...\")\n",
        "    \n",
        "    evolved_questions = state[\"evolved_questions\"].copy()\n",
        "    \n",
        "    # Select random base questions for reasoning evolution\n",
        "    questions_to_evolve = random.sample(\n",
        "        state[\"base_questions\"], \n",
        "        min(2, len(state[\"base_questions\"]))\n",
        "    )\n",
        "    \n",
        "    for base_q in questions_to_evolve:\n",
        "        prompt = ChatPromptTemplate.from_template(REASONING_EVOLUTION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                context=base_q[\"context\"][:1500],\n",
        "                base_question=base_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        evolved_question = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"question\": str(response.content).strip() if hasattr(response, 'content') else str(response).strip(),\n",
        "            \"evolution_type\": EvolutionType.REASONING.value,\n",
        "            \"source_context_ids\": [base_q[\"id\"]],\n",
        "            \"complexity_level\": 4\n",
        "        }\n",
        "        \n",
        "        evolved_questions.append(evolved_question)\n",
        "    \n",
        "    state[\"evolved_questions\"] = evolved_questions\n",
        "    print(f\"‚úÖ Created {len(questions_to_evolve)} reasoning evolved questions\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üí¨ Step 6: Answer Generation and Context Extraction\n",
        "\n",
        "This step completes the synthetic data generation pipeline by creating high-quality answers for the evolved questions and organizing the relevant contexts. This ensures each generated question has both a ground-truth answer and the supporting context needed for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_answers_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Generate answers for all evolved questions\"\"\"\n",
        "    print(\"üîÑ Generating answers for evolved questions...\")\n",
        "    \n",
        "    question_answers = []\n",
        "    \n",
        "    for evolved_q in state[\"evolved_questions\"]:\n",
        "        # Find relevant contexts for this question\n",
        "        contexts = []\n",
        "        \n",
        "        if evolved_q[\"evolution_type\"] == EvolutionType.MULTI_CONTEXT.value:\n",
        "            # For multi-context questions, use multiple document contexts\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1000])\n",
        "            \n",
        "            # Add additional context from other documents\n",
        "            other_docs = [doc for doc in state[\"documents\"]]\n",
        "            if other_docs:\n",
        "                additional_context = random.choice(other_docs).page_content[:1000]\n",
        "                contexts.append(additional_context)\n",
        "        else:\n",
        "            # For simple and reasoning questions, use the original context\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1500])\n",
        "        \n",
        "        # Generate answer using the contexts\n",
        "        combined_contexts = \"\\n\\n\".join(f\"Context {i+1}:\\n{ctx}\" for i, ctx in enumerate(contexts))\n",
        "        \n",
        "        prompt = ChatPromptTemplate.from_template(ANSWER_GENERATION_PROMPT)\n",
        "        \n",
        "        response = synthetic_llm.invoke(\n",
        "            prompt.format_messages(\n",
        "                contexts=combined_contexts,\n",
        "                question=evolved_q[\"question\"]\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        answer = {\n",
        "            \"question_id\": evolved_q[\"id\"],\n",
        "            \"answer\": str(response.content).strip() if hasattr(response, 'content') else str(response).strip()\n",
        "        }\n",
        "        \n",
        "        question_answers.append(answer)\n",
        "    \n",
        "    state[\"question_answers\"] = question_answers\n",
        "    print(f\"‚úÖ Generated {len(question_answers)} answers\")\n",
        "    return state\n",
        "\n",
        "def extract_contexts_node(state: SyntheticDataState) -> SyntheticDataState:\n",
        "    \"\"\"Extract and organize contexts for each question\"\"\"\n",
        "    print(\"üîÑ Extracting contexts for questions...\")\n",
        "    \n",
        "    question_contexts = []\n",
        "    \n",
        "    for evolved_q in state[\"evolved_questions\"]:\n",
        "        contexts = []\n",
        "        \n",
        "        if evolved_q[\"evolution_type\"] == EvolutionType.MULTI_CONTEXT.value:\n",
        "            # For multi-context questions, include multiple contexts\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1000])\n",
        "            \n",
        "            # Add additional context\n",
        "            other_docs = [doc for doc in state[\"documents\"]]\n",
        "            if other_docs:\n",
        "                additional_context = random.choice(other_docs).page_content[:1000]\n",
        "                contexts.append(additional_context)\n",
        "        else:\n",
        "            # For simple and reasoning questions\n",
        "            base_context = next(\n",
        "                (bq[\"context\"] for bq in state[\"base_questions\"] \n",
        "                 if bq[\"id\"] in evolved_q[\"source_context_ids\"]), \n",
        "                \"\"\n",
        "            )\n",
        "            contexts.append(base_context[:1500])\n",
        "        \n",
        "        question_context = {\n",
        "            \"question_id\": evolved_q[\"id\"],\n",
        "            \"contexts\": contexts\n",
        "        }\n",
        "        \n",
        "        question_contexts.append(question_context)\n",
        "    \n",
        "    state[\"question_contexts\"] = question_contexts\n",
        "    print(f\"‚úÖ Extracted contexts for {len(question_contexts)} questions\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üèóÔ∏è Step 7: Create and Configure the LangGraph Workflow\n",
        "\n",
        "This step assembles all the individual nodes into a cohesive LangGraph workflow. The graph defines the execution order and data flow between different stages of the synthetic data generation process.\n",
        "\n",
        "**Workflow Architecture:**\n",
        "- **Sequential Processing**: Each evolution type runs in sequence to build upon previous results\n",
        "- **State Management**: The `SyntheticDataState` flows through each node, accumulating results\n",
        "- **Modular Design**: Each node is independent and can be modified or replaced easily\n",
        "\n",
        "**Execution Flow:**\n",
        "1. Generate base questions from documents\n",
        "2. Apply simple evolution transformations\n",
        "3. Apply multi-context evolution transformations\n",
        "4. Apply reasoning evolution transformations\n",
        "5. Generate answers for all evolved questions\n",
        "6. Extract and organize contexts\n",
        "\n",
        "This graph architecture ensures consistent, reproducible synthetic data generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the LangGraph for Synthetic Data Generation\n",
        "def create_synthetic_data_graph():\n",
        "    \"\"\"Create and configure the LangGraph for synthetic data generation\"\"\"\n",
        "    \n",
        "    # Initialize the graph\n",
        "    workflow = StateGraph(SyntheticDataState)\n",
        "    \n",
        "    # Add nodes to the graph\n",
        "    workflow.add_node(\"generate_base_questions\", generate_base_questions)\n",
        "    workflow.add_node(\"simple_evolution\", simple_evolution_node)\n",
        "    workflow.add_node(\"multi_context_evolution\", multi_context_evolution_node)\n",
        "    workflow.add_node(\"reasoning_evolution\", reasoning_evolution_node)\n",
        "    workflow.add_node(\"generate_answers\", generate_answers_node)\n",
        "    workflow.add_node(\"extract_contexts\", extract_contexts_node)\n",
        "    \n",
        "    # Define the flow\n",
        "    workflow.set_entry_point(\"generate_base_questions\")\n",
        "    \n",
        "    # After generating base questions, run all evolution types in sequence\n",
        "    workflow.add_edge(\"generate_base_questions\", \"simple_evolution\")\n",
        "    workflow.add_edge(\"simple_evolution\", \"multi_context_evolution\")\n",
        "    workflow.add_edge(\"multi_context_evolution\", \"reasoning_evolution\")\n",
        "    \n",
        "    # After all evolutions, generate answers and extract contexts\n",
        "    workflow.add_edge(\"reasoning_evolution\", \"generate_answers\")\n",
        "    workflow.add_edge(\"generate_answers\", \"extract_contexts\")\n",
        "    \n",
        "    # End the workflow\n",
        "    workflow.add_edge(\"extract_contexts\", END)\n",
        "    \n",
        "    return workflow.compile()\n",
        "\n",
        "# Create the graph\n",
        "synthetic_data_graph = create_synthetic_data_graph()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x11d603ed0>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_data_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üöÄ Step 8: Main Execution Function and Demo Run\n",
        "\n",
        "This step provides the main entry point for running the synthetic data generation system. The function handles initialization, execution, and result formatting, making it easy to use the system with any set of documents.\n",
        "\n",
        "**Main Function Features:**\n",
        "- **Easy Interface**: Simple function call with documents and optional parameters\n",
        "- **Progress Tracking**: Real-time feedback on generation progress\n",
        "- **Result Organization**: Structured output with all required data formats\n",
        "- **Error Handling**: Robust execution with proper state management\n",
        "\n",
        "**Demo Execution:**\n",
        "- Uses a subset of documents to demonstrate the system\n",
        "- Generates evolved questions across all three evolution types\n",
        "- Produces the final output in the required format (question IDs, answers, contexts)\n",
        "\n",
        "This demonstration shows the complete end-to-end workflow in action.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_synthetic_data_generation(documents: List[Document], max_iterations: int = 1) -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Run the synthetic data generation process\n",
        "    \n",
        "    Args:\n",
        "        documents: List of LangChain Document objects\n",
        "        max_iterations: Maximum number of iterations to run\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary containing evolved questions, answers, and contexts\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize the state\n",
        "    initial_state: SyntheticDataState = {\n",
        "        \"documents\": documents,\n",
        "        \"base_questions\": [],\n",
        "        \"evolved_questions\": [],\n",
        "        \"question_answers\": [],\n",
        "        \"question_contexts\": [],\n",
        "        \"current_iteration\": 0,\n",
        "        \"max_iterations\": max_iterations\n",
        "    }\n",
        "    \n",
        "    print(\"üöÄ Starting LangGraph-based Synthetic Data Generation with Evol Instruct\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Run the graph\n",
        "    final_state = synthetic_data_graph.invoke(initial_state)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üéâ Synthetic Data Generation Complete!\")\n",
        "    print(f\"üìä Generated {len(final_state['evolved_questions'])} evolved questions\")\n",
        "    print(f\"üí¨ Generated {len(final_state['question_answers'])} answers\")\n",
        "    print(f\"üìù Extracted {len(final_state['question_contexts'])} context sets\")\n",
        "    \n",
        "    return {\n",
        "        \"evolved_questions\": final_state[\"evolved_questions\"],\n",
        "        \"question_answers\": final_state[\"question_answers\"],\n",
        "        \"question_contexts\": final_state[\"question_contexts\"]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 5 documents from the main notebook\n",
            "üöÄ Starting LangGraph-based Synthetic Data Generation with Evol Instruct\n",
            "======================================================================\n",
            "üîÑ Generating base questions from documents...\n",
            "‚úÖ Generated 15 base questions\n",
            "üîÑ Applying simple evolution...\n",
            "‚úÖ Created 3 simple evolved questions\n",
            "üîÑ Applying multi-context evolution...\n",
            "‚úÖ Created 2 multi-context evolved questions\n",
            "üîÑ Applying reasoning evolution...\n",
            "‚úÖ Created 2 reasoning evolved questions\n",
            "üîÑ Generating answers for evolved questions...\n",
            "‚úÖ Generated 7 answers\n",
            "üîÑ Extracting contexts for questions...\n",
            "‚úÖ Extracted contexts for 7 questions\n",
            "\n",
            "======================================================================\n",
            "üéâ Synthetic Data Generation Complete!\n",
            "üìä Generated 7 evolved questions\n",
            "üí¨ Generated 7 answers\n",
            "üìù Extracted 7 context sets\n"
          ]
        }
      ],
      "source": [
        "# Demo execution - Load documents and run the generation\n",
        "# NOTE: You need to have documents loaded from the main notebook or load them here\n",
        "# For demonstration purposes, create some sample documents if none are available\n",
        "\n",
        "try:\n",
        "    # Try to use documents from the main notebook if available\n",
        "    if 'docs' in globals() and docs:\n",
        "        demo_docs = docs[:5]  # Use first 5 documents\n",
        "        print(f\"Using {len(demo_docs)} documents from the main notebook\")\n",
        "    else:\n",
        "        # Create sample documents for demonstration\n",
        "        sample_docs = [\n",
        "            Document(page_content=\"This is a sample document about loan programs and eligibility criteria.\", metadata={\"source\": \"sample1\"}),\n",
        "            Document(page_content=\"Federal student aid provides funding for undergraduate and graduate students.\", metadata={\"source\": \"sample2\"}),\n",
        "            Document(page_content=\"Academic calendars determine the timing of financial aid disbursements.\", metadata={\"source\": \"sample3\"})\n",
        "        ]\n",
        "        demo_docs = sample_docs\n",
        "        print(f\"Using {len(demo_docs)} sample documents for demonstration\")\n",
        "    \n",
        "    # Run the synthetic data generation\n",
        "    synthetic_results = run_synthetic_data_generation(demo_docs, max_iterations=1)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error running demonstration: {e}\")\n",
        "    print(\"Please ensure you have the required dependencies installed and documents loaded.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üìä Step 9: Results Analysis and Display\n",
        "\n",
        "This step provides comprehensive analysis and visualization of the generated synthetic data. It helps understand the distribution of evolution types, quality of questions, and overall system performance.\n",
        "\n",
        "**Analysis Features:**\n",
        "- **Evolution Type Distribution**: Shows how many questions were generated for each evolution strategy\n",
        "- **Sample Questions Display**: Provides examples of evolved questions with their answers and contexts\n",
        "- **Quality Assessment**: Demonstrates the complexity and diversity of generated questions\n",
        "- **Data Structure Validation**: Confirms all required outputs are properly formatted\n",
        "\n",
        "**Display Components:**\n",
        "- **Summary Statistics**: Quick overview of generation results\n",
        "- **Detailed Examples**: In-depth look at sample questions across all evolution types\n",
        "- **Context Analysis**: Shows how contexts are associated with different question types\n",
        "\n",
        "This analysis helps validate the effectiveness of the Evol Instruct approach and the quality of the synthetic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç SYNTHETIC DATA GENERATION RESULTS ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üìä EVOLUTION TYPE DISTRIBUTION:\n",
            "------------------------------\n",
            "  simple_evolution: 3 questions\n",
            "  multi_context_evolution: 2 questions\n",
            "  reasoning_evolution: 2 questions\n",
            "\n",
            "üí° SAMPLE EVOLVED QUESTIONS BY TYPE:\n",
            "----------------------------------------\n",
            "\n",
            "üéØ SIMPLE EVOLUTION:\n",
            "   1. Considering the scope and purpose of Volume 3 of the Federal Student Aid Handbook, how does this volume specifically address the interplay between academic calendars, payment periods, and disbursement requirements in the administration of Title IV student financial aid programs, and in what ways does it guide school financial aid administrators in accurately determining a student's cost of attendance and effectively packaging Title IV aid for the 2025-2026 award year?\n",
            "      Answer: Volume 3 of the Federal Student Aid (FSA) Handbook specifically addresses the interplay between academic calendars, payment periods, and disbursement requirements by providing detailed guidance on how...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "   2. Considering the definitions and distinctions between asynchronous and synchronous coursework, as well as the Department‚Äôs guidelines on instructional time and academic engagement, what specific conditions must a term or payment period meet in order to qualify as having scheduled days of study for examinations, and how do these conditions differ in programs offered through distance education or correspondence courses compared to traditional in-person programs?\n",
            "      Answer: To qualify as having scheduled days of study for examinations within a term or payment period, the following specific condition must be met:\n",
            "\n",
            "- At least one scheduled day of study for examinations occ...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "\n",
            "üéØ MULTI CONTEXT EVOLUTION:\n",
            "   1. How do the minimum clock hour requirements for a full-time undergraduate student in an academic year compare to the credit hour requirements, and how do different academic calendar types (term, non-term, and subscription-based) affect the measurement and definition of these hours for Title IV purposes?\n",
            "      Answer: The minimum coursework requirements for a full-time undergraduate student in an academic year are established by law and regulations and differ based on whether the program is measured in credit hours...\n",
            "      Contexts: 2 context(s)\n",
            "\n",
            "   2. How do the definitions and structuring of academic years differ between term-based, non-term, and subscription-based programs for Title IV purposes, and what are the implications of these differences on measuring academic progress and disbursing financial aid?\n",
            "      Answer: Based strictly on the provided context, the definitions and structuring of academic years for Title IV purposes vary depending on the nature of the academic program‚Äîwhether term-based, non-term, or ot...\n",
            "      Contexts: 2 context(s)\n",
            "\n",
            "\n",
            "üéØ REASONING EVOLUTION:\n",
            "   1. Evolved Question:  \n",
            "How does the requirement for at least one scheduled day of study for examinations within a term or payment period affect the calculation of instructional time, especially in programs using asynchronous coursework, and what implications does this have for determining whether students are meeting academic engagement expectations during that period?  \n",
            "\n",
            "**Explanation:**  \n",
            "Answering this question requires the reader to:  \n",
            "1. Connect the requirement of scheduled examination days to the structure of instructional time.  \n",
            "2. Understand how instructional time is defined and measured, particularly excluding breaks and non-engagement activities.  \n",
            "3. Consider the unique nature of asynchronous coursework where students work independently and the school provides resources rather than real-time interaction.  \n",
            "4. Infer how these factors collectively influence the assessment of academic engagement and compliance with regulatory expectations during the term or payment period.\n",
            "      Answer: The requirement that at least one scheduled day of study for examinations occurs within a term or payment period establishes a clear temporal anchor point that helps define the boundaries of instructi...\n",
            "      Contexts: 1 context(s)\n",
            "\n",
            "   2. Evolved Question:  \n",
            "If a graduate program does not have a minimum hour requirement for an academic year but is structured with 24 semester credit hours and 30 weeks of instructional time, how might this definition impact a student‚Äôs eligibility for Title IV financial aid awards such as Pell Grants or Direct Loans, considering the regulatory requirements for undergraduate programs and the school's academic calendar? Explain the steps and reasoning involved in determining the effects on aid disbursement and loan limit progression.\n",
            "      Answer: Based on the provided context, the impact of defining an academic year for a graduate program that has no minimum hour requirement but is structured with 24 semester credit hours and 30 weeks of instr...\n",
            "      Contexts: 1 context(s)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display and analyze the synthetic data generation results\n",
        "import pandas as pd\n",
        "\n",
        "def display_results(results):\n",
        "    \"\"\"Display the synthetic data generation results in a structured format\"\"\"\n",
        "    \n",
        "    print(\"üîç SYNTHETIC DATA GENERATION RESULTS ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Analyze evolved questions by type\n",
        "    evolved_questions = results[\"evolved_questions\"]\n",
        "    question_answers = results[\"question_answers\"]\n",
        "    question_contexts = results[\"question_contexts\"]\n",
        "    \n",
        "    # Create DataFrame for better visualization\n",
        "    questions_df = pd.DataFrame(evolved_questions)\n",
        "    \n",
        "    print(f\"\\nüìä EVOLUTION TYPE DISTRIBUTION:\")\n",
        "    print(\"-\" * 30)\n",
        "    if not questions_df.empty:\n",
        "        type_counts = questions_df['evolution_type'].value_counts()\n",
        "        for evo_type, count in type_counts.items():\n",
        "            print(f\"  {evo_type}: {count} questions\")\n",
        "    \n",
        "    print(f\"\\nüí° SAMPLE EVOLVED QUESTIONS BY TYPE:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for evo_type in [EvolutionType.SIMPLE.value, EvolutionType.MULTI_CONTEXT.value, EvolutionType.REASONING.value]:\n",
        "        type_questions = [q for q in evolved_questions if q['evolution_type'] == evo_type]\n",
        "        if type_questions:\n",
        "            print(f\"\\nüéØ {evo_type.upper().replace('_', ' ')}:\")\n",
        "            for i, q in enumerate(type_questions[:2], 1):  # Show first 2 of each type\n",
        "                print(f\"   {i}. {q['question']}\")\n",
        "                \n",
        "                # Find corresponding answer\n",
        "                answer = next((a['answer'] for a in question_answers if a['question_id'] == q['id']), \"No answer found\")\n",
        "                print(f\"      Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\")\n",
        "                \n",
        "                # Find corresponding contexts\n",
        "                context_info = next((c for c in question_contexts if c['question_id'] == q['id']), None)\n",
        "                if context_info:\n",
        "                    print(f\"      Contexts: {len(context_info['contexts'])} context(s)\")\n",
        "                print()\n",
        "    \n",
        "    return questions_df\n",
        "\n",
        "# Display the results if synthetic_results is available\n",
        "try:\n",
        "    if 'synthetic_results' in globals():\n",
        "        results_df = display_results(synthetic_results)\n",
        "    else:\n",
        "        print(\"No synthetic results available. Please run the generation first.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error displaying results: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üìã Step 10: Final Output Formatting and Export\n",
        "\n",
        "This step formats the generated synthetic data according to the specified requirements and exports the results for use in evaluation frameworks. The output follows the exact structure requested in the assignment.\n",
        "\n",
        "**Required Output Formats:**\n",
        "1. **Evolved Questions**: List of dictionaries with question IDs, questions, evolution types, and complexity levels\n",
        "2. **Question Answers**: List of dictionaries linking question IDs to their corresponding answers\n",
        "3. **Question Contexts**: List of dictionaries associating question IDs with their relevant document contexts\n",
        "\n",
        "**Export Features:**\n",
        "- **JSON Export**: Saves results in a structured format for easy loading and analysis\n",
        "- **Validation Summary**: Confirms all required outputs are present and properly formatted\n",
        "- **Data Integrity**: Ensures consistency between questions, answers, and contexts\n",
        "\n",
        "**Usage Ready:**\n",
        "The exported data can be directly imported into evaluation frameworks, LangSmith datasets, or other synthetic data evaluation pipelines. The structured format makes it easy to work with programmatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No synthetic results available. Please run the generation first.\n"
          ]
        }
      ],
      "source": [
        "# Create the final output in the required format\n",
        "def format_final_output(results):\n",
        "    \"\"\"Format results according to the specified requirements\"\"\"\n",
        "    \n",
        "    evolved_questions = results[\"evolved_questions\"]\n",
        "    question_answers = results[\"question_answers\"]\n",
        "    question_contexts = results[\"question_contexts\"]\n",
        "    \n",
        "    # Format 1: List[dict] - Evolved Questions, their IDs, and their Evolution Type\n",
        "    evolved_questions_output = [\n",
        "        {\n",
        "            \"question_id\": q[\"id\"],\n",
        "            \"question\": q[\"question\"],\n",
        "            \"evolution_type\": q[\"evolution_type\"],\n",
        "            \"complexity_level\": q[\"complexity_level\"]\n",
        "        }\n",
        "        for q in evolved_questions\n",
        "    ]\n",
        "    \n",
        "    # Format 2: List[dict] - Question IDs and Answer to the referenced Evolved Question\n",
        "    question_answers_output = [\n",
        "        {\n",
        "            \"question_id\": qa[\"question_id\"],\n",
        "            \"answer\": qa[\"answer\"]\n",
        "        }\n",
        "        for qa in question_answers\n",
        "    ]\n",
        "    \n",
        "    # Format 3: List[dict] - Question IDs and the relevant Context(s) to the Evolved Question\n",
        "    question_contexts_output = [\n",
        "        {\n",
        "            \"question_id\": qc[\"question_id\"],\n",
        "            \"contexts\": qc[\"contexts\"]\n",
        "        }\n",
        "        for qc in question_contexts\n",
        "    ]\n",
        "    \n",
        "    return {\n",
        "        \"evolved_questions\": evolved_questions_output,\n",
        "        \"question_answers\": question_answers_output,\n",
        "        \"question_contexts\": question_contexts_output\n",
        "    }\n",
        "\n",
        "# Format and export the results if available\n",
        "try:\n",
        "    if 'synthetic_results' in globals():\n",
        "        final_output = format_final_output(synthetic_results)\n",
        "        \n",
        "        print(\"üìã FINAL OUTPUT SUMMARY:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"‚úÖ Evolved Questions: {len(final_output['evolved_questions'])} items\")\n",
        "        print(f\"‚úÖ Question Answers: {len(final_output['question_answers'])} items\")\n",
        "        print(f\"‚úÖ Question Contexts: {len(final_output['question_contexts'])} items\")\n",
        "        \n",
        "        # Save results to JSON for later use\n",
        "        import json\n",
        "        with open(\"langgraph_synthetic_data.json\", \"w\") as f:\n",
        "            json.dump(final_output, f, indent=2)\n",
        "        \n",
        "        print(f\"\\nüíæ Results saved to 'langgraph_synthetic_data.json'\")\n",
        "    else:\n",
        "        print(\"No synthetic results available. Please run the generation first.\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error formatting output: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ Comparison: LangGraph vs. RAGAS Knowledge Graph Approach\n",
        "\n",
        "### Key Differences\n",
        "\n",
        "| Aspect | RAGAS Knowledge Graph | LangGraph + Evol Instruct |\n",
        "|--------|----------------------|---------------------------|\n",
        "| **Architecture** | Knowledge Graph with nodes and relationships | Agent-based workflow with sequential processing |\n",
        "| **Question Evolution** | Graph-based similarity and relationships | Prompt-based evolution with specific strategies |\n",
        "| **Evolution Types** | SingleHop, MultiHop Abstract/Specific | Simple, Multi-Context, Reasoning |\n",
        "| **Context Handling** | Automatic relationship discovery | Explicit context selection and combination |\n",
        "| **Scalability** | Graph complexity grows with data | Linear processing with controlled complexity |\n",
        "| **Customization** | Limited to graph transformations | Highly customizable prompts and evolution strategies |\n",
        "| **Processing Flow** | Parallel graph operations | Sequential workflow with defined stages |\n",
        "\n",
        "### Advantages of LangGraph Approach\n",
        "\n",
        "1. **üéØ Targeted Evolution**: Each evolution type has specific prompts designed for particular question characteristics\n",
        "2. **üîß Customizable**: Easy to modify prompts and add new evolution strategies\n",
        "3. **üìä Transparent**: Clear workflow with visible processing stages\n",
        "4. **‚ö° Efficient**: No need to build complex graph relationships\n",
        "5. **üéÆ Controllable**: Direct control over question complexity and evolution paths\n",
        "\n",
        "### Output Quality\n",
        "\n",
        "The LangGraph approach provides:\n",
        "- More focused question evolution based on specific strategies\n",
        "- Better control over question-answer consistency\n",
        "- Explicit handling of multi-context scenarios\n",
        "- Clear traceability from base questions to evolved versions\n",
        "\n",
        "This implementation demonstrates how modern agent-based approaches can effectively replace traditional graph-based methods for synthetic data generation while providing greater flexibility and control.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ LangGraph Synthetic Data Generation System Usage Guide\n",
        "\n",
        "### üìñ Usage Example\n",
        "\n",
        "```python\n",
        "# 1. Import your documents\n",
        "documents = [Document(page_content=\"...\", metadata={...}), ...]\n",
        "\n",
        "# 2. Run the generation\n",
        "results = run_synthetic_data_generation(documents, max_iterations=1)\n",
        "\n",
        "# 3. Access the outputs\n",
        "evolved_questions = results[\"evolved_questions\"]  # Questions with IDs and evolution types\n",
        "question_answers = results[\"question_answers\"]    # Question IDs with their answers\n",
        "question_contexts = results[\"question_contexts\"]  # Question IDs with relevant contexts\n",
        "```\n",
        "\n",
        "### üìä Sample Output Structure\n",
        "\n",
        "#### üéØ Evolved Questions Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Evolution Type**: simple_evolution\n",
        "- **Question**: \"Considering the regulatory standards outlined for academic years, how do the minimum credit or clock...\"\n",
        "- **Complexity Level**: 2\n",
        "\n",
        "#### üí¨ Question Answers Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Answer**: \"The regulatory standards for an academic year differ notably between undergraduate programs and grad...\"\n",
        "\n",
        "#### üìù Question Contexts Sample\n",
        "- **Question ID**: 01cafd87-d507-4cc4-ba5e-7a15cd1e09cc\n",
        "- **Number of Contexts**: 1\n",
        "- **First Context**: \"Credit or Clock Hours in an Academic Year For undergraduate educational programs, the law and regula...\"\n",
        "\n",
        "### üéâ System Successfully Implemented!\n",
        "\n",
        "- **Evolution Types Supported**: Simple, Multi-Context, Reasoning\n",
        "- **Output Format**: Structured dictionaries with IDs and metadata\n",
        "- **Export Format**: JSON file (langgraph_synthetic_data.json) ready for evaluation frameworks\n",
        "- **Usage**: Can be integrated into any evaluation pipeline or used standalone for synthetic data generation\n",
        "\n",
        "### üìö Real-World Applications\n",
        "\n",
        "This system can be used for:\n",
        "- Creating evaluation datasets for RAG systems\n",
        "- Generating training data for question-answering models\n",
        "- Benchmarking information retrieval systems\n",
        "- Testing synthetic data generation approaches\n",
        "- Academic research in natural language processing\n",
        "\n",
        "The Evol Instruct approach ensures high-quality, challenging questions that properly test system capabilities across different complexity levels and reasoning requirements.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
