{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\" id=\"heading\">OpenAI Agents SDK - AIM</h1>\n",
    "\n",
    "In this notebook, we'll go over some of the key features of the OpenAI Agents SDK - as explored through a notebook-ified version of their [Research Bot](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### You don't need to run this cell if you're running this notebook locally. \n",
    "\n",
    "#!pip install -qU openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nest Async:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "As may be expected, the primary thing we'll do in the Agents SDK is construct Agents!\n",
    "\n",
    "Agents are constructed with a few basic properties:\n",
    "\n",
    "- A prompt, which OpenAI is using the language \"instruction\" for, that determines the behaviour or goal of the Agent\n",
    "- A model, the \"brain\" of the Agent\n",
    "\n",
    "They also typically include an additional property: \n",
    "\n",
    "- Tool(s) that equip the Agent with things it can use to get stuff done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Create Planner Agent\n",
    "\n",
    "Let's start by creating our \"Planner Agent\" - which will come up with the initial set of search terms that should answer a query provided by the user. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from agents import Agent\n",
    "\n",
    "PLANNER_PROMPT = (\n",
    "    \"You are a helpful research assistant. Given a query, come up with a set of web searches to perform\" \n",
    "    \"to best answer the query. Output between 5 and 20 terms to query for.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the data models that our Planner Agent will use to structure its output. We'll create:\n",
    "\n",
    "1. `WebSearchItem` - A model for individual search items, containing the search query and reasoning\n",
    "2. `WebSearchPlan` - A container model that holds a list of search items\n",
    "\n",
    "These Pydantic models will help ensure our agent returns structured data that we can easily process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchItem(BaseModel):\n",
    "    reason: str\n",
    "    \"Your reasoning for why this search is important to the query.\"\n",
    "\n",
    "    query: str\n",
    "    \"The search term to use for the web search.\"\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem]\n",
    "    \"\"\"A list of web searches to perform to best answer the query.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Planner Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `PLANNER_PROMPT` and will output structured data in the form of our WebSearchPlan model. We're using the GPT-4o model for this agent to ensure high-quality search term generation.\n",
    "\n",
    "> NOTE: When we provide an `output_type` - the model will return a [structured response](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=PLANNER_PROMPT,\n",
    "    model=\"gpt-4.1\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓Question #1:\n",
    "\n",
    "Why is it important to provide a structured response template? (As in: Why are structured outputs helpful/preferred in Agentic workflows?)\n",
    "\n",
    "\n",
    "Looking at Question #1 from the notebook:\n",
    "\n",
    "##### ✅ Answer:\n",
    "Structured outputs are crucial in agentic workflows for several key reasons:\n",
    "\n",
    "**1. Reliability and Consistency**\n",
    "When agents return structured data (like the `WebSearchPlan` with defined fields), subsequent agents can reliably parse and process that information. Without structure, agents might return responses in varying formats, making it difficult for the next agent in the workflow to understand and act on the data.\n",
    "\n",
    "**2. Error Prevention**\n",
    "Structured outputs using Pydantic models provide built-in validation. If an agent tries to return data that doesn't match the expected schema (missing fields, wrong data types), the system catches these errors immediately rather than propagating invalid data through the workflow.\n",
    "\n",
    "**3. Seamless Agent Handoffs**\n",
    "In multi-agent systems like the research bot, each agent needs to pass specific information to the next. The Planner Agent's structured `WebSearchPlan` output becomes the exact input format the Search Agent expects. This creates clean, predictable interfaces between agents.\n",
    "\n",
    "**4. Programmatic Processing**\n",
    "Structured outputs enable automated processing. The `ResearchManager` can easily iterate through `search_plan.searches` because it knows the exact structure. With unstructured text, parsing would be error-prone and require complex regex or natural language processing.\n",
    "\n",
    "**5. Type Safety and IDE Support**\n",
    "Using Pydantic models provides type hints, enabling better IDE autocomplete, static analysis, and catch potential errors at development time rather than runtime.\n",
    "\n",
    "**6. Scalability**\n",
    "As workflows become more complex with multiple agents, structured interfaces prevent the \"telephone game\" effect where information gets corrupted as it passes between agents. Each agent knows exactly what format to expect and produce.\n",
    "\n",
    "**7. Debugging and Observability**\n",
    "Structured outputs make it easier to trace data flow through the system. When debugging, you can clearly see what each agent produced and verify it matches expectations.\n",
    "\n",
    "**8. Modularity**\n",
    "Well-defined structured interfaces allow agents to be developed, tested, and modified independently. As long as they maintain the same input/output contracts, internal implementations can change without breaking the overall workflow.\n",
    "\n",
    "In essence, structured outputs transform unpredictable AI responses into reliable, machine-readable data that enables robust, scalable agentic systems. They're the foundation that makes complex multi-agent workflows possible and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create Search Agent\n",
    "\n",
    "Now we'll create our Search Agent, which will be responsible for executing web searches based on the terms generated by the Planner Agent. This agent will take each search query, perform a web search using the `WebSearchTool`, and then summarize the results in a concise format.\n",
    "\n",
    "> NOTE: We are using the `WebSearchTool`, a hosted tool that can be used as part of an `OpenAIResponsesModel` as outlined in the [documentation](https://openai.github.io/openai-agents-python/tools/). This is based on the tools available through OpenAI's new [Responses API](https://openai.com/index/new-tools-for-building-agents/).\n",
    "\n",
    "The `SEARCH_PROMPT` below instructs the agent to create brief, focused summaries of search results. These summaries are designed to be 2-3 paragraphs, under 300 words, and capture only the essential information without unnecessary details. The goal is to provide the Writer Agent with clear, distilled information that can be efficiently synthesized into the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PROMPT = (\n",
    "    \"You are a research assistant. Given a search term, you search the web for that term and\"\n",
    "    \"produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300\"\n",
    "    \"words. Capture the main points. Write succinctly, no need to have complete sentences or good\"\n",
    "    \"grammar. This will be consumed by someone synthesizing a report, so its vital you capture the\"\n",
    "    \"essence and ignore any fluff. Do not include any additional commentary other than the summary\"\n",
    "    \"itself.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Search Agent using the Agent class from the OpenAI Agents SDK. This agent will use the instructions defined in `SEARCH_PROMPT` and will utilize the `WebSearchTool` to perform web searches. We're configuring it with `tool_choice=\"required\"` to ensure it always uses the search tool when processing requests.\n",
    "\n",
    "> NOTE: We can, as demonstrated, indicate how we want our model to use tools. You can read more about that at the bottom of the page [here](https://openai.github.io/openai-agents-python/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import WebSearchTool\n",
    "from agents.model_settings import ModelSettings\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=SEARCH_PROMPT,\n",
    "    tools=[WebSearchTool()],\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #2: \n",
    "\n",
    "What other tools are supported in OpenAI's Responses API?\n",
    "\n",
    "OpenAI's Responses API supports several types of tools beyond the `WebSearchTool` mentioned in the notebook:\n",
    "\n",
    "**Built-in Hosted Tools:**\n",
    "- **Web Search Preview** (`web_search_preview`) - For real-time web searches with configurable search context and user location\n",
    "- **Code Interpreter** (`code_interpreter`) - For executing Python code, data analysis, and file processing\n",
    "- **Image Generation** (`image_generation`) - For creating images using AI models\n",
    "- **File Search** - For searching through uploaded documents and files\n",
    "\n",
    "**Model Context Protocol (MCP) Tools:**\n",
    "- **MCP Tool** (`mcp`) - A powerful tool that connects to remote MCP servers, enabling integration with external services like:\n",
    "  - E-commerce platforms (Shopify, Allbirds, Alo Yoga)\n",
    "  - Development tools (GitHub, Sentry)\n",
    "  - Payment systems (Stripe)\n",
    "  - Communication services (Twilio)\n",
    "  - Documentation systems (GitMCP) [¹](https://cookbook.openai.com/examples/mcp/mcp_tool_guide)\n",
    "\n",
    "**Custom Function Tools:**\n",
    "- **Custom Functions** - User-defined tools that can be called by the model for specific business logic or API integrations [²](https://docs.exa.ai/reference/openai-responses-api-with-exa)\n",
    "\n",
    "**Key Features:**\n",
    "- **Tool Combinations**: Multiple tools can be used together in a single workflow\n",
    "- **Approval Controls**: Tools can require user approval before execution or run automatically\n",
    "- **Caching**: Tool definitions are cached to reduce latency in multi-turn conversations\n",
    "- **Filtering**: You can limit which tools are available using parameters like `allowed_tools` [¹](https://cookbook.openai.com/examples/mcp/mcp_tool_guide)\n",
    "\n",
    "The MCP tool is particularly powerful as it acts as a universal connector to external services, eliminating the need for custom backend integrations and reducing latency by allowing direct model-to-service communication. [¹](https://cookbook.openai.com/examples/mcp/mcp_tool_guide)\n",
    "\n",
    "**Citations:**\n",
    "1. [Guide to Using the Responses API's MCP Tool | OpenAI Cookbook](https://cookbook.openai.com/examples/mcp/mcp_tool_guide)\n",
    "2. [OpenAI Responses API - Exa Documentation](https://docs.exa.ai/reference/openai-responses-api-with-exa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Create Writer Agent\n",
    "\n",
    "Finally, we'll create our Writer Agent, which will synthesize all the research findings into a comprehensive report. This agent takes the original query and the research summaries from the Search Agent, then produces a structured report with follow-up questions.\n",
    "\n",
    "The Writer Agent will:\n",
    "1. Create an outline for the report structure\n",
    "2. Generate a detailed markdown report (5-10 pages)\n",
    "3. Provide follow-up questions for further research\n",
    "\n",
    "We'll define the prompt for this agent in the next cell. This prompt will instruct the Writer Agent on how to synthesize research findings into a comprehensive report with follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research \"\n",
    "    \"assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\\n\"\n",
    "    \"For the follow-up questions, provide exactly 5 unique questions that would help extend \"\n",
    "    \"this research. Do not repeat questions.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #1: \n",
    "\n",
    "This prompt is quite generic - modify this prompt to produce a report that is more personalized to either your personal preference, or more appropriate for a specific use case (eg. law domain research)\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "Shown in next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = (\n",
    "    \"You are a senior cybersecurity analyst and threat researcher tasked with writing a comprehensive \"\n",
    "    \"security assessment report for a research query. You will be provided with the original query \"\n",
    "    \"and initial research conducted by a research assistant.\\n\"\n",
    "    \"Your expertise includes threat intelligence, vulnerability assessment, incident response, \"\n",
    "    \"compliance frameworks, and emerging cyber threats.\\n\\n\"\n",
    "\n",
    "    \"Report Structure Requirements:\\n\"\n",
    "    \"1. Executive Summary - Brief overview for C-level executives (non-technical)\\n\"\n",
    "    \"2. Threat Landscape Overview - Current threat environment and key actors\\n\"\n",
    "    \"3. Technical Analysis - Detailed technical findings with CVE references where applicable\\n\"\n",
    "    \"4. Risk Assessment - Impact and likelihood analysis using CVSS scores or similar metrics\\n\"\n",
    "    \"5. Mitigation Strategies - Actionable recommendations with implementation timelines\\n\"\n",
    "    \"6. Compliance Considerations - Relevant frameworks (NIST, ISO 27001, SOC 2, etc.)\\n\"\n",
    "    \"7. Conclusion and Next Steps\\n\\n\"\n",
    "\n",
    "    \"Formatting Guidelines:\\n\"\n",
    "    \"- Use markdown format with clear section headers\\n\"\n",
    "    \"- Include risk ratings (Critical/High/Medium/Low) with color-coded indicators\\n\"\n",
    "    \"- Cite specific CVE numbers, threat actor groups, and security advisories\\n\"\n",
    "    \"- Provide actionable recommendations with priority levels\\n\"\n",
    "    \"- Target 7-12 pages of content, minimum 1500 words\\n\"\n",
    "    \"- Use tables for vulnerability matrices and timelines where appropriate\\n\\n\"\n",
    "\n",
    "    \"Writing Style:\\n\"\n",
    "    \"- Executive summary should be business-focused and jargon-free\\n\"\n",
    "    \"- Technical sections should include specific indicators of compromise (IOCs)\\n\"\n",
    "    \"- Maintain professional, authoritative tone throughout\\n\"\n",
    "    \"- Include estimated costs or resource requirements for major recommendations\\n\\n\"\n",
    "\n",
    "    \"Follow-up Questions:\\n\"\n",
    "    \"Generate exactly 5 strategic follow-up questions that would enhance this security analysis. \"\n",
    "    \"Focus on areas like threat hunting opportunities, additional attack vectors to investigate, \"\n",
    "    \"specific compliance gaps, or emerging threats in this domain. Ensure questions are unique \"\n",
    "    \"and actionable for further research.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will synthesize all the research findings into a comprehensive report. We're configuring it with the `ReportData` output type to structure the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str\n",
    "    \"\"\"A short 2-3 sentence summary of the findings.\"\"\"\n",
    "\n",
    "    markdown_report: str\n",
    "    \"\"\"The final report\"\"\"\n",
    "\n",
    "    follow_up_questions: list[str]\n",
    "    \"\"\"Suggested topics to research further\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll define our Writer Agent using the Agent class from the OpenAI Agents SDK. This agent will take the original query and research summaries, then synthesize them into a comprehensive report with follow-up questions. We've defined a custom output type called `ReportData` that structures the response with a short summary, markdown report, and follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=WRITER_PROMPT,\n",
    "    model=\"o3-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ❓ Question #3: \n",
    "\n",
    "Why are we electing to use a reasoning model for writing our report?\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "**Why are we electing to use a reasoning model for writing our report?**\n",
    "\n",
    "We're using a reasoning model (o3-mini) for the Writer Agent because report writing is a complex, multi-step cognitive task that benefits significantly from deliberate reasoning and planning.\n",
    "\n",
    "**1. Complex Synthesis Requirements:**\n",
    "Report writing involves synthesizing multiple sources of information from the Search Agent into a coherent, structured narrative. A reasoning model can better understand relationships between different pieces of information, identify contradictions, and create logical connections that produce more comprehensive and accurate reports.\n",
    "\n",
    "**2. Strategic Planning and Structure:**\n",
    "The Writer Agent needs to create an outline, organize content hierarchically, and ensure proper flow between sections. Reasoning models excel at this type of strategic planning, thinking through the optimal structure before writing and ensuring each section builds logically on the previous ones.\n",
    "\n",
    "**3. Quality and Depth of Analysis:**\n",
    "Reasoning models can perform deeper analysis of the research findings, drawing insights that go beyond simple summarization. They can identify patterns, implications, and connections that might be missed by faster, non-reasoning models, resulting in more valuable and actionable reports.\n",
    "\n",
    "**4. Consistency and Coherence:**\n",
    "Long-form content generation requires maintaining consistency in tone, style, and argumentation throughout the document. Reasoning models are better at maintaining this coherence across lengthy outputs, ensuring the report reads as a unified piece rather than disjointed sections.\n",
    "\n",
    "**5. Following Complex Instructions:**\n",
    "The Writer Agent has detailed formatting requirements, specific word counts, and needs to generate exactly 5 unique follow-up questions. Reasoning models are more reliable at following these complex, multi-part instructions precisely.\n",
    "\n",
    "**6. Error Detection and Self-Correction:**\n",
    "During the writing process, reasoning models can catch and correct their own errors, fact-check consistency, and ensure the report meets all specified requirements before finalizing the output.\n",
    "\n",
    "**7. Handling Ambiguity:**\n",
    "Research findings often contain ambiguous or conflicting information. Reasoning models can better navigate these complexities, clearly articulating uncertainties and providing balanced perspectives rather than making unfounded claims.\n",
    "\n",
    "**Trade-offs Consideration:**\n",
    "While reasoning models are slower and more token-intensive, the Writer Agent's task justifies this cost. Report quality is more important than speed for this final synthesis step, and the comprehensive nature of the output benefits from the deeper thinking that reasoning models provide.\n",
    "\n",
    "The investment in reasoning capability ensures the final report is professional, well-structured, and provides genuine value to the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Create Utility Classes \n",
    "\n",
    "We'll define utility classes to help with displaying progress and managing the research workflow. The Printer class below will provide real-time updates on the research process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Printer class provides real-time progress updates during the research process. It uses Rich's Live display to show dynamic content with spinners for in-progress items and checkmarks for completed tasks. The class maintains a dictionary of items with their completion status and can selectively hide checkmarks for specific items. This creates a clean, interactive console experience that keeps the user informed about the current state of the research workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from rich.console import Console, Group\n",
    "from rich.live import Live\n",
    "from rich.spinner import Spinner\n",
    "\n",
    "class Printer:\n",
    "    def __init__(self, console: Console):\n",
    "        self.live = Live(console=console)\n",
    "        self.items: dict[str, tuple[str, bool]] = {}\n",
    "        self.hide_done_ids: set[str] = set()\n",
    "        self.live.start()\n",
    "\n",
    "    def end(self) -> None:\n",
    "        self.live.stop()\n",
    "\n",
    "    def hide_done_checkmark(self, item_id: str) -> None:\n",
    "        self.hide_done_ids.add(item_id)\n",
    "\n",
    "    def update_item(\n",
    "        self, item_id: str, content: str, is_done: bool = False, hide_checkmark: bool = False\n",
    "    ) -> None:\n",
    "        self.items[item_id] = (content, is_done)\n",
    "        if hide_checkmark:\n",
    "            self.hide_done_ids.add(item_id)\n",
    "        self.flush()\n",
    "\n",
    "    def mark_item_done(self, item_id: str) -> None:\n",
    "        self.items[item_id] = (self.items[item_id][0], True)\n",
    "        self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        renderables: list[Any] = []\n",
    "        for item_id, (content, is_done) in self.items.items():\n",
    "            if is_done:\n",
    "                prefix = \"✅ \" if item_id not in self.hide_done_ids else \"\"\n",
    "                renderables.append(prefix + content)\n",
    "            else:\n",
    "                renderables.append(Spinner(\"dots\", text=content))\n",
    "        self.live.update(Group(*renderables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a ResearchManager class that will orchestrate the research process. This class will:\n",
    "1. Plan searches based on the query\n",
    "2. Perform those searches to gather information\n",
    "3. Write a comprehensive report based on the gathered information\n",
    "4. Display progress using our Printer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from agents import Runner, custom_span, gen_trace_id, trace\n",
    "\n",
    "class ResearchManager:\n",
    "    def __init__(self):\n",
    "        self.console = Console()\n",
    "        self.printer = Printer(self.console)\n",
    "\n",
    "    async def run(self, query: str) -> None:\n",
    "        trace_id = gen_trace_id()\n",
    "        with trace(\"Research trace\", trace_id=trace_id):\n",
    "            self.printer.update_item(\n",
    "                \"trace_id\",\n",
    "                f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "\n",
    "            self.printer.update_item(\n",
    "                \"starting\",\n",
    "                \"Starting research...\",\n",
    "                is_done=True,\n",
    "                hide_checkmark=True,\n",
    "            )\n",
    "            search_plan = await self._plan_searches(query)\n",
    "            search_results = await self._perform_searches(search_plan)\n",
    "            report = await self._write_report(query, search_results)\n",
    "\n",
    "            final_report = f\"Report summary\\n\\n{report.short_summary}\"\n",
    "            self.printer.update_item(\"final_report\", final_report, is_done=True)\n",
    "\n",
    "            self.printer.end()\n",
    "\n",
    "        print(\"\\n\\n=====REPORT=====\\n\\n\")\n",
    "        print(f\"Report: {report.markdown_report}\")\n",
    "        print(\"\\n\\n=====FOLLOW UP QUESTIONS=====\\n\\n\")\n",
    "        unique_questions = []\n",
    "        seen = set()\n",
    "        \n",
    "        for question in report.follow_up_questions:\n",
    "            if question not in seen:\n",
    "                unique_questions.append(question)\n",
    "                seen.add(question)\n",
    "        \n",
    "        for i, question in enumerate(unique_questions, 1):\n",
    "            print(f\"{i}. {question}\")\n",
    "\n",
    "    async def _plan_searches(self, query: str) -> WebSearchPlan:\n",
    "        self.printer.update_item(\"planning\", \"Planning searches...\")\n",
    "        result = await Runner.run(\n",
    "            planner_agent,\n",
    "            f\"Query: {query}\",\n",
    "        )\n",
    "        self.printer.update_item(\n",
    "            \"planning\",\n",
    "            f\"Will perform {len(result.final_output.searches)} searches\",\n",
    "            is_done=True,\n",
    "        )\n",
    "        return result.final_output_as(WebSearchPlan)\n",
    "\n",
    "    async def _perform_searches(self, search_plan: WebSearchPlan) -> list[str]:\n",
    "        with custom_span(\"Search the web\"):\n",
    "            self.printer.update_item(\"searching\", \"Searching...\")\n",
    "            num_completed = 0\n",
    "            max_concurrent = 5\n",
    "            results = []\n",
    "            \n",
    "            for i in range(0, len(search_plan.searches), max_concurrent):\n",
    "                batch = search_plan.searches[i:i+max_concurrent]\n",
    "                tasks = [asyncio.create_task(self._search(item)) for item in batch]\n",
    "                \n",
    "                for task in asyncio.as_completed(tasks):\n",
    "                    try:\n",
    "                        result = await task\n",
    "                        if result is not None:\n",
    "                            results.append(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Search error: {e}\")\n",
    "                        \n",
    "                    num_completed += 1\n",
    "                    self.printer.update_item(\n",
    "                        \"searching\", f\"Searching... {num_completed}/{len(search_plan.searches)} completed\"\n",
    "                    )\n",
    "            \n",
    "            self.printer.mark_item_done(\"searching\")\n",
    "            return results\n",
    "\n",
    "    async def _search(self, item: WebSearchItem) -> str | None:\n",
    "        input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "        try:\n",
    "            result = await Runner.run(\n",
    "                search_agent,\n",
    "                input,\n",
    "            )\n",
    "            return str(result.final_output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for '{item.query}': {e}\")\n",
    "            return None\n",
    "\n",
    "    async def _write_report(self, query: str, search_results: list[str]) -> ReportData:\n",
    "        self.printer.update_item(\"writing\", \"Thinking about report...\")\n",
    "        input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "        \n",
    "        result = Runner.run_streamed(\n",
    "            writer_agent,\n",
    "            input,\n",
    "        )\n",
    "        \n",
    "        update_messages = [\n",
    "            \"Thinking about report...\",\n",
    "            \"Planning report structure...\",\n",
    "            \"Writing outline...\",\n",
    "            \"Creating sections...\",\n",
    "            \"Cleaning up formatting...\",\n",
    "            \"Finalizing report...\",\n",
    "            \"Finishing report...\",\n",
    "        ]\n",
    "\n",
    "        last_update = time.time()\n",
    "        next_message = 0\n",
    "        \n",
    "        async for event in result.stream_events():\n",
    "            if time.time() - last_update > 5 and next_message < len(update_messages):\n",
    "                self.printer.update_item(\"writing\", update_messages[next_message])\n",
    "                next_message += 1\n",
    "                last_update = time.time()\n",
    "\n",
    "        self.printer.mark_item_done(\"writing\")\n",
    "        return result.final_output_as(ReportData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🏗️ Activity #2:\n",
    "\n",
    "Convert the above flow into a flowchart style image (software of your choosing, but if you're not sure which to use try [Excallidraw](https://excalidraw.com/)) that outlines how the different Agents interact with each other. \n",
    "\n",
    "> HINT: Cursor's AI (CMD+L or CTRL+L on Windows) would be a helpful way to get a basic diagram that you can add more detail to!\n",
    "\n",
    "##### ✅ Answer:\n",
    "\n",
    "![image](./img/diagram-1.png) \n",
    "![image](./img/diagram-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Running Our Agent\n",
    "\n",
    "Now let's run our agent! The main function below will prompt the user for a research topic, then pass that query to our ResearchManager to handle the entire research process. The ResearchManager will: \n",
    "\n",
    "1. Break down the query into search items\n",
    "2. Search for information on each item\n",
    "3. Write a comprehensive report based on the search results\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    query = input(\"What would you like to research? \")\n",
    "    await ResearchManager().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7983513b55a140e5892f0cad698e0ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=====REPORT=====\n",
      "\n",
      "\n",
      "Report: # Security Assessment Report for MCP Servers in Production Environments\n",
      "\n",
      "## Table of Contents\n",
      "\n",
      "1. [Executive Summary](#executive-summary)\n",
      "2. [Threat Landscape Overview](#threat-landscape-overview)\n",
      "3. [Technical Analysis](#technical-analysis)\n",
      "4. [Risk Assessment](#risk-assessment)\n",
      "5. [Mitigation Strategies](#mitigation-strategies)\n",
      "6. [Compliance Considerations](#compliance-considerations)\n",
      "7. [Conclusion and Next Steps](#conclusion-and-next-steps)\n",
      "\n",
      "---\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "In today’s digital economy, securing production systems is critical. MCP servers serve as an essential component within the Model Context Protocol ecosystem, enabling large language models (LLMs) and AI applications to interact with diverse data sources and external tools. However, the integration of these servers into production environments—especially for sensitive application security functions—introduces unique challenges. These challenges arise from emerging threats such as prompt injection, token theft, insecure authentication mechanisms, and operational misconfigurations.\n",
      "\n",
      "This report is designed for C-level executives and technical decision-makers. It provides an overview of the current threat environment related to MCP servers, a deep dive into technical vulnerabilities, a risk assessment incorporating impact and likelihood evaluations, and a detailed set of mitigation strategies along with relevant compliance and regulatory frameworks. The goal is to ensure that organizations implementing MCP servers in production can safeguard sensitive data, maintain system integrity, and achieve compliance with industry standards while fully leveraging the benefits of modular, scalable AI interactions.\n",
      "\n",
      "---\n",
      "\n",
      "## Threat Landscape Overview\n",
      "\n",
      "The current threat landscape for MCP servers is characterized by rapidly evolving attack vectors, largely due to the novelty of the Model Context Protocol and its integration with AI systems. Key observations include:\n",
      "\n",
      "- **Dynamic Attack Surfaces:** The open and modular nature of MCP servers increases attack surface areas. The need to integrate with various data sources, tools, and APIs introduces potential vulnerabilities if traditional security practices are not fully adapted to this new context.\n",
      "\n",
      "- **Emerging Threat Actors:** State-sponsored actors, cybercriminal groups, and hacktivists are actively probing for vulnerabilities in MCP implementations. Tactics like prompt injection attacks and tool poisoning have been documented and adopted by adversaries.\n",
      "\n",
      "- **Key Attack Techniques:** Notable attack methodologies include:\n",
      "  - **Prompt Injection:** Manipulating server inputs to alter AI behavior.\n",
      "  - **Tool Poisoning:** Injecting malicious tool definitions that later enable unauthorized access or data exfiltration.\n",
      "  - **Credential/Token Theft:** Exploiting weak authentication, hardcoded credentials, and obsolete encryption protocols.\n",
      "  - **Privilege Escalation:** Abusing dynamic interactions and permission management weaknesses.\n",
      "\n",
      "- **Incident References:** Several studies, including whitepapers and academic research, have documented the risks associated with MCP servers. Recent analyses highlight vulnerabilities that allow cross-tool exfiltration and remote code execution (RCE) in misconfigured deployments.\n",
      "\n",
      "These vulnerabilities are particularly concerning in production environments where MCP servers are essential for real-time data access and automation across domains such as healthcare, finance, and manufacturing.\n",
      "\n",
      "---\n",
      "\n",
      "## Technical Analysis\n",
      "\n",
      "The technical landscape of MCP servers has several dimensions that present both operational value and inherent risks. This section details the primary technical findings:\n",
      "\n",
      "### 1. Vulnerability Categories\n",
      "\n",
      "A comprehensive analysis of MCP servers has identified multiple vulnerability categories, including:\n",
      "\n",
      "| Vulnerability Type                  | Description                                                                                                                                         | Risk Rating           | Mitigation Strategy Summary                                      |\n",
      "|-------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|------------------------------------------------------------------|\n",
      "| **Prompt Injection**                | Attackers manipulate input data to inject malicious prompts that can alter MCP server behavior.                                                     | High (🔴)             | Input validation, strict schema enforcement, and output filtering |\n",
      "| **Tool Poisoning**                  | Malicious tools masquerade as benign, allowing unauthorized operations and data exfiltration.                                                      | High (🔴)             | Code signing, tool definition verification, and reputation scoring |\n",
      "| **Credential and Token Exposure**   | Hardcoded credentials, unencrypted tokens, and weak key management that lead to unauthorized access.                                              | Critical (🔴)         | Implement strong authentication (e.g., OAuth 2.0, mTLS) and secure key management practices |\n",
      "| **Insecure Authentication Mechanisms** | Reliance on outdated methods (e.g., simple username/password) making brute-force and dictionary attacks easier to execute.                             | Critical (🔴)         | Transition to advanced protocols like OAuth 2.0 with PKCE                           |\n",
      "| **Obsolete Encryption Protocols**   | Use of outmoded encryption methods (e.g., DES) or plaintext communications exposing data to eavesdropping and man-in-the-middle attacks.           | Critical (🔴)         | Enforce current encryption standards such as TLS 1.3 and AES-256         |\n",
      "| **Permission Management Complexity**| Difficulty in implementing fine-grained, function-level permissions leading to potential over-privileged access.                                      | Medium (🟠)           | Implement RBAC with regularly audited and minimal scope permissions       |\n",
      "| **Operational Misconfigurations**   | Persistent connections and local file system access required for MCP servers complicate container orchestration and result in misconfigurations.  | Medium (🟠)           | Enhance orchestration management and use secure container configurations |\n",
      "| **Lack of Logging/Observability**   | Inadequate logging and monitoring hinder rapid detection and remediation of potential breaches.                                                   | Medium (🟠)           | Integrate comprehensive SIEM solutions and real-time monitoring tools       |\n",
      "\n",
      "### 2. Protocol and Integration Challenges\n",
      "\n",
      "MCP servers serve a dual role by facilitating seamless integration for AI systems and serving as a gatekeeper for external resources. This dual functionality leads to several technical challenges:\n",
      "\n",
      "- **Dynamic Tool Discovery:** While dynamic discovery enhances flexibility, it also introduces risks if manifests are improperly secured, potentially enabling privilege escalation.\n",
      "\n",
      "- **Interoperability vs. Security:** The emphasis on standardization and interoperability may result in trade-offs where security hardening can be bypassed for ease of integration.\n",
      "\n",
      "- **Containerization and Scalability:** MCP servers deployed within Kubernetes or Docker containers may face issues related to persistent connections and state management, thereby impacting reliable operation and security controls.\n",
      "\n",
      "### 3. Real-World Exploits and Incident Examples\n",
      "\n",
      "Various documented cases underscore the risks associated with MCP servers:\n",
      "\n",
      "- **Remote Code Execution (RCE):** Several misconfigured MCP deployments have allowed RCE, enabling attackers to execute arbitrary commands. While a specific CVE is not yet attributed, analogous vulnerabilities have been documented in similar protocols (e.g., CVE-2024-XXXX).\n",
      "\n",
      "- **Preference Manipulation Attacks:** Recent academic studies describe how attackers can influence the decision matrix of LLMs by deploying malicious MCP servers that spoof legitimate service registries. These attacks, though in a nascent stage, highlight potential economic and reputational damages.\n",
      "\n",
      "- **Credential and API Key Leaks:** Incidents reported where hard-coded credentials and insecure token handling in MCP environments have resulted in unauthorized access and data exfiltration.\n",
      "\n",
      "The technical investigation of such incidents recommends a multi-layered defense strategy combining both traditional vulnerability management with innovations tailored for MCP-specific threats.\n",
      "\n",
      "---\n",
      "\n",
      "## Risk Assessment\n",
      "\n",
      "### Impact Analysis\n",
      "\n",
      "Given the critical role of MCP servers in managing sensitive data access and command execution in production environments, the following impact analysis is considered:\n",
      "\n",
      "- **Data Breach:** Exploits like token theft and credential exposure can lead to data compromise across integrated systems. The potential impact is classified as **Critical (🔴)** with CVSS scores that may exceed 9.0 in severe cases.\n",
      "\n",
      "- **Service Disruption:** Misconfigurations and vulnerabilities (e.g., RCE, tool poisoning) could disrupt AI service delivery and production operations, leading to operational downtimes and service level agreement (SLA) penalties. Classified as **High (🔴)** with potential CVSS 8.0+ ratings.\n",
      "\n",
      "- **Reputation Damage:** Unauthorized activities, especially those impacting customer data in industries like finance and healthcare, pose a significant risk to brand reputation. Likelihood of reputational damage is **High (🔴)** in scenarios of prolonged breaches.\n",
      "\n",
      "- **Regulatory Non-Compliance:** Failure to secure MCP servers adequately can result in violations of regulatory frameworks like GDPR, HIPAA, and SOC 2, with financial penalties and legal liabilities. Impact here is **Critical (🔴)**.\n",
      "\n",
      "### Likelihood Analysis\n",
      "\n",
      "The dynamic and evolving nature of MCP ecosystems increases the likelihood of the following risks:\n",
      "\n",
      "- **High Likelihood:** Attack vectors such as prompt injection, token theft, and insecure authentication are highly exploitable if not properly mitigated. The inherent design of MCP servers, which emphasizes rapid integration, compounds these risks.\n",
      "\n",
      "- **Medium Likelihood:** Misconfigurations in container orchestration and permission management, while less frequent, provide significant attack opportunities if neglected during deployment and maintenance.\n",
      "\n",
      "- **Low to Medium Likelihood:** Supply chain attacks and advanced persistent threats (APTs) targeting MCP vendors or third-party tools are emerging risks that need ongoing vigilance.\n",
      "\n",
      "### Risk Rating Summary\n",
      "\n",
      "| Risk Category                     | Impact      | Likelihood      | Overall Risk Rating |\n",
      "|-----------------------------------|-------------|-----------------|---------------------|\n",
      "| **Data Breach via Token/Credential Theft** | Critical (🔴) | High (🔴)      | Critical            |\n",
      "| **Remote Code Execution (RCE)**   | Critical (🔴) | Medium/High (🟠/🔴)  | High to Critical   |\n",
      "| **Service Disruption**            | High (🔴)   | High (🔴)       | High                |\n",
      "| **Prompt Injection**              | High (🔴)   | High (🔴)       | High                |\n",
      "| **Regulatory Non-Compliance**     | Critical (🔴) | Medium (🟠)      | Critical            |\n",
      "\n",
      "---\n",
      "\n",
      "## Mitigation Strategies\n",
      "\n",
      "To address the vulnerabilities and risks identified above, we propose the following actionable recommendations:\n",
      "\n",
      "### Immediate Actions (0-3 months)\n",
      "\n",
      "- **Enhance Authentication and Authorization**: \n",
      "  - Transition from outdated username/password combinations to secure authentication frameworks such as OAuth 2.0 with PKCE or mutual TLS (mTLS).\n",
      "  - Implement Role-Based Access Control (RBAC) with strict policy definitions.\n",
      "  - Estimated Cost: Medium investment in identity management solutions and integration resources.\n",
      "\n",
      "- **Secure Communications and Data Encryption**:\n",
      "  - Mandate TLS 1.3 and AES-256 encryption for all data in transit and at rest.\n",
      "  - Automate certificate rotation and key management.\n",
      "  - Estimated Cost: Low to medium, depending on existing infrastructure support.\n",
      "\n",
      "- **Strengthen Input Validation and Logging Practices:**\n",
      "  - Deploy strict data schemas and sanitization techniques to guard against prompt injection and tool poisoning.\n",
      "  - Integrate comprehensive logging with SIEM systems to monitor anomalous activities.\n",
      "  - Estimated Cost: Low to medium, building on existing logging infrastructures.\n",
      "\n",
      "### Medium-Term Actions (3-6 months)\n",
      "\n",
      "- **Container and Orchestration Hardening**:\n",
      "  - Optimize MCP server deployment configurations to ensure container isolation and secure orchestration in environments like Kubernetes.\n",
      "  - Conduct regular vulnerability scans using tools such as MCP Scanner, Bandit, and SonarQube.\n",
      "  - Estimated Cost: Medium - potential software licenses and workforce training.\n",
      "\n",
      "- **Implement Code Signing and Tool Verification:**\n",
      "  - Adopt code signing for all tool updates to prevent tool poisoning.\n",
      "  - Establish a reputation scoring mechanism for dynamically discovered tools.\n",
      "  - Estimated Cost: Low to medium, contingent on integration complexity.\n",
      "\n",
      "- **Penetration Testing and Security Audits:**\n",
      "  - Schedule periodic penetration testing and red team exercises focused on MCP-specific attack vectors.\n",
      "  - Maintain detailed audit trails for compliance and operational resilience.\n",
      "  - Estimated Cost: Medium to high, depending on the frequency of audits.\n",
      "\n",
      "### Long-Term Actions (6-12 months)\n",
      "\n",
      "- **Security Operations Center (SOC) Integration and Advanced Threat Detection:**\n",
      "  - Expand monitoring capabilities with AI-driven anomaly detection and behavior analytics specific to MCP interactions.\n",
      "  - Integrate with existing security infrastructure and establish alerts for prompt injection, permission creep, and unusual data flows.\n",
      "  - Estimated Cost: High - investments in advanced SIEM capabilities and specialist personnel.\n",
      "\n",
      "- **Supply Chain Security and Vendor Management:**\n",
      "  - Regularly assess third-party components and dependencies for vulnerabilities.\n",
      "  - Implement a comprehensive patch management program tailored for MCP servers, ensuring prompt remediation of newly discovered vulnerabilities.\n",
      "  - Estimated Cost: Medium to high, factoring in ongoing assessments and software updates.\n",
      "\n",
      "- **Continuous Training and Awareness:**\n",
      "  - Provide ongoing cybersecurity training to development and operations teams focused on emerging MCP-specific threats and best security practices.\n",
      "  - Estimated Cost: Low to medium, based on training resources and frequency of sessions.\n",
      "\n",
      "---\n",
      "\n",
      "## Compliance Considerations\n",
      "\n",
      "Ensuring that MCP servers comply with relevant industry standards is critical for avoiding legal ramifications and maintaining customer trust. Consider the following frameworks:\n",
      "\n",
      "- **NIST Cybersecurity Framework:**\n",
      "  - Align security controls with NIST guidelines to enhance risk management and incident response.\n",
      "  - Key Focus: Protect, Detect, Respond, and Recover functions.\n",
      "\n",
      "- **ISO 27001:**\n",
      "  - Implement an Information Security Management System (ISMS) to systematically manage sensitive information.\n",
      "  - Key Focus: Regular risk assessments and continuous improvement of security processes.\n",
      "\n",
      "- **SOC 2:**\n",
      "  - Ensure that security controls meet the Trust Service Criteria, enhancing the reliability and security of production systems.\n",
      "  - Key Focus: Availability, integrity, and confidentiality of data processes.\n",
      "\n",
      "- **GDPR/HIPAA (if applicable):**\n",
      "  - For organizations in regulated industries, ensure that data handling and processing comply with data protection requirements, including strong encryption and audit trails.\n",
      "\n",
      "Regular audits, compliance assessments, and integrated reporting tools should be harnessed to demonstrate adherence to these frameworks and to proactively address any deviations.\n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion and Next Steps\n",
      "\n",
      "MCP servers provide transformative benefits by enhancing the scalability, integration, and efficiency of AI-driven production systems. However, the evolving security landscape has revealed critical vulnerabilities that could jeopardize data security, system integrity, and regulatory compliance if left unaddressed.\n",
      "\n",
      "**Key Takeaways:**\n",
      "\n",
      "- The security risk associated with MCP servers is significant, particularly regarding prompt injection, tool poisoning, and insecure authentication mechanisms.\n",
      "- A layered security approach—encompassing secure communication protocols, strong authentication, rigorous input validation, comprehensive logging, and continuous monitoring—is essential to mitigate identified risks.\n",
      "- Compliance with frameworks such as NIST, ISO 27001, SOC 2, GDPR, and HIPAA is not only necessary for regulatory reasons but also serves as a benchmark for the overall security posture.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "1. **Immediate Remediation:** Prioritize patching and securing known vulnerabilities with a focus on authentication, encryption, and logging.\n",
      "2. **Conduct a Comprehensive Security Audit:** Engage third-party experts to perform a full security assessment and penetration test tailored to MCP server configurations.\n",
      "3. **Implement Continuous Monitoring:** Integrate advanced SIEM and anomaly detection systems to provide real-time threat intelligence focused on MCP-specific activities.\n",
      "4. **Staff Training & Policy Updates:** Educate development and operations teams on the unique security challenges of MCP implementations and update internal policies to reflect the latest best practices.\n",
      "5. **Ongoing Compliance Reviews:** Schedule regular compliance audits and update security frameworks to keep pace with evolving regulatory requirements and threat landscapes.\n",
      "\n",
      "By following these recommendations, organizations can leverage the benefits of MCP servers while maintaining a robust security posture, ensuring that production systems remain secure, resilient, and compliant in the long term.\n",
      "\n",
      "---\n",
      "\n",
      "## Appendices\n",
      "\n",
      "### Appendix A: Vulnerability Matrix and Timeline\n",
      "\n",
      "| Milestone                          | Action Item                                              | Timeline         | Priority  |\n",
      "|------------------------------------|----------------------------------------------------------|------------------|-----------|\n",
      "| 0-3 Months                         | Enhance authentication protocols (OAuth/mTLS)          | Immediate        | Critical  |\n",
      "| 0-3 Months                         | Enforce TLS 1.3, AES-256 encryption and automate certs   | Immediate        | Critical  |\n",
      "| 3-6 Months                         | Container hardening & vulnerability scanning             | Near-Term        | High      |\n",
      "| 3-6 Months                         | Implement code signing and tool verification mechanisms | Near-Term        | High      |\n",
      "| 6-12 Months                        | Integrate SOC and advanced threat monitoring systems     | Long-Term        | Critical  |\n",
      "| 6-12 Months                        | Establish supply chain security reviews & Continuous Training | Long-Term    | High      |\n",
      "\n",
      "### Appendix B: Resources and Tools\n",
      "\n",
      "- **Security Testing:** MCP Scanner, OWASP ZAP, Burp Suite\n",
      "- **Static Code Analysis:** Bandit, Semgrep, CodeQL\n",
      "- **Container Security:** Trivy, docker-bench-security\n",
      "- **Network Scanning:** Nmap, sslyze\n",
      "- **Compliance:** SIEM integrations, regular external audits\n",
      "\n",
      "---\n",
      "\n",
      "*This report is intended as a strategic guide for securing MCP servers. It is recommended that organizations tailor these recommendations to their specific operational environments and conduct periodic reviews to adapt to new threats and compliance requirements.*\n",
      "\n",
      "\n",
      "\n",
      "=====FOLLOW UP QUESTIONS=====\n",
      "\n",
      "\n",
      "1. How can organizations implement threat hunting frameworks specifically tailored for detecting prompt injection and tool poisoning attacks in MCP servers?\n",
      "2. What additional attack vectors should be evaluated for MCP servers, such as supply chain threats or exploitation through third-party dependencies?\n",
      "3. Which specific compliance gaps remain unaddressed in current MCP server implementations, particularly regarding evolving regulations like GDPR and HIPAA?\n",
      "4. How can integration of advanced monitoring tools and AI-driven anomaly detection further enhance the detection capabilities for MCP server vulnerabilities?\n",
      "5. What are the resource implications and estimated costs associated with transitioning from traditional authentication models to more secure options like OAuth 2.0 with PKCE and mTLS?\n"
     ]
    }
   ],
   "source": [
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Own Report in Markdown format\n",
    "\n",
    "## =====REPORT=====\n",
    "\n",
    "# Security Assessment Report for MCP Servers in Production Environments\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Executive Summary](#executive-summary)\n",
    "2. [Threat Landscape Overview](#threat-landscape-overview)\n",
    "3. [Technical Analysis](#technical-analysis)\n",
    "4. [Risk Assessment](#risk-assessment)\n",
    "5. [Mitigation Strategies](#mitigation-strategies)\n",
    "6. [Compliance Considerations](#compliance-considerations)\n",
    "7. [Conclusion and Next Steps](#conclusion-and-next-steps)\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "In today’s digital economy, securing production systems is critical. MCP servers serve as an essential component within the Model Context Protocol ecosystem, enabling large language models (LLMs) and AI applications to interact with diverse data sources and external tools. However, the integration of these servers into production environments—especially for sensitive application security functions—introduces unique challenges. These challenges arise from emerging threats such as prompt injection, token theft, insecure authentication mechanisms, and operational misconfigurations.\n",
    "\n",
    "This report is designed for C-level executives and technical decision-makers. It provides an overview of the current threat environment related to MCP servers, a deep dive into technical vulnerabilities, a risk assessment incorporating impact and likelihood evaluations, and a detailed set of mitigation strategies along with relevant compliance and regulatory frameworks. The goal is to ensure that organizations implementing MCP servers in production can safeguard sensitive data, maintain system integrity, and achieve compliance with industry standards while fully leveraging the benefits of modular, scalable AI interactions.\n",
    "\n",
    "---\n",
    "\n",
    "## Threat Landscape Overview\n",
    "\n",
    "The current threat landscape for MCP servers is characterized by rapidly evolving attack vectors, largely due to the novelty of the Model Context Protocol and its integration with AI systems. Key observations include:\n",
    "\n",
    "- **Dynamic Attack Surfaces:** The open and modular nature of MCP servers increases attack surface areas. The need to integrate with various data sources, tools, and APIs introduces potential vulnerabilities if traditional security practices are not fully adapted to this new context.\n",
    "\n",
    "- **Emerging Threat Actors:** State-sponsored actors, cybercriminal groups, and hacktivists are actively probing for vulnerabilities in MCP implementations. Tactics like prompt injection attacks and tool poisoning have been documented and adopted by adversaries.\n",
    "\n",
    "- **Key Attack Techniques:** Notable attack methodologies include:\n",
    "  - **Prompt Injection:** Manipulating server inputs to alter AI behavior.\n",
    "  - **Tool Poisoning:** Injecting malicious tool definitions that later enable unauthorized access or data exfiltration.\n",
    "  - **Credential/Token Theft:** Exploiting weak authentication, hardcoded credentials, and obsolete encryption protocols.\n",
    "  - **Privilege Escalation:** Abusing dynamic interactions and permission management weaknesses.\n",
    "\n",
    "- **Incident References:** Several studies, including whitepapers and academic research, have documented the risks associated with MCP servers. Recent analyses highlight vulnerabilities that allow cross-tool exfiltration and remote code execution (RCE) in misconfigured deployments.\n",
    "\n",
    "These vulnerabilities are particularly concerning in production environments where MCP servers are essential for real-time data access and automation across domains such as healthcare, finance, and manufacturing.\n",
    "\n",
    "---\n",
    "\n",
    "## Technical Analysis\n",
    "\n",
    "The technical landscape of MCP servers has several dimensions that present both operational value and inherent risks. This section details the primary technical findings:\n",
    "\n",
    "### 1. Vulnerability Categories\n",
    "\n",
    "A comprehensive analysis of MCP servers has identified multiple vulnerability categories, including:\n",
    "\n",
    "| Vulnerability Type                  | Description                                                                                                                                         | Risk Rating           | Mitigation Strategy Summary                                      |\n",
    "|-------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|------------------------------------------------------------------|\n",
    "| **Prompt Injection**                | Attackers manipulate input data to inject malicious prompts that can alter MCP server behavior.                                                     | High (🔴)             | Input validation, strict schema enforcement, and output filtering |\n",
    "| **Tool Poisoning**                  | Malicious tools masquerade as benign, allowing unauthorized operations and data exfiltration.                                                      | High (🔴)             | Code signing, tool definition verification, and reputation scoring |\n",
    "| **Credential and Token Exposure**   | Hardcoded credentials, unencrypted tokens, and weak key management that lead to unauthorized access.                                              | Critical (🔴)         | Implement strong authentication (e.g., OAuth 2.0, mTLS) and secure key management practices |\n",
    "| **Insecure Authentication Mechanisms** | Reliance on outdated methods (e.g., simple username/password) making brute-force and dictionary attacks easier to execute.                             | Critical (🔴)         | Transition to advanced protocols like OAuth 2.0 with PKCE                           |\n",
    "| **Obsolete Encryption Protocols**   | Use of outmoded encryption methods (e.g., DES) or plaintext communications exposing data to eavesdropping and man-in-the-middle attacks.           | Critical (🔴)         | Enforce current encryption standards such as TLS 1.3 and AES-256         |\n",
    "| **Permission Management Complexity**| Difficulty in implementing fine-grained, function-level permissions leading to potential over-privileged access.                                      | Medium (🟠)           | Implement RBAC with regularly audited and minimal scope permissions       |\n",
    "| **Operational Misconfigurations**   | Persistent connections and local file system access required for MCP servers complicate container orchestration and result in misconfigurations.  | Medium (🟠)           | Enhance orchestration management and use secure container configurations |\n",
    "| **Lack of Logging/Observability**   | Inadequate logging and monitoring hinder rapid detection and remediation of potential breaches.                                                   | Medium (🟠)           | Integrate comprehensive SIEM solutions and real-time monitoring tools       |\n",
    "\n",
    "### 2. Protocol and Integration Challenges\n",
    "\n",
    "MCP servers serve a dual role by facilitating seamless integration for AI systems and serving as a gatekeeper for external resources. This dual functionality leads to several technical challenges:\n",
    "\n",
    "- **Dynamic Tool Discovery:** While dynamic discovery enhances flexibility, it also introduces risks if manifests are improperly secured, potentially enabling privilege escalation.\n",
    "\n",
    "- **Interoperability vs. Security:** The emphasis on standardization and interoperability may result in trade-offs where security hardening can be bypassed for ease of integration.\n",
    "\n",
    "- **Containerization and Scalability:** MCP servers deployed within Kubernetes or Docker containers may face issues related to persistent connections and state management, thereby impacting reliable operation and security controls.\n",
    "\n",
    "### 3. Real-World Exploits and Incident Examples\n",
    "\n",
    "Various documented cases underscore the risks associated with MCP servers:\n",
    "\n",
    "- **Remote Code Execution (RCE):** Several misconfigured MCP deployments have allowed RCE, enabling attackers to execute arbitrary commands. While a specific CVE is not yet attributed, analogous vulnerabilities have been documented in similar protocols (e.g., CVE-2024-XXXX).\n",
    "\n",
    "- **Preference Manipulation Attacks:** Recent academic studies describe how attackers can influence the decision matrix of LLMs by deploying malicious MCP servers that spoof legitimate service registries. These attacks, though in a nascent stage, highlight potential economic and reputational damages.\n",
    "\n",
    "- **Credential and API Key Leaks:** Incidents reported where hard-coded credentials and insecure token handling in MCP environments have resulted in unauthorized access and data exfiltration.\n",
    "\n",
    "The technical investigation of such incidents recommends a multi-layered defense strategy combining both traditional vulnerability management with innovations tailored for MCP-specific threats.\n",
    "\n",
    "---\n",
    "\n",
    "## Risk Assessment\n",
    "\n",
    "### Impact Analysis\n",
    "\n",
    "Given the critical role of MCP servers in managing sensitive data access and command execution in production environments, the following impact analysis is considered:\n",
    "\n",
    "- **Data Breach:** Exploits like token theft and credential exposure can lead to data compromise across integrated systems. The potential impact is classified as **Critical (🔴)** with CVSS scores that may exceed 9.0 in severe cases.\n",
    "\n",
    "- **Service Disruption:** Misconfigurations and vulnerabilities (e.g., RCE, tool poisoning) could disrupt AI service delivery and production operations, leading to operational downtimes and service level agreement (SLA) penalties. Classified as **High (🔴)** with potential CVSS 8.0+ ratings.\n",
    "\n",
    "- **Reputation Damage:** Unauthorized activities, especially those impacting customer data in industries like finance and healthcare, pose a significant risk to brand reputation. Likelihood of reputational damage is **High (🔴)** in scenarios of prolonged breaches.\n",
    "\n",
    "- **Regulatory Non-Compliance:** Failure to secure MCP servers adequately can result in violations of regulatory frameworks like GDPR, HIPAA, and SOC 2, with financial penalties and legal liabilities. Impact here is **Critical (🔴)**.\n",
    "\n",
    "### Likelihood Analysis\n",
    "\n",
    "The dynamic and evolving nature of MCP ecosystems increases the likelihood of the following risks:\n",
    "\n",
    "- **High Likelihood:** Attack vectors such as prompt injection, token theft, and insecure authentication are highly exploitable if not properly mitigated. The inherent design of MCP servers, which emphasizes rapid integration, compounds these risks.\n",
    "\n",
    "- **Medium Likelihood:** Misconfigurations in container orchestration and permission management, while less frequent, provide significant attack opportunities if neglected during deployment and maintenance.\n",
    "\n",
    "- **Low to Medium Likelihood:** Supply chain attacks and advanced persistent threats (APTs) targeting MCP vendors or third-party tools are emerging risks that need ongoing vigilance.\n",
    "\n",
    "### Risk Rating Summary\n",
    "\n",
    "| Risk Category                     | Impact      | Likelihood      | Overall Risk Rating |\n",
    "|-----------------------------------|-------------|-----------------|---------------------|\n",
    "| **Data Breach via Token/Credential Theft** | Critical (🔴) | High (🔴)      | Critical            |\n",
    "| **Remote Code Execution (RCE)**   | Critical (🔴) | Medium/High (🟠/🔴)  | High to Critical   |\n",
    "| **Service Disruption**            | High (🔴)   | High (🔴)       | High                |\n",
    "| **Prompt Injection**              | High (🔴)   | High (🔴)       | High                |\n",
    "| **Regulatory Non-Compliance**     | Critical (🔴) | Medium (🟠)      | Critical            |\n",
    "\n",
    "---\n",
    "\n",
    "## Mitigation Strategies\n",
    "\n",
    "To address the vulnerabilities and risks identified above, we propose the following actionable recommendations:\n",
    "\n",
    "### Immediate Actions (0-3 months)\n",
    "\n",
    "- **Enhance Authentication and Authorization**: \n",
    "  - Transition from outdated username/password combinations to secure authentication frameworks such as OAuth 2.0 with PKCE or mutual TLS (mTLS).\n",
    "  - Implement Role-Based Access Control (RBAC) with strict policy definitions.\n",
    "  - Estimated Cost: Medium investment in identity management solutions and integration resources.\n",
    "\n",
    "- **Secure Communications and Data Encryption**:\n",
    "  - Mandate TLS 1.3 and AES-256 encryption for all data in transit and at rest.\n",
    "  - Automate certificate rotation and key management.\n",
    "  - Estimated Cost: Low to medium, depending on existing infrastructure support.\n",
    "\n",
    "- **Strengthen Input Validation and Logging Practices:**\n",
    "  - Deploy strict data schemas and sanitization techniques to guard against prompt injection and tool poisoning.\n",
    "  - Integrate comprehensive logging with SIEM systems to monitor anomalous activities.\n",
    "  - Estimated Cost: Low to medium, building on existing logging infrastructures.\n",
    "\n",
    "### Medium-Term Actions (3-6 months)\n",
    "\n",
    "- **Container and Orchestration Hardening**:\n",
    "  - Optimize MCP server deployment configurations to ensure container isolation and secure orchestration in environments like Kubernetes.\n",
    "  - Conduct regular vulnerability scans using tools such as MCP Scanner, Bandit, and SonarQube.\n",
    "  - Estimated Cost: Medium - potential software licenses and workforce training.\n",
    "\n",
    "- **Implement Code Signing and Tool Verification:**\n",
    "  - Adopt code signing for all tool updates to prevent tool poisoning.\n",
    "  - Establish a reputation scoring mechanism for dynamically discovered tools.\n",
    "  - Estimated Cost: Low to medium, contingent on integration complexity.\n",
    "\n",
    "- **Penetration Testing and Security Audits:**\n",
    "  - Schedule periodic penetration testing and red team exercises focused on MCP-specific attack vectors.\n",
    "  - Maintain detailed audit trails for compliance and operational resilience.\n",
    "  - Estimated Cost: Medium to high, depending on the frequency of audits.\n",
    "\n",
    "### Long-Term Actions (6-12 months)\n",
    "\n",
    "- **Security Operations Center (SOC) Integration and Advanced Threat Detection:**\n",
    "  - Expand monitoring capabilities with AI-driven anomaly detection and behavior analytics specific to MCP interactions.\n",
    "  - Integrate with existing security infrastructure and establish alerts for prompt injection, permission creep, and unusual data flows.\n",
    "  - Estimated Cost: High - investments in advanced SIEM capabilities and specialist personnel.\n",
    "\n",
    "- **Supply Chain Security and Vendor Management:**\n",
    "  - Regularly assess third-party components and dependencies for vulnerabilities.\n",
    "  - Implement a comprehensive patch management program tailored for MCP servers, ensuring prompt remediation of newly discovered vulnerabilities.\n",
    "  - Estimated Cost: Medium to high, factoring in ongoing assessments and software updates.\n",
    "\n",
    "- **Continuous Training and Awareness:**\n",
    "  - Provide ongoing cybersecurity training to development and operations teams focused on emerging MCP-specific threats and best security practices.\n",
    "  - Estimated Cost: Low to medium, based on training resources and frequency of sessions.\n",
    "\n",
    "---\n",
    "\n",
    "## Compliance Considerations\n",
    "\n",
    "Ensuring that MCP servers comply with relevant industry standards is critical for avoiding legal ramifications and maintaining customer trust. Consider the following frameworks:\n",
    "\n",
    "- **NIST Cybersecurity Framework:**\n",
    "  - Align security controls with NIST guidelines to enhance risk management and incident response.\n",
    "  - Key Focus: Protect, Detect, Respond, and Recover functions.\n",
    "\n",
    "- **ISO 27001:**\n",
    "  - Implement an Information Security Management System (ISMS) to systematically manage sensitive information.\n",
    "  - Key Focus: Regular risk assessments and continuous improvement of security processes.\n",
    "\n",
    "- **SOC 2:**\n",
    "  - Ensure that security controls meet the Trust Service Criteria, enhancing the reliability and security of production systems.\n",
    "  - Key Focus: Availability, integrity, and confidentiality of data processes.\n",
    "\n",
    "- **GDPR/HIPAA (if applicable):**\n",
    "  - For organizations in regulated industries, ensure that data handling and processing comply with data protection requirements, including strong encryption and audit trails.\n",
    "\n",
    "Regular audits, compliance assessments, and integrated reporting tools should be harnessed to demonstrate adherence to these frameworks and to proactively address any deviations.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion and Next Steps\n",
    "\n",
    "MCP servers provide transformative benefits by enhancing the scalability, integration, and efficiency of AI-driven production systems. However, the evolving security landscape has revealed critical vulnerabilities that could jeopardize data security, system integrity, and regulatory compliance if left unaddressed.\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- The security risk associated with MCP servers is significant, particularly regarding prompt injection, tool poisoning, and insecure authentication mechanisms.\n",
    "- A layered security approach—encompassing secure communication protocols, strong authentication, rigorous input validation, comprehensive logging, and continuous monitoring—is essential to mitigate identified risks.\n",
    "- Compliance with frameworks such as NIST, ISO 27001, SOC 2, GDPR, and HIPAA is not only necessary for regulatory reasons but also serves as a benchmark for the overall security posture.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Immediate Remediation:** Prioritize patching and securing known vulnerabilities with a focus on authentication, encryption, and logging.\n",
    "2. **Conduct a Comprehensive Security Audit:** Engage third-party experts to perform a full security assessment and penetration test tailored to MCP server configurations.\n",
    "3. **Implement Continuous Monitoring:** Integrate advanced SIEM and anomaly detection systems to provide real-time threat intelligence focused on MCP-specific activities.\n",
    "4. **Staff Training & Policy Updates:** Educate development and operations teams on the unique security challenges of MCP implementations and update internal policies to reflect the latest best practices.\n",
    "5. **Ongoing Compliance Reviews:** Schedule regular compliance audits and update security frameworks to keep pace with evolving regulatory requirements and threat landscapes.\n",
    "\n",
    "By following these recommendations, organizations can leverage the benefits of MCP servers while maintaining a robust security posture, ensuring that production systems remain secure, resilient, and compliant in the long term.\n",
    "\n",
    "---\n",
    "\n",
    "## Appendices\n",
    "\n",
    "### Appendix A: Vulnerability Matrix and Timeline\n",
    "\n",
    "| Milestone                          | Action Item                                              | Timeline         | Priority  |\n",
    "|------------------------------------|----------------------------------------------------------|------------------|-----------|\n",
    "| 0-3 Months                         | Enhance authentication protocols (OAuth/mTLS)          | Immediate        | Critical  |\n",
    "| 0-3 Months                         | Enforce TLS 1.3, AES-256 encryption and automate certs   | Immediate        | Critical  |\n",
    "| 3-6 Months                         | Container hardening & vulnerability scanning             | Near-Term        | High      |\n",
    "| 3-6 Months                         | Implement code signing and tool verification mechanisms | Near-Term        | High      |\n",
    "| 6-12 Months                        | Integrate SOC and advanced threat monitoring systems     | Long-Term        | Critical  |\n",
    "| 6-12 Months                        | Establish supply chain security reviews & Continuous Training | Long-Term    | High      |\n",
    "\n",
    "### Appendix B: Resources and Tools\n",
    "\n",
    "- **Security Testing:** MCP Scanner, OWASP ZAP, Burp Suite\n",
    "- **Static Code Analysis:** Bandit, Semgrep, CodeQL\n",
    "- **Container Security:** Trivy, docker-bench-security\n",
    "- **Network Scanning:** Nmap, sslyze\n",
    "- **Compliance:** SIEM integrations, regular external audits\n",
    "\n",
    "---\n",
    "\n",
    "*This report is intended as a strategic guide for securing MCP servers. It is recommended that organizations tailor these recommendations to their specific operational environments and conduct periodic reviews to adapt to new threats and compliance requirements.*\n",
    "\n",
    "\n",
    "\n",
    "=====FOLLOW UP QUESTIONS=====\n",
    "\n",
    "\n",
    "1. How can organizations implement threat hunting frameworks specifically tailored for detecting prompt injection and tool poisoning attacks in MCP servers?\n",
    "2. What additional attack vectors should be evaluated for MCP servers, such as supply chain threats or exploitation through third-party dependencies?\n",
    "3. Which specific compliance gaps remain unaddressed in current MCP server implementations, particularly regarding evolving regulations like GDPR and HIPAA?\n",
    "4. How can integration of advanced monitoring tools and AI-driven anomaly detection further enhance the detection capabilities for MCP server vulnerabilities?\n",
    "5. What are the resource implications and estimated costs associated with transitioning from traditional authentication models to more secure options like OAuth 2.0 with PKCE and mTLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sample Report in Markdown \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Agents SDK: A Comprehensive Report\n",
    "\n",
    "*Published: October 2023*\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Core Concepts and Key Features](#core-concepts-and-key-features)\n",
    "3. [Architecture and Developer Experience](#architecture-and-developer-experience)\n",
    "4. [Comparative Analysis with Alternative Frameworks](#comparative-analysis-with-alternative-frameworks)\n",
    "5. [Integrations and Real-World Applications](#integrations-and-real-world-applications)\n",
    "6. [Troubleshooting, Observability, and Debugging](#troubleshooting-observability-and-debugging)\n",
    "7. [Community Impact and Future Directions](#community-impact-and-future-directions)\n",
    "8. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In March 2025, OpenAI released the Agents SDK, a groundbreaking, open-source framework aimed at simplifying the development of autonomous AI agents capable of performing intricate tasks with minimal human intervention. Designed with a Python-first approach, the SDK offers a minimal set of abstractions, yet provides all the necessary components to build, debug, and optimize multi-agent workflows. The release marked a significant milestone for developers who seek to integrate large language models (LLMs) with advanced task delegation mechanisms, enabling next-generation automation in various industries.\n",
    "\n",
    "The primary goal of the OpenAI Agents SDK is to streamline the creation of agentic applications by offering core primitives such as *agents*, *handoffs*, and *guardrails*. These primitives are essential for orchestrating autonomous AI systems that perform key functions such as web search, file operations, and even actions on a computer. This report delves into the SDK's features, its operational architecture, integration capabilities, and how it compares to other frameworks in the rapidly evolving landscape of AI development tools.\n",
    "\n",
    "## Core Concepts and Key Features\n",
    "\n",
    "### Agents\n",
    "\n",
    "At the heart of the SDK are **agents**—intelligent entities that encapsulate a specific set of instructions and tools. Each agent is built on top of a large language model and can be customized with its own personality, domain expertise, and operational directives. For example, a \"Math Tutor\" agent could be designed to solve math problems by explaining each step clearly.\n",
    "\n",
    "**Key elements of an agent include:**\n",
    "\n",
    "- **Instructions:** Specific guidelines that shape the agent's responses and behavior in the context of its designated role.\n",
    "- **Tools:** Predefined or dynamically integrated tools that the agent can leverage to access external resources (e.g., web search or file search functionalities).\n",
    "\n",
    "### Handoffs\n",
    "\n",
    "A unique feature introduced by the SDK is the concept of **handoffs**. Handoffs allow agents to delegate tasks to one another based on expertise and contextual needs. This orchestration paves the way for sophisticated workflows where multiple agents work in tandem, each contributing its specialized capabilities to complete a complex task.\n",
    "\n",
    "### Guardrails\n",
    "\n",
    "Safety and reliability remain a cornerstone in AI development, and the SDK introduces **guardrails** as a means of controlling input and output validation. Guardrails help ensure that agents operate within defined safety parameters, preventing unintended actions and mitigating risks associated with autonomous decision-making.\n",
    "\n",
    "### Built-in Debugging and Observability\n",
    "\n",
    "The development process is further enhanced by built-in **tracing and visualization tools**. These tools offer real-time insights into agent interactions, tool invocations, and decision-making pathways, thereby making debugging and optimization more accessible and systematic. The tracing functionality is a vital feature for developers looking to fine-tune agent performance in production environments.\n",
    "\n",
    "## Architecture and Developer Experience\n",
    "\n",
    "### Python-First Approach\n",
    "\n",
    "The SDK is inherently Python-based, making it highly accessible to the vast community of Python developers. By leveraging existing language features without introducing excessive abstractions, the SDK provides both simplicity and power. The installation is straightforward:\n",
    "\n",
    "```bash\n",
    "mkdir my_project\n",
    "cd my_project\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip install openai-agents\n",
    "```\n",
    "\n",
    "Once installed, developers can create and configure agents with minimal boilerplate code. The emphasis on a minimal learning curve has been a significant point of praise among early adopters.\n",
    "\n",
    "### Developer Tools and Tutorials\n",
    "\n",
    "In addition to comprehensive official documentation available on OpenAI’s GitHub pages, the community has contributed numerous tutorials and code examples. Video tutorials by experts such as Sam Witteveen and James Briggs provide hands-on demonstrations, ranging from simple agent creation to more sophisticated scenarios involving parallel execution and advanced tool integrations.\n",
    "\n",
    "### Use of Python's Ecosystem\n",
    "\n",
    "The integration with Python’s ecosystem means that developers can immediately apply a range of established libraries and frameworks. For instance, utilizing Pydantic for input validation in guardrails or leveraging visualization libraries to display agent workflows are examples of how the SDK embraces the strengths of Python.\n",
    "\n",
    "## Comparative Analysis with Alternative Frameworks\n",
    "\n",
    "While the OpenAI Agents SDK has received acclaim for its simplicity and robust integration with OpenAI’s ecosystem, other frameworks such as LangGraph, CrewAI, and AutoGen have emerged as viable alternatives. Here’s how they compare:\n",
    "\n",
    "- **LangGraph:** Known for its graph-based architecture, LangGraph is ideal for handling complex and cyclical workflows that require sophisticated state management. However, it comes with a steeper learning curve, making it less accessible for projects that require quick prototyping.\n",
    "\n",
    "- **CrewAI:** Emphasizing a role-based multi-agent system, CrewAI excels in scenarios where collaboration among agents is critical. Its design promotes clear segregation of duties among different agents, which can be beneficial in customer service or large-scale business automation.\n",
    "\n",
    "- **AutoGen:** This framework supports flexible conversation patterns and diverse agent interactions, particularly useful in applications where adaptive dialogue is essential. Nevertheless, AutoGen may introduce additional overhead when managing state and coordinating multiple agents.\n",
    "\n",
    "In contrast, the OpenAI Agents SDK strikes an effective balance by offering a lightweight yet powerful toolset geared towards production readiness. Its strengths lie in its minimal abstractions, ease of integration with various tools (like web search and file search), and built-in observability features that are crucial for debugging and tracing agent interactions.\n",
    "\n",
    "## Integrations and Real-World Applications\n",
    "\n",
    "### Diverse Integrations\n",
    "\n",
    "The real power of the OpenAI Agents SDK surfaces when it is integrated with other systems and platforms. Notable integrations include:\n",
    "\n",
    "- **Box Integration:** Enhancing enterprise content management, Box has adopted the SDK to enable secure AI-powered data processing. This integration allows agents to reliably access and interpret proprietary data.\n",
    "\n",
    "- **Coinbase AgentKit:** With financial capabilities in mind, Coinbase introduced AgentKit, leveraging the SDK to incorporate financial operations and risk analysis directly into AI agents.\n",
    "\n",
    "- **Milvus and Ollama:** These integrations allow the SDK to handle high-performance data queries and run agents on local infrastructure respectively, ensuring both speed and privacy.\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "The versatility of the SDK lends itself to a multitude of applications:\n",
    "\n",
    "- **Customer Support:** Automated agents can be built to handle customer inquiries, providing faster and more accurate responses while reducing workload on human agents.\n",
    "\n",
    "- **Content Generation:** In marketing and media, agents can generate high-quality articles, detailed reports, and even code reviews with built-in content guidelines.\n",
    "\n",
    "- **Financial Analysis:** Specialized agents capable of real-time data fetching and market analysis can generate actionable insights for investors and analysts.\n",
    "\n",
    "- **Health and Wellness:** Custom agents can handle tasks such as appointment scheduling, patient record management, and even provide personalized fitness and dietary recommendations.\n",
    "\n",
    "- **Educational Tools:** Intelligent tutoring agents can assist students by providing personalized learning experiences and instant feedback on assignments.\n",
    "\n",
    "These applications underscore the SDK’s transformative potential across various industries, driving the trend towards increased automation and efficiency.\n",
    "\n",
    "## Troubleshooting, Observability, and Debugging\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "As with any cutting-edge technology, developers working with the OpenAI Agents SDK have encountered challenges:\n",
    "\n",
    "- **API Key Management:** Authentication errors due to missing or invalid API keys are common. The solution involves ensuring that the `OPENAI_API_KEY` environment variable is correctly set or programmatically configured using OpenAI’s helper functions.\n",
    "\n",
    "- **Rate Limitations:** Rate limits, an intrinsic challenge with API-based services, require developers to monitor dashboard usage and implement retry strategies with exponential backoff.\n",
    "\n",
    "- **Response Delays:** Network latency and high server loads can result in unexpected delays. Developers are advised to check network settings, adhere to best practices in setting request timeouts, and monitor OpenAI’s service status.\n",
    "\n",
    "### Built-In Tracing Capabilities\n",
    "\n",
    "The SDK provides robust tracing tools that log agent inputs, outputs, tool interactions, and error messages. This level of observability is crucial for debugging complex workflows and allows developers to visualize the agent’s decision-making process in real time. By configuring a `TracingConfig` object, developers can capture detailed insights and identify performance bottlenecks.\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Prompt Engineering:** Refine prompts to reduce ambiguity and minimize unexpected outputs.\n",
    "- **Layered Validation:** Use guardrails extensively to ensure inputs and outputs are verified at multiple layers.\n",
    "- **Modular Design:** Break complex tasks into smaller, more manageable components using handoffs to delegate tasks appropriately.\n",
    "\n",
    "## Community Impact and Future Directions\n",
    "\n",
    "### Developer and Enterprise Adoption\n",
    "\n",
    "The release of the OpenAI Agents SDK has been met with enthusiasm within the developer community. Its ease of use, combined with comprehensive documentation and community-driven resources (such as tutorials on Class Central and DataCamp), has accelerated its adoption across educational, enterprise, and research sectors.\n",
    "\n",
    "Several leading organizations, including Box and Coinbase, have integrated the SDK into their workflows, demonstrating its capability to drive real-world business solutions. The open-source nature of the SDK, licensed under the MIT License, further encourages widespread industrial collaboration and innovation.\n",
    "\n",
    "### Future Prospects\n",
    "\n",
    "Looking forward, OpenAI plans to extend the SDK’s support beyond Python, potentially embracing other programming languages like JavaScript. Additionally, future updates are anticipated to expand tool integrations, further enhance safety mechanisms, and streamline the development of multi-agent ecosystems. Planned deprecations of older APIs, such as the Assistants API in favor of the more unified Responses API, underline the SDK’s evolving roadmap aimed at future-proofing agentic applications.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The OpenAI Agents SDK represents a significant step forward in the field of AI development. Its lightweight, Python-first framework facilitates the creation of autonomous agents that can handle a wide array of tasks—from simple inquiries to complex multi-agent systems. The SDK’s robust integration capabilities, combined with its focus on safety and observability, make it an ideal choice for both developers and enterprises seeking to build reliable, scalable agentic applications.\n",
    "\n",
    "In summary, the SDK not only lowers the barrier to entry for developing sophisticated AI applications but also sets the stage for further innovations as the ecosystem evolves. It is poised to become a standard toolkit for the next generation of AI-driven technologies, empowering users across sectors to achieve greater efficiency and creativity in task automation.\n",
    "\n",
    "---\n",
    "\n",
    "*For further reading, developers are encouraged to visit the official OpenAI documentation, join the community forums, and explore real-world use cases to deepen their understanding of this transformative tool.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
